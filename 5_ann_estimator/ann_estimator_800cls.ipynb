{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import random\n",
    "import plotly.express as px\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('..//3_k-means_clustering//apartment_data_frame_clustered_800','rb')\n",
    "frame = pkl.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>district</th>\n",
       "      <th>voivodeship</th>\n",
       "      <th>localization_y</th>\n",
       "      <th>localization_x</th>\n",
       "      <th>market</th>\n",
       "      <th>area</th>\n",
       "      <th>rooms</th>\n",
       "      <th>floor</th>\n",
       "      <th>floors</th>\n",
       "      <th>build_yr</th>\n",
       "      <th>price</th>\n",
       "      <th>url</th>\n",
       "      <th>price_of_sqm</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warszawa</td>\n",
       "      <td>Wola</td>\n",
       "      <td>mazowieckie</td>\n",
       "      <td>52.245982</td>\n",
       "      <td>20.985385</td>\n",
       "      <td>wtorny</td>\n",
       "      <td>36.00</td>\n",
       "      <td>2</td>\n",
       "      <td>parter</td>\n",
       "      <td>3</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>496000.0</td>\n",
       "      <td>https://gratka.pl/nieruchomosci/mieszkanie-war...</td>\n",
       "      <td>13777.777778</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kraków</td>\n",
       "      <td>Swoszowice</td>\n",
       "      <td>małopolskie</td>\n",
       "      <td>49.991389</td>\n",
       "      <td>19.946389</td>\n",
       "      <td>wtorny</td>\n",
       "      <td>78.32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>https://gratka.pl/nieruchomosci/mieszkanie-kra...</td>\n",
       "      <td>6869.254341</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Łódź</td>\n",
       "      <td>Śródmieście</td>\n",
       "      <td>łódzkie</td>\n",
       "      <td>51.772914</td>\n",
       "      <td>19.458331</td>\n",
       "      <td>wtorny</td>\n",
       "      <td>60.27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>https://gratka.pl/nieruchomosci/mieszkanie-lod...</td>\n",
       "      <td>4479.840717</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warszawa</td>\n",
       "      <td>Stara Ochota</td>\n",
       "      <td>mazowieckie</td>\n",
       "      <td>52.218900</td>\n",
       "      <td>20.978800</td>\n",
       "      <td>wtorny</td>\n",
       "      <td>122.00</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1955000.0</td>\n",
       "      <td>https://gratka.pl/nieruchomosci/mieszkanie-war...</td>\n",
       "      <td>16024.590164</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kraków</td>\n",
       "      <td>Mistrzejowice</td>\n",
       "      <td>małopolskie</td>\n",
       "      <td>50.096196</td>\n",
       "      <td>20.009887</td>\n",
       "      <td>wtorny</td>\n",
       "      <td>48.07</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>384000.0</td>\n",
       "      <td>https://gratka.pl/nieruchomosci/mieszkanie-kra...</td>\n",
       "      <td>7988.350322</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54462</th>\n",
       "      <td>Warszawa</td>\n",
       "      <td>Wola</td>\n",
       "      <td>mazowieckie</td>\n",
       "      <td>52.237222</td>\n",
       "      <td>20.960556</td>\n",
       "      <td>pierwotny</td>\n",
       "      <td>109.00</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1460000.0</td>\n",
       "      <td>https://gratka.pl/nieruchomosci/nowe-mieszkani...</td>\n",
       "      <td>13394.495413</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54463</th>\n",
       "      <td>Warszawa</td>\n",
       "      <td>Wola</td>\n",
       "      <td>mazowieckie</td>\n",
       "      <td>52.237222</td>\n",
       "      <td>20.960556</td>\n",
       "      <td>wtorny</td>\n",
       "      <td>82.60</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>885000.0</td>\n",
       "      <td>https://gratka.pl/nieruchomosci/4-pokojowe-got...</td>\n",
       "      <td>10714.285714</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54464</th>\n",
       "      <td>Poznań</td>\n",
       "      <td>Grunwald</td>\n",
       "      <td>wielkopolskie</td>\n",
       "      <td>52.392626</td>\n",
       "      <td>16.846137</td>\n",
       "      <td>wtorny</td>\n",
       "      <td>68.25</td>\n",
       "      <td>3</td>\n",
       "      <td>parter</td>\n",
       "      <td>4</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>540000.0</td>\n",
       "      <td>https://gratka.pl/nieruchomosci/mieszkanie-poz...</td>\n",
       "      <td>7912.087912</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54465</th>\n",
       "      <td>Kraków</td>\n",
       "      <td>Os. Prądnik Czerwony</td>\n",
       "      <td>małopolskie</td>\n",
       "      <td>50.088513</td>\n",
       "      <td>19.958912</td>\n",
       "      <td>wtorny</td>\n",
       "      <td>45.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>610000.0</td>\n",
       "      <td>https://gratka.pl/nieruchomosci/mieszkanie-kra...</td>\n",
       "      <td>13555.555556</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54466</th>\n",
       "      <td>Suszec</td>\n",
       "      <td>pszczyński</td>\n",
       "      <td>śląskie</td>\n",
       "      <td>50.029463</td>\n",
       "      <td>18.791269</td>\n",
       "      <td>wtorny</td>\n",
       "      <td>34.05</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>119900.0</td>\n",
       "      <td>https://gratka.pl/nieruchomosci/mieszkanie-sus...</td>\n",
       "      <td>3521.292217</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54467 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city              district    voivodeship  localization_y  \\\n",
       "0      Warszawa                  Wola    mazowieckie       52.245982   \n",
       "1        Kraków            Swoszowice    małopolskie       49.991389   \n",
       "2          Łódź           Śródmieście        łódzkie       51.772914   \n",
       "3      Warszawa          Stara Ochota    mazowieckie       52.218900   \n",
       "4        Kraków         Mistrzejowice    małopolskie       50.096196   \n",
       "...         ...                   ...            ...             ...   \n",
       "54462  Warszawa                  Wola    mazowieckie       52.237222   \n",
       "54463  Warszawa                  Wola    mazowieckie       52.237222   \n",
       "54464    Poznań              Grunwald  wielkopolskie       52.392626   \n",
       "54465    Kraków  Os. Prądnik Czerwony    małopolskie       50.088513   \n",
       "54466    Suszec            pszczyński        śląskie       50.029463   \n",
       "\n",
       "       localization_x     market    area rooms   floor floors  build_yr  \\\n",
       "0           20.985385     wtorny   36.00     2  parter      3    1956.0   \n",
       "1           19.946389     wtorny   78.32     3       3      3    2014.0   \n",
       "2           19.458331     wtorny   60.27     2       2      3    1910.0   \n",
       "3           20.978800     wtorny  122.00     4       6      7    2020.0   \n",
       "4           20.009887     wtorny   48.07     3       3      4    1978.0   \n",
       "...               ...        ...     ...   ...     ...    ...       ...   \n",
       "54462       20.960556  pierwotny  109.00     4      12     13    2020.0   \n",
       "54463       20.960556     wtorny   82.60     4       4      5    2020.0   \n",
       "54464       16.846137     wtorny   68.25     3  parter      4    2009.0   \n",
       "54465       19.958912     wtorny   45.00     2       2     10    2019.0   \n",
       "54466       18.791269     wtorny   34.05     1       3      4    1990.0   \n",
       "\n",
       "           price                                                url  \\\n",
       "0       496000.0  https://gratka.pl/nieruchomosci/mieszkanie-war...   \n",
       "1       538000.0  https://gratka.pl/nieruchomosci/mieszkanie-kra...   \n",
       "2       270000.0  https://gratka.pl/nieruchomosci/mieszkanie-lod...   \n",
       "3      1955000.0  https://gratka.pl/nieruchomosci/mieszkanie-war...   \n",
       "4       384000.0  https://gratka.pl/nieruchomosci/mieszkanie-kra...   \n",
       "...          ...                                                ...   \n",
       "54462  1460000.0  https://gratka.pl/nieruchomosci/nowe-mieszkani...   \n",
       "54463   885000.0  https://gratka.pl/nieruchomosci/4-pokojowe-got...   \n",
       "54464   540000.0  https://gratka.pl/nieruchomosci/mieszkanie-poz...   \n",
       "54465   610000.0  https://gratka.pl/nieruchomosci/mieszkanie-kra...   \n",
       "54466   119900.0  https://gratka.pl/nieruchomosci/mieszkanie-sus...   \n",
       "\n",
       "       price_of_sqm  cluster  \n",
       "0      13777.777778      601  \n",
       "1       6869.254341      331  \n",
       "2       4479.840717      127  \n",
       "3      16024.590164      777  \n",
       "4       7988.350322       40  \n",
       "...             ...      ...  \n",
       "54462  13394.495413      488  \n",
       "54463  10714.285714      488  \n",
       "54464   7912.087912      292  \n",
       "54465  13555.555556      326  \n",
       "54466   3521.292217      367  \n",
       "\n",
       "[54467 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparation for ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54467 entries, 0 to 54466\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   city            54467 non-null  object \n",
      " 1   district        54467 non-null  object \n",
      " 2   voivodeship     46557 non-null  object \n",
      " 3   localization_y  54467 non-null  float64\n",
      " 4   localization_x  54467 non-null  float64\n",
      " 5   market          54467 non-null  object \n",
      " 6   area            54467 non-null  float64\n",
      " 7   rooms           54467 non-null  object \n",
      " 8   floor           54467 non-null  object \n",
      " 9   floors          54467 non-null  object \n",
      " 10  build_yr        54467 non-null  float64\n",
      " 11  price           54467 non-null  float64\n",
      " 12  url             54467 non-null  object \n",
      " 13  price_of_sqm    54467 non-null  float64\n",
      " 14  cluster         54467 non-null  int32  \n",
      "dtypes: float64(6), int32(1), object(8)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame.drop(['city','district','voivodeship','localization_y','localization_x','area','price','url'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.cluster = frame.cluster.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54467 entries, 0 to 54466\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   market        54467 non-null  object \n",
      " 1   rooms         54467 non-null  object \n",
      " 2   floor         54467 non-null  object \n",
      " 3   floors        54467 non-null  object \n",
      " 4   build_yr      54467 non-null  float64\n",
      " 5   price_of_sqm  54467 non-null  float64\n",
      " 6   cluster       54467 non-null  object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "frame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(frame[['market','rooms','floor','floors','cluster']],drop_first=True)\n",
    "frame = frame.drop(['market','rooms','floor','floors','cluster'],axis=1)\n",
    "frame = pd.concat([frame,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>build_yr</th>\n",
       "      <th>price_of_sqm</th>\n",
       "      <th>market_wtorny</th>\n",
       "      <th>rooms_2</th>\n",
       "      <th>rooms_3</th>\n",
       "      <th>rooms_4</th>\n",
       "      <th>rooms_5</th>\n",
       "      <th>rooms_6</th>\n",
       "      <th>rooms_7</th>\n",
       "      <th>rooms_8</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_90</th>\n",
       "      <th>cluster_91</th>\n",
       "      <th>cluster_92</th>\n",
       "      <th>cluster_93</th>\n",
       "      <th>cluster_94</th>\n",
       "      <th>cluster_95</th>\n",
       "      <th>cluster_96</th>\n",
       "      <th>cluster_97</th>\n",
       "      <th>cluster_98</th>\n",
       "      <th>cluster_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956.0</td>\n",
       "      <td>13777.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>6869.254341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1910.0</td>\n",
       "      <td>4479.840717</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>16024.590164</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1978.0</td>\n",
       "      <td>7988.350322</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54462</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>13394.495413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54463</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>10714.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54464</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>7912.087912</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54465</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>13555.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54466</th>\n",
       "      <td>1990.0</td>\n",
       "      <td>3521.292217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54467 rows × 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       build_yr  price_of_sqm  market_wtorny  rooms_2  rooms_3  rooms_4  \\\n",
       "0        1956.0  13777.777778              1        1        0        0   \n",
       "1        2014.0   6869.254341              1        0        1        0   \n",
       "2        1910.0   4479.840717              1        1        0        0   \n",
       "3        2020.0  16024.590164              1        0        0        1   \n",
       "4        1978.0   7988.350322              1        0        1        0   \n",
       "...         ...           ...            ...      ...      ...      ...   \n",
       "54462    2020.0  13394.495413              0        0        0        1   \n",
       "54463    2020.0  10714.285714              1        0        0        1   \n",
       "54464    2009.0   7912.087912              1        0        1        0   \n",
       "54465    2019.0  13555.555556              1        1        0        0   \n",
       "54466    1990.0   3521.292217              1        0        0        0   \n",
       "\n",
       "       rooms_5  rooms_6  rooms_7  rooms_8  ...  cluster_90  cluster_91  \\\n",
       "0            0        0        0        0  ...           0           0   \n",
       "1            0        0        0        0  ...           0           0   \n",
       "2            0        0        0        0  ...           0           0   \n",
       "3            0        0        0        0  ...           0           0   \n",
       "4            0        0        0        0  ...           0           0   \n",
       "...        ...      ...      ...      ...  ...         ...         ...   \n",
       "54462        0        0        0        0  ...           0           0   \n",
       "54463        0        0        0        0  ...           0           0   \n",
       "54464        0        0        0        0  ...           0           0   \n",
       "54465        0        0        0        0  ...           0           0   \n",
       "54466        0        0        0        0  ...           0           0   \n",
       "\n",
       "       cluster_92  cluster_93  cluster_94  cluster_95  cluster_96  cluster_97  \\\n",
       "0               0           0           0           0           0           0   \n",
       "1               0           0           0           0           0           0   \n",
       "2               0           0           0           0           0           0   \n",
       "3               0           0           0           0           0           0   \n",
       "4               0           0           0           0           0           0   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "54462           0           0           0           0           0           0   \n",
       "54463           0           0           0           0           0           0   \n",
       "54464           0           0           0           0           0           0   \n",
       "54465           0           0           0           0           0           0   \n",
       "54466           0           0           0           0           0           0   \n",
       "\n",
       "       cluster_98  cluster_99  \n",
       "0               0           0  \n",
       "1               0           0  \n",
       "2               0           0  \n",
       "3               0           0  \n",
       "4               0           0  \n",
       "...           ...         ...  \n",
       "54462           0           0  \n",
       "54463           0           0  \n",
       "54464           0           0  \n",
       "54465           0           0  \n",
       "54466           0           0  \n",
       "\n",
       "[54467 rows x 874 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = frame.drop('price_of_sqm',axis=1).values\n",
    "y = frame.price_of_sqm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40850, 873)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13617, 873)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94094488, 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.98818898, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.98425197, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7480315 , 1.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.89370079, 1.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.95275591, 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation ,Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16,activation='relu',input_dim=X_test.shape[1]))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mean_squared_error',random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                13984     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 14,473\n",
      "Trainable params: 14,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop = EarlyStopping(monitor='val_loss',patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40850 samples, validate on 13617 samples\n",
      "Epoch 1/5000\n",
      "40850/40850 [==============================] - 2s 47us/sample - loss: 101232332.8212 - val_loss: 102002139.8734\n",
      "Epoch 2/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 83923401.5644 - val_loss: 51640560.9988\n",
      "Epoch 3/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 23197996.0986 - val_loss: 16033724.1849\n",
      "Epoch 4/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 14572964.8625 - val_loss: 14340938.9094\n",
      "Epoch 5/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 13061926.2626 - val_loss: 13023447.4868\n",
      "Epoch 6/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 11828862.6107 - val_loss: 11889662.4815\n",
      "Epoch 7/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 10751681.9108 - val_loss: 10883304.9971\n",
      "Epoch 8/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 9773232.0055 - val_loss: 9937166.6228\n",
      "Epoch 9/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 8874698.7237 - val_loss: 9080858.2471\n",
      "Epoch 10/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 8069466.8212 - val_loss: 8298239.0760\n",
      "Epoch 11/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 7372591.6960 - val_loss: 7639925.3047\n",
      "Epoch 12/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 6803806.0766 - val_loss: 7124269.2755\n",
      "Epoch 13/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 6365489.2641 - val_loss: 6718914.1880\n",
      "Epoch 14/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 6047024.5108 - val_loss: 6435123.0639\n",
      "Epoch 15/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 5819376.4040 - val_loss: 6228971.7924\n",
      "Epoch 16/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 5656158.3066 - val_loss: 6077745.0218\n",
      "Epoch 17/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 5534714.2110 - val_loss: 5963117.2968\n",
      "Epoch 18/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 5444497.4405 - val_loss: 5881362.0110\n",
      "Epoch 19/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 5373462.3656 - val_loss: 5813410.3706\n",
      "Epoch 20/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 5319150.5174 - val_loss: 5750719.1676\n",
      "Epoch 21/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 5273904.2490 - val_loss: 5709753.6193\n",
      "Epoch 22/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 5235213.2575 - val_loss: 5677958.0758\n",
      "Epoch 23/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 5206713.2805 - val_loss: 5648472.7136\n",
      "Epoch 24/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 5177443.3667 - val_loss: 5613647.7888\n",
      "Epoch 25/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 5150771.8397 - val_loss: 5593426.7718\n",
      "Epoch 26/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 5132496.6618 - val_loss: 5578469.1587\n",
      "Epoch 27/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 5116156.8000 - val_loss: 5573212.4652\n",
      "Epoch 28/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 5100639.7020 - val_loss: 5547350.7820\n",
      "Epoch 29/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 5083021.4374 - val_loss: 5542463.6047\n",
      "Epoch 30/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 5072776.7587 - val_loss: 5511609.9376\n",
      "Epoch 31/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 5060229.4429 - val_loss: 5536454.1725\n",
      "Epoch 32/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 5051350.1132 - val_loss: 5504702.0996\n",
      "Epoch 33/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 5043384.9396 - val_loss: 5485171.5964\n",
      "Epoch 34/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 5031963.5231 - val_loss: 5478063.7508\n",
      "Epoch 35/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 5025953.5996 - val_loss: 5476298.3907\n",
      "Epoch 36/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 5020894.7470 - val_loss: 5459760.9515\n",
      "Epoch 37/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 5012087.7737 - val_loss: 5456456.3161\n",
      "Epoch 38/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 5004936.4523 - val_loss: 5454341.7017\n",
      "Epoch 39/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4998775.6292 - val_loss: 5439550.0058\n",
      "Epoch 40/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4994810.3240 - val_loss: 5437058.3784\n",
      "Epoch 41/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4992211.8095 - val_loss: 5438131.9097\n",
      "Epoch 42/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4984775.7921 - val_loss: 5425654.5022\n",
      "Epoch 43/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4975498.6898 - val_loss: 5418729.6579\n",
      "Epoch 44/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4974435.8607 - val_loss: 5420737.2405\n",
      "Epoch 45/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4970305.5459 - val_loss: 5417396.5948\n",
      "Epoch 46/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4961867.0596 - val_loss: 5412772.0153\n",
      "Epoch 47/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4958034.2405 - val_loss: 5423866.0735\n",
      "Epoch 48/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4955387.5019 - val_loss: 5399333.5374\n",
      "Epoch 49/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4951052.1841 - val_loss: 5395854.4068\n",
      "Epoch 50/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4949859.3975 - val_loss: 5393986.3613\n",
      "Epoch 51/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4947094.0170 - val_loss: 5400569.5746\n",
      "Epoch 52/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4940322.1669 - val_loss: 5385915.7002\n",
      "Epoch 53/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4935768.9162 - val_loss: 5383504.3286\n",
      "Epoch 54/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4936072.3547 - val_loss: 5379760.4070\n",
      "Epoch 55/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4930924.1079 - val_loss: 5382361.6065\n",
      "Epoch 56/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4926420.9178 - val_loss: 5391786.8611\n",
      "Epoch 57/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4923982.6859 - val_loss: 5381537.4903\n",
      "Epoch 58/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4919750.6743 - val_loss: 5373246.9679\n",
      "Epoch 59/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4918603.0528 - val_loss: 5368317.1110\n",
      "Epoch 60/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4914202.0869 - val_loss: 5369418.3027\n",
      "Epoch 61/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4911738.7053 - val_loss: 5364868.9989\n",
      "Epoch 62/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4906982.6791 - val_loss: 5363357.6344\n",
      "Epoch 63/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4907305.6951 - val_loss: 5360656.4001\n",
      "Epoch 64/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4903722.6481 - val_loss: 5358429.6658\n",
      "Epoch 65/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4902208.8824 - val_loss: 5361283.0050\n",
      "Epoch 66/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4900928.4629 - val_loss: 5356765.2476\n",
      "Epoch 67/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4897627.2097 - val_loss: 5353736.6177\n",
      "Epoch 68/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4894988.8241 - val_loss: 5357620.3166\n",
      "Epoch 69/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4897533.9664 - val_loss: 5350321.7762\n",
      "Epoch 70/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4890803.4132 - val_loss: 5346644.9191\n",
      "Epoch 71/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4894455.3396 - val_loss: 5348783.7267\n",
      "Epoch 72/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4888848.7089 - val_loss: 5352406.7651\n",
      "Epoch 73/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4885151.2436 - val_loss: 5347774.1478\n",
      "Epoch 74/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4884015.5246 - val_loss: 5342222.8159\n",
      "Epoch 75/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4881158.4965 - val_loss: 5353253.1445\n",
      "Epoch 76/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4879284.9538 - val_loss: 5340683.4553\n",
      "Epoch 77/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4883089.2929 - val_loss: 5346787.1098\n",
      "Epoch 78/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4878122.4942 - val_loss: 5337752.9099\n",
      "Epoch 79/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4879320.7497 - val_loss: 5336629.3044\n",
      "Epoch 80/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4873121.0932 - val_loss: 5337289.7369\n",
      "Epoch 81/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4871214.0537 - val_loss: 5334279.3915\n",
      "Epoch 82/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4870555.1460 - val_loss: 5335213.3588\n",
      "Epoch 83/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4869827.5557 - val_loss: 5329756.2416\n",
      "Epoch 84/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4868714.9600 - val_loss: 5330885.3769\n",
      "Epoch 85/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4869216.4853 - val_loss: 5329351.4790\n",
      "Epoch 86/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4866180.0929 - val_loss: 5342602.9862\n",
      "Epoch 87/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4863504.0643 - val_loss: 5324247.8225\n",
      "Epoch 88/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4861832.8881 - val_loss: 5329642.9492\n",
      "Epoch 89/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4860541.0735 - val_loss: 5329286.7954\n",
      "Epoch 90/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4859388.4918 - val_loss: 5323123.5355\n",
      "Epoch 91/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4860901.4864 - val_loss: 5321885.2945\n",
      "Epoch 92/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4860166.4484 - val_loss: 5327659.9082\n",
      "Epoch 93/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4856626.8477 - val_loss: 5330267.1644\n",
      "Epoch 94/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4854241.0422 - val_loss: 5322501.8006\n",
      "Epoch 95/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4854600.6583 - val_loss: 5324718.7481\n",
      "Epoch 96/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4855728.5155 - val_loss: 5317165.5933\n",
      "Epoch 97/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4853671.3209 - val_loss: 5313537.5918\n",
      "Epoch 98/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4853672.6572 - val_loss: 5314074.3019\n",
      "Epoch 99/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4850312.7109 - val_loss: 5314744.2078\n",
      "Epoch 100/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4849876.7529 - val_loss: 5310525.4294\n",
      "Epoch 101/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4848411.8355 - val_loss: 5312346.6589\n",
      "Epoch 102/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4845648.4645 - val_loss: 5312463.7483\n",
      "Epoch 103/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4844843.6869 - val_loss: 5346243.0082\n",
      "Epoch 104/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4849210.2901 - val_loss: 5313508.9114\n",
      "Epoch 105/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4840574.2641 - val_loss: 5304617.7846\n",
      "Epoch 106/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4843239.0884 - val_loss: 5310569.4666\n",
      "Epoch 107/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4836610.5069 - val_loss: 5302059.8508\n",
      "Epoch 108/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4834915.3915 - val_loss: 5309649.9945\n",
      "Epoch 109/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4839034.2863 - val_loss: 5316581.9527\n",
      "Epoch 110/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4832660.7459 - val_loss: 5309830.7854\n",
      "Epoch 111/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4831922.7882 - val_loss: 5310384.4636\n",
      "Epoch 112/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4829300.0891 - val_loss: 5302197.5501\n",
      "Epoch 113/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4829364.7205 - val_loss: 5294085.0928\n",
      "Epoch 114/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4826185.6553 - val_loss: 5320827.9577\n",
      "Epoch 115/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4827494.5345 - val_loss: 5292103.7577\n",
      "Epoch 116/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4822461.2781 - val_loss: 5297096.3752\n",
      "Epoch 117/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4823619.6506 - val_loss: 5290317.2864\n",
      "Epoch 118/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4818818.0246 - val_loss: 5290081.4147\n",
      "Epoch 119/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4819289.8755 - val_loss: 5288495.3886\n",
      "Epoch 120/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4815621.0472 - val_loss: 5290452.3037\n",
      "Epoch 121/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4814235.1203 - val_loss: 5283718.9553\n",
      "Epoch 122/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4813800.2022 - val_loss: 5286950.4298\n",
      "Epoch 123/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4809934.7793 - val_loss: 5284714.0457\n",
      "Epoch 124/5000\n",
      "40850/40850 [==============================] - ETA: 0s - loss: 4816079.779 - 1s 14us/sample - loss: 4810112.9758 - val_loss: 5283548.0599\n",
      "Epoch 125/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4806263.1969 - val_loss: 5282986.2701\n",
      "Epoch 126/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4805749.7430 - val_loss: 5279284.4171\n",
      "Epoch 127/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4804383.2341 - val_loss: 5280091.0278\n",
      "Epoch 128/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4802949.4762 - val_loss: 5281526.8112\n",
      "Epoch 129/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4801908.6298 - val_loss: 5281937.4587\n",
      "Epoch 130/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4803833.2945 - val_loss: 5301147.5196\n",
      "Epoch 131/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4799275.1844 - val_loss: 5277920.7758\n",
      "Epoch 132/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4796427.5047 - val_loss: 5275063.3810\n",
      "Epoch 133/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4792798.0062 - val_loss: 5274133.8511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4790894.0751 - val_loss: 5274301.5520\n",
      "Epoch 135/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4789092.9897 - val_loss: 5286330.4313\n",
      "Epoch 136/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4787480.2875 - val_loss: 5275067.5767\n",
      "Epoch 137/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4783310.2863 - val_loss: 5267663.2312\n",
      "Epoch 138/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4783832.4540 - val_loss: 5270933.1129\n",
      "Epoch 139/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4781484.2264 - val_loss: 5268985.6166\n",
      "Epoch 140/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4779493.2533 - val_loss: 5277109.3247\n",
      "Epoch 141/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4778713.1302 - val_loss: 5264717.9520\n",
      "Epoch 142/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4776292.0911 - val_loss: 5261810.7726\n",
      "Epoch 143/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4775403.9367 - val_loss: 5273491.6607\n",
      "Epoch 144/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4772396.0567 - val_loss: 5261930.2873\n",
      "Epoch 145/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4771516.8542 - val_loss: 5260622.0417\n",
      "Epoch 146/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4765794.4602 - val_loss: 5268196.3495\n",
      "Epoch 147/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4767331.0970 - val_loss: 5262896.8141\n",
      "Epoch 148/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4764388.6432 - val_loss: 5262814.6643\n",
      "Epoch 149/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4759707.3366 - val_loss: 5255591.3862\n",
      "Epoch 150/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4756917.6749 - val_loss: 5259809.4848\n",
      "Epoch 151/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4756369.1068 - val_loss: 5256072.9892\n",
      "Epoch 152/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4752367.8925 - val_loss: 5249322.1823\n",
      "Epoch 153/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4752789.7880 - val_loss: 5268044.2406\n",
      "Epoch 154/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4749949.2028 - val_loss: 5275667.5716\n",
      "Epoch 155/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4751161.4648 - val_loss: 5249401.6899\n",
      "Epoch 156/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4749427.8009 - val_loss: 5255255.8019\n",
      "Epoch 157/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4744762.9235 - val_loss: 5247174.5120\n",
      "Epoch 158/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4745451.5091 - val_loss: 5246583.8087\n",
      "Epoch 159/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4741780.7200 - val_loss: 5245168.6763\n",
      "Epoch 160/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4740640.1739 - val_loss: 5247664.2098\n",
      "Epoch 161/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4739083.9760 - val_loss: 5243713.7711\n",
      "Epoch 162/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4736294.1034 - val_loss: 5243662.4653\n",
      "Epoch 163/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4735382.7095 - val_loss: 5244379.9964\n",
      "Epoch 164/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4734439.4693 - val_loss: 5239299.3676\n",
      "Epoch 165/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4733992.1422 - val_loss: 5240664.3593\n",
      "Epoch 166/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4733053.3134 - val_loss: 5252088.7280\n",
      "Epoch 167/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4730932.8631 - val_loss: 5241540.0821\n",
      "Epoch 168/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4729352.1997 - val_loss: 5245041.8970\n",
      "Epoch 169/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4727986.0144 - val_loss: 5244690.7973\n",
      "Epoch 170/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4724519.4589 - val_loss: 5233655.3269\n",
      "Epoch 171/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4724094.7049 - val_loss: 5230244.3611\n",
      "Epoch 172/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4723503.5582 - val_loss: 5230413.3315\n",
      "Epoch 173/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4721147.0548 - val_loss: 5228926.7874\n",
      "Epoch 174/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4722994.5117 - val_loss: 5229716.8144\n",
      "Epoch 175/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4719119.6415 - val_loss: 5228591.2384\n",
      "Epoch 176/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4718241.7048 - val_loss: 5223188.1437\n",
      "Epoch 177/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4713851.0325 - val_loss: 5222526.4213\n",
      "Epoch 178/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4715986.9258 - val_loss: 5237615.8464\n",
      "Epoch 179/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4717628.1827 - val_loss: 5219836.0176\n",
      "Epoch 180/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4712473.4174 - val_loss: 5219080.4007\n",
      "Epoch 181/5000\n",
      "40850/40850 [==============================] - 1s 25us/sample - loss: 4709758.8445 - val_loss: 5219787.8906\n",
      "Epoch 182/5000\n",
      "40850/40850 [==============================] - 1s 24us/sample - loss: 4707261.5119 - val_loss: 5226721.5127\n",
      "Epoch 183/5000\n",
      "40850/40850 [==============================] - 1s 23us/sample - loss: 4707894.2852 - val_loss: 5219998.5076\n",
      "Epoch 184/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 4708320.9107 - val_loss: 5210637.0913\n",
      "Epoch 185/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4706956.6019 - val_loss: 5210574.3579\n",
      "Epoch 186/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 4705821.3664 - val_loss: 5212920.8615\n",
      "Epoch 187/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4706567.8286 - val_loss: 5238417.3786\n",
      "Epoch 188/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4699590.9517 - val_loss: 5216583.8615\n",
      "Epoch 189/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4700227.4098 - val_loss: 5205053.6499\n",
      "Epoch 190/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4698129.7986 - val_loss: 5203351.8463\n",
      "Epoch 191/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4696467.8682 - val_loss: 5202483.8214\n",
      "Epoch 192/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4695706.9285 - val_loss: 5216710.6712\n",
      "Epoch 193/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4695935.6230 - val_loss: 5201562.6144\n",
      "Epoch 194/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4698315.4748 - val_loss: 5209869.4039\n",
      "Epoch 195/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4691436.1835 - val_loss: 5204010.3879\n",
      "Epoch 196/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4691764.7968 - val_loss: 5195555.5094\n",
      "Epoch 197/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4690030.3376 - val_loss: 5207588.2047\n",
      "Epoch 198/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4689484.8255 - val_loss: 5207125.0486\n",
      "Epoch 199/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4683984.8885 - val_loss: 5192560.8427\n",
      "Epoch 200/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4682370.0302 - val_loss: 5197063.6569\n",
      "Epoch 201/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4681268.5883 - val_loss: 5189139.2549\n",
      "Epoch 202/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4681349.0117 - val_loss: 5191768.0539\n",
      "Epoch 203/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4676328.2243 - val_loss: 5201592.9543\n",
      "Epoch 204/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4673733.4066 - val_loss: 5182784.6930\n",
      "Epoch 205/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4670478.1065 - val_loss: 5181034.0138\n",
      "Epoch 206/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4668314.6940 - val_loss: 5182065.5516\n",
      "Epoch 207/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4664562.9783 - val_loss: 5174958.8997\n",
      "Epoch 208/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4662946.0324 - val_loss: 5178376.2227\n",
      "Epoch 209/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4659673.9353 - val_loss: 5169396.8865\n",
      "Epoch 210/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4659355.6017 - val_loss: 5170652.9865\n",
      "Epoch 211/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4657684.1842 - val_loss: 5178735.1138\n",
      "Epoch 212/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4653884.4493 - val_loss: 5165934.2205\n",
      "Epoch 213/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4653307.0719 - val_loss: 5164564.5034\n",
      "Epoch 214/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4650031.4489 - val_loss: 5166730.9083\n",
      "Epoch 215/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4646987.4090 - val_loss: 5161284.7838\n",
      "Epoch 216/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4645400.2571 - val_loss: 5167520.0789\n",
      "Epoch 217/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4642348.5529 - val_loss: 5161113.0080\n",
      "Epoch 218/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4638497.0037 - val_loss: 5156321.9009\n",
      "Epoch 219/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4637589.6951 - val_loss: 5163502.8413\n",
      "Epoch 220/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4634399.9308 - val_loss: 5164124.9948\n",
      "Epoch 221/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4636889.7858 - val_loss: 5153844.7477\n",
      "Epoch 222/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4632798.3240 - val_loss: 5150800.6738\n",
      "Epoch 223/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4638477.6403 - val_loss: 5149074.1742\n",
      "Epoch 224/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4629799.9436 - val_loss: 5158389.5243\n",
      "Epoch 225/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4629150.9349 - val_loss: 5151832.3315\n",
      "Epoch 226/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4628287.4613 - val_loss: 5146092.6360\n",
      "Epoch 227/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4623369.2287 - val_loss: 5152441.7411\n",
      "Epoch 228/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4621237.2149 - val_loss: 5154320.3711\n",
      "Epoch 229/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4619795.9730 - val_loss: 5143116.8225\n",
      "Epoch 230/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4620258.0049 - val_loss: 5142587.0736\n",
      "Epoch 231/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4615642.6383 - val_loss: 5139844.4285\n",
      "Epoch 232/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4614859.6640 - val_loss: 5137915.8985\n",
      "Epoch 233/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4612135.8488 - val_loss: 5154854.6093\n",
      "Epoch 234/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4609100.5193 - val_loss: 5135617.5641\n",
      "Epoch 235/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4605928.4903 - val_loss: 5134764.3934\n",
      "Epoch 236/5000\n",
      "40850/40850 [==============================] - 1s 23us/sample - loss: 4604823.9669 - val_loss: 5137248.2118\n",
      "Epoch 237/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 4601424.3963 - val_loss: 5130646.8037\n",
      "Epoch 238/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 4602769.1743 - val_loss: 5130091.6663\n",
      "Epoch 239/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4596827.0181 - val_loss: 5127706.2530\n",
      "Epoch 240/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4596571.7847 - val_loss: 5125776.1487\n",
      "Epoch 241/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4591595.9693 - val_loss: 5127281.4291\n",
      "Epoch 242/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4592028.2036 - val_loss: 5124227.8243\n",
      "Epoch 243/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4587257.3947 - val_loss: 5130798.9827\n",
      "Epoch 244/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4584710.7863 - val_loss: 5126556.0363\n",
      "Epoch 245/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4581847.1210 - val_loss: 5115464.3388\n",
      "Epoch 246/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4581182.6738 - val_loss: 5120673.6495\n",
      "Epoch 247/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4575829.6617 - val_loss: 5113219.4433\n",
      "Epoch 248/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4573349.1364 - val_loss: 5114388.7407\n",
      "Epoch 249/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4568228.6961 - val_loss: 5108157.0596\n",
      "Epoch 250/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4569097.8698 - val_loss: 5105263.8077\n",
      "Epoch 251/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4568884.2923 - val_loss: 5104600.5345\n",
      "Epoch 252/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4566340.2116 - val_loss: 5103687.4913\n",
      "Epoch 253/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4562513.1195 - val_loss: 5100742.7956\n",
      "Epoch 254/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4560832.9300 - val_loss: 5097442.0158\n",
      "Epoch 255/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4557824.0410 - val_loss: 5094293.8348\n",
      "Epoch 256/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4555367.5696 - val_loss: 5093578.9128\n",
      "Epoch 257/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4554902.8278 - val_loss: 5106434.7218\n",
      "Epoch 258/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4552147.6833 - val_loss: 5087423.2031\n",
      "Epoch 259/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4551016.0032 - val_loss: 5091932.7240\n",
      "Epoch 260/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4546672.1910 - val_loss: 5092558.6410\n",
      "Epoch 261/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4547711.9410 - val_loss: 5089342.9616\n",
      "Epoch 262/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4542664.5169 - val_loss: 5084627.2388\n",
      "Epoch 263/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4540992.2900 - val_loss: 5083544.3879\n",
      "Epoch 264/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4539575.5582 - val_loss: 5083029.2729\n",
      "Epoch 265/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4538830.8841 - val_loss: 5081888.8926\n",
      "Epoch 266/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4537166.5733 - val_loss: 5092218.6918\n",
      "Epoch 267/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4532959.4536 - val_loss: 5076434.9006\n",
      "Epoch 268/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4535301.6883 - val_loss: 5076484.9246\n",
      "Epoch 269/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4529679.9619 - val_loss: 5076830.9643\n",
      "Epoch 270/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4534138.6785 - val_loss: 5073506.2352\n",
      "Epoch 271/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4526118.5786 - val_loss: 5074752.5621\n",
      "Epoch 272/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4527789.6208 - val_loss: 5081219.7387\n",
      "Epoch 273/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4524380.2888 - val_loss: 5073816.3754\n",
      "Epoch 274/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4521912.9843 - val_loss: 5067770.8063\n",
      "Epoch 275/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4518326.1792 - val_loss: 5064853.1040\n",
      "Epoch 276/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4516646.3330 - val_loss: 5066222.7987\n",
      "Epoch 277/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4514530.7507 - val_loss: 5060232.4469\n",
      "Epoch 278/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4510879.9737 - val_loss: 5066138.8883\n",
      "Epoch 279/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4510874.2692 - val_loss: 5061698.1656\n",
      "Epoch 280/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4508288.2586 - val_loss: 5068063.6385\n",
      "Epoch 281/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4506697.3929 - val_loss: 5056130.5361\n",
      "Epoch 282/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4505615.9670 - val_loss: 5055806.3782\n",
      "Epoch 283/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4501874.8062 - val_loss: 5062799.5224\n",
      "Epoch 284/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4500439.8066 - val_loss: 5050815.7161\n",
      "Epoch 285/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4495879.0382 - val_loss: 5052643.7395\n",
      "Epoch 286/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4493952.6007 - val_loss: 5051343.0048\n",
      "Epoch 287/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4492408.4434 - val_loss: 5046422.4723\n",
      "Epoch 288/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4489339.2121 - val_loss: 5044784.0510\n",
      "Epoch 289/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4484669.5798 - val_loss: 5044600.3651\n",
      "Epoch 290/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4487394.4081 - val_loss: 5043059.0428\n",
      "Epoch 291/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4482500.1870 - val_loss: 5042760.7485\n",
      "Epoch 292/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4479606.5990 - val_loss: 5036992.5073\n",
      "Epoch 293/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4479571.3669 - val_loss: 5070479.5035\n",
      "Epoch 294/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4473784.8600 - val_loss: 5049665.3978\n",
      "Epoch 295/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4468113.6749 - val_loss: 5044103.1257\n",
      "Epoch 296/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4467673.4208 - val_loss: 5034549.6064\n",
      "Epoch 297/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4463035.2893 - val_loss: 5042456.0030\n",
      "Epoch 298/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4463410.5389 - val_loss: 5034677.2221\n",
      "Epoch 299/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4463880.2301 - val_loss: 5033172.0015\n",
      "Epoch 300/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4460786.6356 - val_loss: 5046980.0728\n",
      "Epoch 301/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4456255.1462 - val_loss: 5025982.4607\n",
      "Epoch 302/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4452568.7179 - val_loss: 5031342.5386\n",
      "Epoch 303/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4450405.9491 - val_loss: 5028395.1690\n",
      "Epoch 304/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4447401.1744 - val_loss: 5022561.9027\n",
      "Epoch 305/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4444104.4408 - val_loss: 5026261.0085\n",
      "Epoch 306/5000\n",
      "40850/40850 [==============================] - 1s 27us/sample - loss: 4443838.2812 - val_loss: 5021034.0322\n",
      "Epoch 307/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 4441459.1041 - val_loss: 5016015.9032\n",
      "Epoch 308/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4439551.7839 - val_loss: 5018059.4935\n",
      "Epoch 309/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4436617.7571 - val_loss: 5044926.9621\n",
      "Epoch 310/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 4442477.4154 - val_loss: 5014427.0409\n",
      "Epoch 311/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4430445.3357 - val_loss: 5037739.3061\n",
      "Epoch 312/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4428074.7331 - val_loss: 5012135.4809\n",
      "Epoch 313/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4426254.1687 - val_loss: 5014367.4821\n",
      "Epoch 314/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4426961.0645 - val_loss: 5007405.5122\n",
      "Epoch 315/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4422730.2122 - val_loss: 5017244.7293\n",
      "Epoch 316/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4419473.9353 - val_loss: 5003468.9796\n",
      "Epoch 317/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4417129.8609 - val_loss: 5000919.1941\n",
      "Epoch 318/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4419080.6115 - val_loss: 5005578.9830\n",
      "Epoch 319/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4413501.1193 - val_loss: 5000722.7336\n",
      "Epoch 320/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4412468.4702 - val_loss: 5002776.3014\n",
      "Epoch 321/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4411073.4737 - val_loss: 5003202.8494\n",
      "Epoch 322/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4407849.1046 - val_loss: 5041115.1622\n",
      "Epoch 323/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4405093.2079 - val_loss: 5009371.7164\n",
      "Epoch 324/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4403878.7787 - val_loss: 5000026.1926\n",
      "Epoch 325/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4402097.9947 - val_loss: 4991746.5507\n",
      "Epoch 326/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4398892.4851 - val_loss: 5017539.8127\n",
      "Epoch 327/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4397054.4529 - val_loss: 4990806.6793\n",
      "Epoch 328/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4396008.9003 - val_loss: 4990563.5135\n",
      "Epoch 329/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4395086.1533 - val_loss: 4990688.1449\n",
      "Epoch 330/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4388945.0486 - val_loss: 4983594.9194\n",
      "Epoch 331/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4385949.4905 - val_loss: 4988308.0825\n",
      "Epoch 332/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4385430.0155 - val_loss: 4985811.9499\n",
      "Epoch 333/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4386241.2909 - val_loss: 4981626.9468\n",
      "Epoch 334/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4381214.6966 - val_loss: 4981631.6678\n",
      "Epoch 335/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4377482.6535 - val_loss: 4980983.7896\n",
      "Epoch 336/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4374872.6904 - val_loss: 4976713.2313\n",
      "Epoch 337/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4374774.3638 - val_loss: 4983268.9607\n",
      "Epoch 338/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4369175.9864 - val_loss: 4997712.6527\n",
      "Epoch 339/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4371474.4151 - val_loss: 4981787.2190\n",
      "Epoch 340/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4368366.7481 - val_loss: 5004424.9803\n",
      "Epoch 341/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4368728.2249 - val_loss: 4966925.2624\n",
      "Epoch 342/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4358395.5787 - val_loss: 4960824.7848\n",
      "Epoch 343/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4358771.3385 - val_loss: 4958624.2920\n",
      "Epoch 344/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4355960.1139 - val_loss: 4959745.0336\n",
      "Epoch 345/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4352366.1787 - val_loss: 4961833.1067\n",
      "Epoch 346/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4352874.7261 - val_loss: 4957608.1064\n",
      "Epoch 347/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4349822.0003 - val_loss: 4961585.5035\n",
      "Epoch 348/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4345775.7948 - val_loss: 4957431.2320\n",
      "Epoch 349/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4344869.5712 - val_loss: 4955436.6471\n",
      "Epoch 350/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4339932.3176 - val_loss: 4954231.9166\n",
      "Epoch 351/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4337883.6070 - val_loss: 4952402.7516\n",
      "Epoch 352/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4336760.0160 - val_loss: 4951764.7614\n",
      "Epoch 353/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4337040.3874 - val_loss: 4956095.9036\n",
      "Epoch 354/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4332187.3794 - val_loss: 4948348.2955\n",
      "Epoch 355/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4331321.5896 - val_loss: 4947954.4190\n",
      "Epoch 356/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4323427.7243 - val_loss: 4947793.2493\n",
      "Epoch 357/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4322626.5733 - val_loss: 4940172.3931\n",
      "Epoch 358/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4317715.5634 - val_loss: 4945411.1164\n",
      "Epoch 359/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4317911.8186 - val_loss: 4963032.5899\n",
      "Epoch 360/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4312621.4440 - val_loss: 4949862.4114\n",
      "Epoch 361/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4317064.8659 - val_loss: 4942773.3988\n",
      "Epoch 362/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4310715.3265 - val_loss: 4944730.6507\n",
      "Epoch 363/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4309547.3940 - val_loss: 4939782.9416\n",
      "Epoch 364/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4303773.5078 - val_loss: 4938062.6408\n",
      "Epoch 365/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4303079.8411 - val_loss: 4932480.6870\n",
      "Epoch 366/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4299843.1572 - val_loss: 4938289.4575\n",
      "Epoch 367/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4294610.9923 - val_loss: 4948000.8239\n",
      "Epoch 368/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4295118.9789 - val_loss: 4938145.3071\n",
      "Epoch 369/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4291899.3320 - val_loss: 4925212.4781\n",
      "Epoch 370/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4290961.4652 - val_loss: 4927100.1234\n",
      "Epoch 371/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4289621.2892 - val_loss: 4934876.0380\n",
      "Epoch 372/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4290706.4607 - val_loss: 4927712.8066\n",
      "Epoch 373/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4286286.3985 - val_loss: 4927348.3118\n",
      "Epoch 374/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4284459.0720 - val_loss: 4932846.5666\n",
      "Epoch 375/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4281285.9992 - val_loss: 4927439.7017\n",
      "Epoch 376/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4276454.8677 - val_loss: 4934134.8036\n",
      "Epoch 377/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4277298.9665 - val_loss: 4933447.7107\n",
      "Epoch 378/5000\n",
      "40850/40850 [==============================] - 1s 24us/sample - loss: 4271591.0848 - val_loss: 4934651.6917\n",
      "Epoch 379/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4274752.3083 - val_loss: 4929071.6562\n",
      "Epoch 380/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4271104.9602 - val_loss: 4927822.2572\n",
      "Epoch 381/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4268458.1043 - val_loss: 4922959.0924\n",
      "Epoch 382/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4269523.5353 - val_loss: 4928825.6921\n",
      "Epoch 383/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4265310.6186 - val_loss: 4925640.0869\n",
      "Epoch 384/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4267253.8494 - val_loss: 4917496.3550\n",
      "Epoch 385/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4262596.0968 - val_loss: 4926124.6312\n",
      "Epoch 386/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4260808.2852 - val_loss: 4924548.1449\n",
      "Epoch 387/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4258432.8979 - val_loss: 4922289.0226\n",
      "Epoch 388/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4255652.6005 - val_loss: 4922260.2914\n",
      "Epoch 389/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 4256107.4075 - val_loss: 4919240.0151\n",
      "Epoch 390/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4254743.9409 - val_loss: 4916799.5031\n",
      "Epoch 391/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4252246.6921 - val_loss: 4916524.8514\n",
      "Epoch 392/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4250955.6802 - val_loss: 4913960.2208\n",
      "Epoch 393/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4251512.8887 - val_loss: 4918489.4002\n",
      "Epoch 394/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4250302.8803 - val_loss: 4918417.0711\n",
      "Epoch 395/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4248397.8084 - val_loss: 4910230.0560\n",
      "Epoch 396/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4246558.4462 - val_loss: 4910938.2828\n",
      "Epoch 397/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4243313.1870 - val_loss: 4909303.1000\n",
      "Epoch 398/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4243893.4819 - val_loss: 4912157.4596\n",
      "Epoch 399/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4240676.5556 - val_loss: 4911999.7821\n",
      "Epoch 400/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4239554.8830 - val_loss: 4911649.8740\n",
      "Epoch 401/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 4240722.9785 - val_loss: 4926127.4869\n",
      "Epoch 402/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4236530.5931 - val_loss: 4906544.7176\n",
      "Epoch 403/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4234944.3799 - val_loss: 4914860.1825\n",
      "Epoch 404/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4233482.1936 - val_loss: 4909124.9193\n",
      "Epoch 405/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4231497.4777 - val_loss: 4905711.7076\n",
      "Epoch 406/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4229110.0171 - val_loss: 4907025.0908\n",
      "Epoch 407/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4226423.6829 - val_loss: 4917449.4142\n",
      "Epoch 408/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4227187.5832 - val_loss: 4913042.9324\n",
      "Epoch 409/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4225874.4872 - val_loss: 4907826.2949\n",
      "Epoch 410/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4225024.6267 - val_loss: 4904193.1147\n",
      "Epoch 411/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4222967.9181 - val_loss: 4903896.5770\n",
      "Epoch 412/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4220439.0514 - val_loss: 4902134.5210\n",
      "Epoch 413/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4217763.3030 - val_loss: 4904101.1683\n",
      "Epoch 414/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4215973.3888 - val_loss: 4905133.3225\n",
      "Epoch 415/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4214918.8531 - val_loss: 4897186.9513\n",
      "Epoch 416/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4212583.8938 - val_loss: 4907963.0417\n",
      "Epoch 417/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4211578.4022 - val_loss: 4904995.4115\n",
      "Epoch 418/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4208439.0489 - val_loss: 4901825.2717\n",
      "Epoch 419/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4204487.6985 - val_loss: 4906259.6366\n",
      "Epoch 420/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4209403.5660 - val_loss: 4899703.4689\n",
      "Epoch 421/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4204519.3204 - val_loss: 4892969.5297\n",
      "Epoch 422/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4205386.4347 - val_loss: 4896574.3935\n",
      "Epoch 423/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4200034.6881 - val_loss: 4894933.3426\n",
      "Epoch 424/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4203236.7872 - val_loss: 4894141.3995\n",
      "Epoch 425/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4195841.5888 - val_loss: 4899654.4137\n",
      "Epoch 426/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4194619.8424 - val_loss: 4891710.3838\n",
      "Epoch 427/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4195333.6855 - val_loss: 4913664.4368\n",
      "Epoch 428/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4190817.9774 - val_loss: 4898310.8192\n",
      "Epoch 429/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 4189813.1811 - val_loss: 4899784.3096\n",
      "Epoch 430/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4185917.5886 - val_loss: 4890808.4961\n",
      "Epoch 431/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4184451.9339 - val_loss: 4888785.4943\n",
      "Epoch 432/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4182266.3454 - val_loss: 4888164.6376\n",
      "Epoch 433/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4185106.4441 - val_loss: 4884078.4377\n",
      "Epoch 434/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4181706.2277 - val_loss: 4877950.2782\n",
      "Epoch 435/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4176233.9835 - val_loss: 4880824.6330\n",
      "Epoch 436/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4176553.4799 - val_loss: 4882950.6817\n",
      "Epoch 437/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4171533.2949 - val_loss: 4885022.8214\n",
      "Epoch 438/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4172048.3136 - val_loss: 4882571.6920\n",
      "Epoch 439/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4167184.4434 - val_loss: 4875759.6060\n",
      "Epoch 440/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4164573.7543 - val_loss: 4880637.4189\n",
      "Epoch 441/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4166658.5785 - val_loss: 4871125.2774\n",
      "Epoch 442/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4162404.9414 - val_loss: 4882618.1363\n",
      "Epoch 443/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4159201.3613 - val_loss: 4874829.4791\n",
      "Epoch 444/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4160475.1129 - val_loss: 4873753.2020\n",
      "Epoch 445/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4155332.1644 - val_loss: 4874191.6879\n",
      "Epoch 446/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4154160.1962 - val_loss: 4873514.7994\n",
      "Epoch 447/5000\n",
      "40850/40850 [==============================] - 1s 27us/sample - loss: 4152050.5502 - val_loss: 4874774.3809\n",
      "Epoch 448/5000\n",
      "40850/40850 [==============================] - 1s 23us/sample - loss: 4153399.2400 - val_loss: 4862067.5481\n",
      "Epoch 449/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 4151254.7601 - val_loss: 4867995.6835\n",
      "Epoch 450/5000\n",
      "40850/40850 [==============================] - 1s 23us/sample - loss: 4148340.5521 - val_loss: 4868867.7251\n",
      "Epoch 451/5000\n",
      "40850/40850 [==============================] - 1s 25us/sample - loss: 4145550.6895 - val_loss: 4871252.2192\n",
      "Epoch 452/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4148245.4024 - val_loss: 4864070.1353\n",
      "Epoch 453/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4141401.1367 - val_loss: 4868544.8680\n",
      "Epoch 454/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 4140328.5575 - val_loss: 4858760.0774\n",
      "Epoch 455/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4141700.2777 - val_loss: 4872639.5849\n",
      "Epoch 456/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4138202.4189 - val_loss: 4859176.3056\n",
      "Epoch 457/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4137730.7640 - val_loss: 4862909.7940\n",
      "Epoch 458/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4134824.3486 - val_loss: 4856971.8275\n",
      "Epoch 459/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4131790.2508 - val_loss: 4853983.6554\n",
      "Epoch 460/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4127886.3187 - val_loss: 4849709.1568\n",
      "Epoch 461/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4129536.9300 - val_loss: 4853147.1877\n",
      "Epoch 462/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4131657.0864 - val_loss: 4849715.4063\n",
      "Epoch 463/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4123456.5393 - val_loss: 4869977.9623\n",
      "Epoch 464/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4123338.8429 - val_loss: 4853205.6628\n",
      "Epoch 465/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4121598.7678 - val_loss: 4853211.2402\n",
      "Epoch 466/5000\n",
      "40850/40850 [==============================] - 1s 24us/sample - loss: 4117567.1231 - val_loss: 4851796.8075\n",
      "Epoch 467/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4118791.6979 - val_loss: 4840635.5292\n",
      "Epoch 468/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4113074.7903 - val_loss: 4837634.5148\n",
      "Epoch 469/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4109976.9930 - val_loss: 4844401.3861\n",
      "Epoch 470/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4111032.3506 - val_loss: 4842208.5004\n",
      "Epoch 471/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4108909.9089 - val_loss: 4831927.3609\n",
      "Epoch 472/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4107368.0088 - val_loss: 4830817.0482\n",
      "Epoch 473/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4101836.0402 - val_loss: 4829522.1168\n",
      "Epoch 474/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4098550.3985 - val_loss: 4828694.7732\n",
      "Epoch 475/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4098398.5484 - val_loss: 4826751.8300\n",
      "Epoch 476/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4094249.1867 - val_loss: 4822421.7004\n",
      "Epoch 477/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4092234.0999 - val_loss: 4831540.1435\n",
      "Epoch 478/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4089218.0543 - val_loss: 4814610.0874\n",
      "Epoch 479/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4088524.7472 - val_loss: 4810718.7267\n",
      "Epoch 480/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4083714.6011 - val_loss: 4825705.2487\n",
      "Epoch 481/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4083393.9001 - val_loss: 4817221.8814\n",
      "Epoch 482/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4084055.5532 - val_loss: 4803388.6716\n",
      "Epoch 483/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4079722.1292 - val_loss: 4821057.9653\n",
      "Epoch 484/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4077699.9964 - val_loss: 4801862.5195\n",
      "Epoch 485/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4077652.8959 - val_loss: 4805944.5328\n",
      "Epoch 486/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4072460.9451 - val_loss: 4818197.1880\n",
      "Epoch 487/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4071070.3976 - val_loss: 4801739.0963\n",
      "Epoch 488/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4068797.0692 - val_loss: 4798635.1311\n",
      "Epoch 489/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4072007.7301 - val_loss: 4793967.7679\n",
      "Epoch 490/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4068760.8223 - val_loss: 4799172.3255\n",
      "Epoch 491/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4067364.7185 - val_loss: 4793884.1016\n",
      "Epoch 492/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 4065251.0651 - val_loss: 4799234.0272\n",
      "Epoch 493/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4064464.7929 - val_loss: 4792126.0439\n",
      "Epoch 494/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4066725.8011 - val_loss: 4801755.4178\n",
      "Epoch 495/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4062250.3648 - val_loss: 4798505.2951\n",
      "Epoch 496/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4060062.3228 - val_loss: 4804917.9292\n",
      "Epoch 497/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4056714.4566 - val_loss: 4810166.0213\n",
      "Epoch 498/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 4057468.1955 - val_loss: 4814617.8516\n",
      "Epoch 499/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4061462.0267 - val_loss: 4790396.5489\n",
      "Epoch 500/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4053236.9068 - val_loss: 4798710.2385\n",
      "Epoch 501/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4054650.5611 - val_loss: 4787811.4777\n",
      "Epoch 502/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4051807.4398 - val_loss: 4790076.8566\n",
      "Epoch 503/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4057357.7272 - val_loss: 4804226.5448\n",
      "Epoch 504/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4052714.1723 - val_loss: 4802409.6152\n",
      "Epoch 505/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4050791.9352 - val_loss: 4799204.5479\n",
      "Epoch 506/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4052075.3159 - val_loss: 4798162.0556\n",
      "Epoch 507/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4046673.8582 - val_loss: 4798004.5195\n",
      "Epoch 508/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4045410.9336 - val_loss: 4784879.6565\n",
      "Epoch 509/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4042937.7834 - val_loss: 4791152.7782\n",
      "Epoch 510/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4043185.0278 - val_loss: 4789676.0748\n",
      "Epoch 511/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4041673.8060 - val_loss: 4789750.9171\n",
      "Epoch 512/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4040160.0615 - val_loss: 4823057.4417\n",
      "Epoch 513/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4045290.0032 - val_loss: 4789586.2231\n",
      "Epoch 514/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4039045.2623 - val_loss: 4788777.1551\n",
      "Epoch 515/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4040974.4226 - val_loss: 4787554.4796\n",
      "Epoch 516/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4038461.4697 - val_loss: 4790250.8634\n",
      "Epoch 517/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4037121.7405 - val_loss: 4801843.6285\n",
      "Epoch 518/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4035797.4866 - val_loss: 4789898.1051\n",
      "Epoch 519/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4033143.0307 - val_loss: 4783571.2703\n",
      "Epoch 520/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4033895.5730 - val_loss: 4792070.6007\n",
      "Epoch 521/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4034004.4467 - val_loss: 4790108.7902\n",
      "Epoch 522/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4031680.8041 - val_loss: 4786975.3731\n",
      "Epoch 523/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4030546.5732 - val_loss: 4789008.1931\n",
      "Epoch 524/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4029822.1388 - val_loss: 4781653.5264\n",
      "Epoch 525/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 4028877.1756 - val_loss: 4787673.6356\n",
      "Epoch 526/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4025525.5162 - val_loss: 4786542.0633\n",
      "Epoch 527/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4023700.9683 - val_loss: 4782980.7657\n",
      "Epoch 528/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4022479.8868 - val_loss: 4791551.5089\n",
      "Epoch 529/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4022658.4261 - val_loss: 4797049.4654\n",
      "Epoch 530/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4023596.5134 - val_loss: 4788364.5964\n",
      "Epoch 531/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4020119.6064 - val_loss: 4782730.6801\n",
      "Epoch 532/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4020117.6401 - val_loss: 4798426.4833\n",
      "Epoch 533/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4019333.9916 - val_loss: 4774875.7622\n",
      "Epoch 534/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4016652.3370 - val_loss: 4789659.4558\n",
      "Epoch 535/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4014519.2244 - val_loss: 4789034.3472\n",
      "Epoch 536/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4016595.2843 - val_loss: 4781320.4663\n",
      "Epoch 537/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4016568.4594 - val_loss: 4799927.4207\n",
      "Epoch 538/5000\n",
      "40850/40850 [==============================] - 1s 23us/sample - loss: 4013694.0082 - val_loss: 4788055.0344\n",
      "Epoch 539/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 4011114.1207 - val_loss: 4779777.1294\n",
      "Epoch 540/5000\n",
      "40850/40850 [==============================] - 1s 26us/sample - loss: 4006463.8108 - val_loss: 4776421.1826\n",
      "Epoch 541/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 4008956.5830 - val_loss: 4785666.7386\n",
      "Epoch 542/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 4007432.5990 - val_loss: 4780217.0680\n",
      "Epoch 543/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4005287.1909 - val_loss: 4778375.9392\n",
      "Epoch 544/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4007251.8729 - val_loss: 4785293.3554\n",
      "Epoch 545/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4004653.3875 - val_loss: 4780179.4834\n",
      "Epoch 546/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4005572.0673 - val_loss: 4780303.4245\n",
      "Epoch 547/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 4003094.7311 - val_loss: 4783473.8944\n",
      "Epoch 548/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 4000755.9913 - val_loss: 4785688.7672\n",
      "Epoch 549/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3996714.4902 - val_loss: 4775396.2826\n",
      "Epoch 550/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3999622.9256 - val_loss: 4780225.1564\n",
      "Epoch 551/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3998780.3358 - val_loss: 4778999.2341\n",
      "Epoch 552/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3996367.7476 - val_loss: 4784495.4824\n",
      "Epoch 553/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 4001161.0592 - val_loss: 4793716.0970\n",
      "Epoch 554/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3997458.6287 - val_loss: 4777943.1777\n",
      "Epoch 555/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3994132.6396 - val_loss: 4772103.7003\n",
      "Epoch 556/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3994659.1358 - val_loss: 4777920.9874\n",
      "Epoch 557/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3991644.5338 - val_loss: 4781418.1584\n",
      "Epoch 558/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3991559.8041 - val_loss: 4792385.9882\n",
      "Epoch 559/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3990579.7089 - val_loss: 4777631.1285\n",
      "Epoch 560/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3992490.5271 - val_loss: 4790326.7898\n",
      "Epoch 561/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3990180.8143 - val_loss: 4776152.9090\n",
      "Epoch 562/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3988934.6333 - val_loss: 4768786.0675\n",
      "Epoch 563/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3986879.2559 - val_loss: 4774575.7020\n",
      "Epoch 564/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3986007.0139 - val_loss: 4784298.1362\n",
      "Epoch 565/5000\n",
      "40850/40850 [==============================] - 1s 23us/sample - loss: 3989404.5394 - val_loss: 4791635.1883\n",
      "Epoch 566/5000\n",
      "40850/40850 [==============================] - 1s 23us/sample - loss: 3985778.6307 - val_loss: 4779260.8058\n",
      "Epoch 567/5000\n",
      "40850/40850 [==============================] - 1s 26us/sample - loss: 3984669.2441 - val_loss: 4787168.6952\n",
      "Epoch 568/5000\n",
      "40850/40850 [==============================] - 1s 25us/sample - loss: 3983934.2341 - val_loss: 4780181.3811\n",
      "Epoch 569/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3983719.6467 - val_loss: 4775661.1938\n",
      "Epoch 570/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3983825.3827 - val_loss: 4781223.9186\n",
      "Epoch 571/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3983504.0100 - val_loss: 4779383.2094\n",
      "Epoch 572/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3979641.9311 - val_loss: 4781762.0430\n",
      "Epoch 573/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3980509.5630 - val_loss: 4778345.8080\n",
      "Epoch 574/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3980506.9713 - val_loss: 4782754.8276\n",
      "Epoch 575/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3979781.1671 - val_loss: 4770429.9009\n",
      "Epoch 576/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3976084.0884 - val_loss: 4773821.9183\n",
      "Epoch 577/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3973917.2099 - val_loss: 4774416.8315\n",
      "Epoch 578/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3976716.4133 - val_loss: 4786043.2526\n",
      "Epoch 579/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3975082.5455 - val_loss: 4772111.7643\n",
      "Epoch 580/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3978029.7598 - val_loss: 4775643.6363\n",
      "Epoch 581/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3975469.4658 - val_loss: 4767129.8602\n",
      "Epoch 582/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3973327.2923 - val_loss: 4777375.8429\n",
      "Epoch 583/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3977352.7240 - val_loss: 4774119.7393\n",
      "Epoch 584/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3969900.8098 - val_loss: 4768078.8974\n",
      "Epoch 585/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3971633.3024 - val_loss: 4763732.3831\n",
      "Epoch 586/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3972062.3836 - val_loss: 4767288.7827\n",
      "Epoch 587/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3971522.2640 - val_loss: 4772495.8905\n",
      "Epoch 588/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3970317.4030 - val_loss: 4775885.1638\n",
      "Epoch 589/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3967811.0955 - val_loss: 4770283.5459\n",
      "Epoch 590/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3966305.4854 - val_loss: 4769894.3370\n",
      "Epoch 591/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3966552.7405 - val_loss: 4764546.4234\n",
      "Epoch 592/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3966550.9335 - val_loss: 4772624.5126\n",
      "Epoch 593/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3963920.6115 - val_loss: 4776300.2512\n",
      "Epoch 594/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3966983.7947 - val_loss: 4770704.4602\n",
      "Epoch 595/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3961662.3718 - val_loss: 4771768.0057\n",
      "Epoch 596/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3965874.6457 - val_loss: 4775782.7215\n",
      "Epoch 597/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3967281.7396 - val_loss: 4771209.1385\n",
      "Epoch 598/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3963680.3934 - val_loss: 4771642.5696\n",
      "Epoch 599/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3961217.4067 - val_loss: 4765400.0585\n",
      "Epoch 600/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3963299.4630 - val_loss: 4786665.4803\n",
      "Epoch 601/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3961656.9179 - val_loss: 4777821.4616\n",
      "Epoch 602/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3961658.0095 - val_loss: 4762509.7127\n",
      "Epoch 603/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3960654.5175 - val_loss: 4785463.5319\n",
      "Epoch 604/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3958767.0032 - val_loss: 4764662.7019\n",
      "Epoch 605/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3956174.3886 - val_loss: 4769606.6065\n",
      "Epoch 606/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3957379.6913 - val_loss: 4763561.3095\n",
      "Epoch 607/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3954942.6112 - val_loss: 4780397.1367\n",
      "Epoch 608/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3952817.2673 - val_loss: 4766767.7092\n",
      "Epoch 609/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3954760.1883 - val_loss: 4780250.7020\n",
      "Epoch 610/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3957317.5032 - val_loss: 4775228.5850\n",
      "Epoch 611/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3952511.4288 - val_loss: 4783078.4187\n",
      "Epoch 612/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3950762.5090 - val_loss: 4775294.3465\n",
      "Epoch 613/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3952266.8716 - val_loss: 4774606.8160\n",
      "Epoch 614/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3951431.6449 - val_loss: 4776258.0489\n",
      "Epoch 615/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3950006.5187 - val_loss: 4772360.3097\n",
      "Epoch 616/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3947067.8013 - val_loss: 4773420.3071\n",
      "Epoch 617/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3944539.6077 - val_loss: 4776734.1555\n",
      "Epoch 618/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3947734.3758 - val_loss: 4771744.5918\n",
      "Epoch 619/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3946735.0988 - val_loss: 4773319.3811\n",
      "Epoch 620/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3947106.0703 - val_loss: 4778082.7909\n",
      "Epoch 621/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3943393.1599 - val_loss: 4764342.8322\n",
      "Epoch 622/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3945246.9150 - val_loss: 4771740.0864\n",
      "Epoch 623/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3942612.7894 - val_loss: 4765485.5698\n",
      "Epoch 624/5000\n",
      "40850/40850 [==============================] - 1s 24us/sample - loss: 3940915.1800 - val_loss: 4768239.7901\n",
      "Epoch 625/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3940187.7911 - val_loss: 4772820.8696\n",
      "Epoch 626/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3941381.7005 - val_loss: 4772308.4100\n",
      "Epoch 627/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3938347.7666 - val_loss: 4795814.4212\n",
      "Epoch 628/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3939025.4852 - val_loss: 4769607.3843\n",
      "Epoch 629/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3941922.6791 - val_loss: 4768154.9590\n",
      "Epoch 630/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3939010.1422 - val_loss: 4768025.7988\n",
      "Epoch 631/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3937067.5266 - val_loss: 4773149.0491\n",
      "Epoch 632/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3935410.6583 - val_loss: 4773213.5299\n",
      "Epoch 633/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3931792.3411 - val_loss: 4773938.1143\n",
      "Epoch 634/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3935218.9055 - val_loss: 4784779.4816\n",
      "Epoch 635/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3933444.4077 - val_loss: 4766237.3098\n",
      "Epoch 636/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3931408.3175 - val_loss: 4761663.2637\n",
      "Epoch 637/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3932381.0127 - val_loss: 4763314.9764\n",
      "Epoch 638/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3931818.3613 - val_loss: 4776842.0207\n",
      "Epoch 639/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3928459.5776 - val_loss: 4778954.6381\n",
      "Epoch 640/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3928081.0748 - val_loss: 4772437.9872\n",
      "Epoch 641/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3929349.6233 - val_loss: 4786202.4595\n",
      "Epoch 642/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3929228.3061 - val_loss: 4764732.5096\n",
      "Epoch 643/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3929653.2544 - val_loss: 4769749.5058\n",
      "Epoch 644/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3927206.4203 - val_loss: 4790400.5387\n",
      "Epoch 645/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3924575.6329 - val_loss: 4762951.8983\n",
      "Epoch 646/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3923800.1854 - val_loss: 4766284.5641\n",
      "Epoch 647/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3924746.9877 - val_loss: 4762897.8691\n",
      "Epoch 648/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3923806.3811 - val_loss: 4772813.9681\n",
      "Epoch 649/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3922613.2137 - val_loss: 4765603.6400\n",
      "Epoch 650/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3921954.5372 - val_loss: 4758935.5337\n",
      "Epoch 651/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3922128.9868 - val_loss: 4766148.9060\n",
      "Epoch 652/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3922682.9500 - val_loss: 4768491.4812\n",
      "Epoch 653/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3919282.4688 - val_loss: 4767717.5153\n",
      "Epoch 654/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3919762.7122 - val_loss: 4766381.4433\n",
      "Epoch 655/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3918650.2286 - val_loss: 4765489.3030\n",
      "Epoch 656/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3919290.7329 - val_loss: 4774691.2378\n",
      "Epoch 657/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3917544.1149 - val_loss: 4762235.8337\n",
      "Epoch 658/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3922250.2130 - val_loss: 4772775.5725\n",
      "Epoch 659/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3915889.0184 - val_loss: 4773939.0134\n",
      "Epoch 660/5000\n",
      "40850/40850 [==============================] - 1s 24us/sample - loss: 3915491.2816 - val_loss: 4770951.0770\n",
      "Epoch 661/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3915391.2429 - val_loss: 4775165.2994\n",
      "Epoch 662/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3918140.3590 - val_loss: 4773508.9512\n",
      "Epoch 663/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3914068.6218 - val_loss: 4779036.6244\n",
      "Epoch 664/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3913311.3386 - val_loss: 4777920.4977\n",
      "Epoch 665/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3913445.0758 - val_loss: 4775982.9452\n",
      "Epoch 666/5000\n",
      "40850/40850 [==============================] - 1s 25us/sample - loss: 3914238.5279 - val_loss: 4774930.6487\n",
      "Epoch 667/5000\n",
      "40850/40850 [==============================] - 1s 25us/sample - loss: 3913611.2080 - val_loss: 4770953.2806\n",
      "Epoch 668/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3911635.1661 - val_loss: 4777217.1112\n",
      "Epoch 669/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3913255.8814 - val_loss: 4782116.7112\n",
      "Epoch 670/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3911990.5171 - val_loss: 4786640.8806\n",
      "Epoch 671/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3910603.0929 - val_loss: 4776374.9401\n",
      "Epoch 672/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3911872.9669 - val_loss: 4775555.5467\n",
      "Epoch 673/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3915309.6182 - val_loss: 4784384.0487\n",
      "Epoch 674/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3909397.9688 - val_loss: 4773761.0438\n",
      "Epoch 675/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3912446.1421 - val_loss: 4778202.3892\n",
      "Epoch 676/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3909881.2173 - val_loss: 4771813.7555\n",
      "Epoch 677/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3912082.7717 - val_loss: 4769715.4779\n",
      "Epoch 678/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3906292.0730 - val_loss: 4775366.6644\n",
      "Epoch 679/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3909731.7080 - val_loss: 4780336.5220\n",
      "Epoch 680/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3908013.6660 - val_loss: 4789254.2103\n",
      "Epoch 681/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3907917.0568 - val_loss: 4774021.3041\n",
      "Epoch 682/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3908334.1936 - val_loss: 4772157.3491\n",
      "Epoch 683/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3906128.0778 - val_loss: 4781838.8372\n",
      "Epoch 684/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3906011.5906 - val_loss: 4797281.0788\n",
      "Epoch 685/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3907273.4121 - val_loss: 4779071.0515\n",
      "Epoch 686/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3907099.8510 - val_loss: 4774535.6067\n",
      "Epoch 687/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3905730.4773 - val_loss: 4777081.8616\n",
      "Epoch 688/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3900549.8717 - val_loss: 4780446.2917\n",
      "Epoch 689/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3906049.1901 - val_loss: 4780048.6377\n",
      "Epoch 690/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3906764.2998 - val_loss: 4775363.6100\n",
      "Epoch 691/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3904778.2898 - val_loss: 4777446.5052\n",
      "Epoch 692/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3903572.4413 - val_loss: 4776943.2444\n",
      "Epoch 693/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3903562.8731 - val_loss: 4781248.1046\n",
      "Epoch 694/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3900772.9568 - val_loss: 4774577.2014\n",
      "Epoch 695/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3901398.2050 - val_loss: 4777975.2011\n",
      "Epoch 696/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3901813.8822 - val_loss: 4771852.9935\n",
      "Epoch 697/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3902433.5229 - val_loss: 4776780.8842\n",
      "Epoch 698/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3902095.7024 - val_loss: 4771613.9094\n",
      "Epoch 699/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3903712.7231 - val_loss: 4777543.3056\n",
      "Epoch 700/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3902653.9341 - val_loss: 4772218.0527\n",
      "Epoch 701/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3901853.4435 - val_loss: 4775641.4744\n",
      "Epoch 702/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3900336.8431 - val_loss: 4768748.2316\n",
      "Epoch 703/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3901460.1525 - val_loss: 4778468.9310\n",
      "Epoch 704/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3898813.8635 - val_loss: 4772713.7912\n",
      "Epoch 705/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3897991.5680 - val_loss: 4780624.5284\n",
      "Epoch 706/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3899039.4626 - val_loss: 4777618.9155\n",
      "Epoch 707/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3898542.6928 - val_loss: 4781782.1250\n",
      "Epoch 708/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3899912.6255 - val_loss: 4772352.7897\n",
      "Epoch 709/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3899999.6267 - val_loss: 4789449.5035\n",
      "Epoch 710/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3899999.6921 - val_loss: 4782719.8350\n",
      "Epoch 711/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3895841.2929 - val_loss: 4791661.7607\n",
      "Epoch 712/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3899187.5186 - val_loss: 4785750.1642\n",
      "Epoch 713/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3897396.2292 - val_loss: 4775994.9704\n",
      "Epoch 714/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3892368.6072 - val_loss: 4766745.5829\n",
      "Epoch 715/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3898340.7929 - val_loss: 4774843.5257\n",
      "Epoch 716/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3894236.1811 - val_loss: 4770324.4147\n",
      "Epoch 717/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3896329.8711 - val_loss: 4763690.0450\n",
      "Epoch 718/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3894219.6971 - val_loss: 4775066.4870\n",
      "Epoch 719/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3897215.4583 - val_loss: 4776367.7675\n",
      "Epoch 720/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3894994.9104 - val_loss: 4771318.2609\n",
      "Epoch 721/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3896844.4417 - val_loss: 4785713.5960\n",
      "Epoch 722/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3894698.4099 - val_loss: 4771153.8748\n",
      "Epoch 723/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3894477.8145 - val_loss: 4766813.8795\n",
      "Epoch 724/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3891403.9228 - val_loss: 4760352.9301\n",
      "Epoch 725/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3891457.3488 - val_loss: 4774433.7675\n",
      "Epoch 726/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3891155.3870 - val_loss: 4778915.2986\n",
      "Epoch 727/5000\n",
      "40850/40850 [==============================] - ETA: 0s - loss: 3911735.359 - 1s 17us/sample - loss: 3887951.0908 - val_loss: 4786051.9862\n",
      "Epoch 728/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3893624.6516 - val_loss: 4772244.1271\n",
      "Epoch 729/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3891155.3670 - val_loss: 4798339.1836\n",
      "Epoch 730/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3887151.5487 - val_loss: 4767194.7333\n",
      "Epoch 731/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3890090.2994 - val_loss: 4779809.3765\n",
      "Epoch 732/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3888341.8292 - val_loss: 4802616.2041\n",
      "Epoch 733/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3890467.1531 - val_loss: 4777921.6715\n",
      "Epoch 734/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3886548.0287 - val_loss: 4767246.7637\n",
      "Epoch 735/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3882277.1578 - val_loss: 4794292.3217\n",
      "Epoch 736/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3891317.8646 - val_loss: 4778587.3250\n",
      "Epoch 737/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3886648.7933 - val_loss: 4766606.1385\n",
      "Epoch 738/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3884413.8557 - val_loss: 4777178.3028\n",
      "Epoch 739/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3886189.1489 - val_loss: 4769379.5388\n",
      "Epoch 740/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3885485.1085 - val_loss: 4783854.1960\n",
      "Epoch 741/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3885789.5546 - val_loss: 4773041.7682\n",
      "Epoch 742/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3884618.4037 - val_loss: 4780969.7799\n",
      "Epoch 743/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3885328.9677 - val_loss: 4775329.8375\n",
      "Epoch 744/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3883871.4191 - val_loss: 4787199.6826\n",
      "Epoch 745/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3884297.9246 - val_loss: 4772904.2764\n",
      "Epoch 746/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3880718.3728 - val_loss: 4775531.3739\n",
      "Epoch 747/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3880835.0045 - val_loss: 4766486.3478\n",
      "Epoch 748/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3880737.1253 - val_loss: 4782235.5807\n",
      "Epoch 749/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3881539.5945 - val_loss: 4774311.9258\n",
      "Epoch 750/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3879351.5718 - val_loss: 4772503.9857\n",
      "Epoch 751/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3886045.0686 - val_loss: 4770076.4176\n",
      "Epoch 752/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3881443.4370 - val_loss: 4777975.6491\n",
      "Epoch 753/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3885247.6336 - val_loss: 4784632.5009\n",
      "Epoch 754/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3878679.8252 - val_loss: 4778969.8662\n",
      "Epoch 755/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3878496.3048 - val_loss: 4767893.1988\n",
      "Epoch 756/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3877035.0546 - val_loss: 4780226.7159\n",
      "Epoch 757/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3877240.0771 - val_loss: 4796282.1942\n",
      "Epoch 758/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3878817.4122 - val_loss: 4770920.9741\n",
      "Epoch 759/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3878839.0161 - val_loss: 4784646.5137\n",
      "Epoch 760/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3875907.6356 - val_loss: 4771654.3162\n",
      "Epoch 761/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3880833.4373 - val_loss: 4789684.2646\n",
      "Epoch 762/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3876050.4193 - val_loss: 4770411.5238\n",
      "Epoch 763/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3880634.8610 - val_loss: 4792326.9298\n",
      "Epoch 764/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3882577.8561 - val_loss: 4776260.6693\n",
      "Epoch 765/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3875689.2817 - val_loss: 4773262.0310\n",
      "Epoch 766/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3879473.6266 - val_loss: 4776237.9113\n",
      "Epoch 767/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3875173.6506 - val_loss: 4768881.2274\n",
      "Epoch 768/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3878157.4281 - val_loss: 4779570.7053\n",
      "Epoch 769/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3872833.3759 - val_loss: 4765733.4433\n",
      "Epoch 770/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3874133.5660 - val_loss: 4772932.7501\n",
      "Epoch 771/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3873023.5118 - val_loss: 4780143.3602\n",
      "Epoch 772/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3873909.9370 - val_loss: 4788390.7708\n",
      "Epoch 773/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3873450.4425 - val_loss: 4782048.0663\n",
      "Epoch 774/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3872505.5862 - val_loss: 4777664.4222\n",
      "Epoch 775/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3873400.2094 - val_loss: 4783447.5275\n",
      "Epoch 776/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3878886.5404 - val_loss: 4793484.1338\n",
      "Epoch 777/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3876493.3225 - val_loss: 4788583.3058\n",
      "Epoch 778/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3871418.1707 - val_loss: 4785224.6175\n",
      "Epoch 779/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3872983.5193 - val_loss: 4786351.5915\n",
      "Epoch 780/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3873605.5210 - val_loss: 4780918.5410\n",
      "Epoch 781/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3868286.8337 - val_loss: 4771938.3904\n",
      "Epoch 782/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3871301.9970 - val_loss: 4766572.5619\n",
      "Epoch 783/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3870994.8409 - val_loss: 4774399.1380\n",
      "Epoch 784/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3872418.7308 - val_loss: 4776672.7140\n",
      "Epoch 785/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3872372.2090 - val_loss: 4777402.2675\n",
      "Epoch 786/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3873875.0162 - val_loss: 4785410.9649\n",
      "Epoch 787/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3867250.2597 - val_loss: 4770255.1543\n",
      "Epoch 788/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3867176.8333 - val_loss: 4777844.0106\n",
      "Epoch 789/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3868821.5640 - val_loss: 4777046.8709\n",
      "Epoch 790/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3866866.4266 - val_loss: 4780021.9170\n",
      "Epoch 791/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3867978.2517 - val_loss: 4787194.6369\n",
      "Epoch 792/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3874842.2032 - val_loss: 4777301.6183\n",
      "Epoch 793/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3868388.5092 - val_loss: 4782076.2767\n",
      "Epoch 794/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3868371.9238 - val_loss: 4767391.4955\n",
      "Epoch 795/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3865953.7942 - val_loss: 4774439.2788\n",
      "Epoch 796/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3865818.6857 - val_loss: 4776807.6478\n",
      "Epoch 797/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3865499.7253 - val_loss: 4793322.3301\n",
      "Epoch 798/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3868907.4837 - val_loss: 4779877.9921\n",
      "Epoch 799/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3869197.0969 - val_loss: 4777601.0776\n",
      "Epoch 800/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3867029.3970 - val_loss: 4775665.6897\n",
      "Epoch 801/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3865710.2194 - val_loss: 4773432.6992\n",
      "Epoch 802/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3865485.1990 - val_loss: 4770884.6710\n",
      "Epoch 803/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3865462.5213 - val_loss: 4775327.2225\n",
      "Epoch 804/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3866326.3542 - val_loss: 4770414.2575\n",
      "Epoch 805/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3861773.1297 - val_loss: 4769488.1345\n",
      "Epoch 806/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3864555.6485 - val_loss: 4787598.6554\n",
      "Epoch 807/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3863557.0391 - val_loss: 4772280.5646\n",
      "Epoch 808/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3860950.4219 - val_loss: 4778994.7730\n",
      "Epoch 809/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3862041.4318 - val_loss: 4790288.6221\n",
      "Epoch 810/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3867143.5026 - val_loss: 4776552.7695\n",
      "Epoch 811/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3864811.0245 - val_loss: 4786031.6458\n",
      "Epoch 812/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3860483.9688 - val_loss: 4778266.8712\n",
      "Epoch 813/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3862876.2178 - val_loss: 4781692.5969\n",
      "Epoch 814/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3857563.0551 - val_loss: 4785548.1417\n",
      "Epoch 815/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3861867.7886 - val_loss: 4781494.6954\n",
      "Epoch 816/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3860935.5301 - val_loss: 4783093.6786\n",
      "Epoch 817/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3862318.7759 - val_loss: 4780637.0036\n",
      "Epoch 818/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3858626.6522 - val_loss: 4782501.1740\n",
      "Epoch 819/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3859629.0846 - val_loss: 4778309.8997\n",
      "Epoch 820/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3862322.3429 - val_loss: 4768424.0257\n",
      "Epoch 821/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3862348.6506 - val_loss: 4776922.9999\n",
      "Epoch 822/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3860981.7809 - val_loss: 4780574.0996\n",
      "Epoch 823/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3861715.7601 - val_loss: 4764859.5704\n",
      "Epoch 824/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3860202.7855 - val_loss: 4770601.7531\n",
      "Epoch 825/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3862577.0794 - val_loss: 4797624.0554\n",
      "Epoch 826/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3859730.8702 - val_loss: 4772632.9345\n",
      "Epoch 827/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3860364.6844 - val_loss: 4778971.8882\n",
      "Epoch 828/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3856903.8230 - val_loss: 4820656.0767\n",
      "Epoch 829/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3859774.7694 - val_loss: 4782068.3570\n",
      "Epoch 830/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3855410.5682 - val_loss: 4783279.6963\n",
      "Epoch 831/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3853248.8185 - val_loss: 4774138.2225\n",
      "Epoch 832/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3860028.8993 - val_loss: 4768698.6944\n",
      "Epoch 833/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3852904.3693 - val_loss: 4775557.5442\n",
      "Epoch 834/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3854947.2696 - val_loss: 4775127.7428\n",
      "Epoch 835/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3853882.6309 - val_loss: 4767762.2649\n",
      "Epoch 836/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3851531.1643 - val_loss: 4759827.5453\n",
      "Epoch 837/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3850015.6684 - val_loss: 4776474.3026\n",
      "Epoch 838/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3851011.6888 - val_loss: 4765921.6862\n",
      "Epoch 839/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3846198.8876 - val_loss: 4795086.5997\n",
      "Epoch 840/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3848283.5366 - val_loss: 4773600.5223\n",
      "Epoch 841/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3845872.0810 - val_loss: 4775522.7454\n",
      "Epoch 842/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3851730.1479 - val_loss: 4768778.2086\n",
      "Epoch 843/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3849310.6183 - val_loss: 4762354.9746\n",
      "Epoch 844/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3845103.4098 - val_loss: 4776693.5784\n",
      "Epoch 845/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3847047.7514 - val_loss: 4781634.9933\n",
      "Epoch 846/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3848201.4850 - val_loss: 4795420.4213\n",
      "Epoch 847/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3850762.2984 - val_loss: 4777774.5312\n",
      "Epoch 848/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3846152.1020 - val_loss: 4770992.7417\n",
      "Epoch 849/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3843645.4621 - val_loss: 4763268.2517\n",
      "Epoch 850/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3845452.6985 - val_loss: 4766946.2885\n",
      "Epoch 851/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3845081.6669 - val_loss: 4776445.1617\n",
      "Epoch 852/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3845192.8997 - val_loss: 4773755.6461\n",
      "Epoch 853/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3843240.9708 - val_loss: 4767995.5555\n",
      "Epoch 854/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3848699.6001 - val_loss: 4800250.3478\n",
      "Epoch 855/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3841450.0442 - val_loss: 4784455.0260\n",
      "Epoch 856/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3845259.4440 - val_loss: 4763570.2637\n",
      "Epoch 857/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3843338.6637 - val_loss: 4769209.5524\n",
      "Epoch 858/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3842847.2064 - val_loss: 4756997.1763\n",
      "Epoch 859/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3840331.2402 - val_loss: 4784803.9672\n",
      "Epoch 860/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3844252.4351 - val_loss: 4766929.2947\n",
      "Epoch 861/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3841181.4292 - val_loss: 4767051.7165\n",
      "Epoch 862/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3842256.5633 - val_loss: 4767911.4127\n",
      "Epoch 863/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3839725.7856 - val_loss: 4769834.0916\n",
      "Epoch 864/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3840158.4174 - val_loss: 4766025.3685\n",
      "Epoch 865/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3840438.7080 - val_loss: 4774639.3923\n",
      "Epoch 866/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3835931.8192 - val_loss: 4788578.0832\n",
      "Epoch 867/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3839934.1808 - val_loss: 4776191.1615\n",
      "Epoch 868/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3840402.1624 - val_loss: 4788775.9409\n",
      "Epoch 869/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3839701.8623 - val_loss: 4779805.4635\n",
      "Epoch 870/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3840628.4551 - val_loss: 4799623.9013\n",
      "Epoch 871/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3840118.8038 - val_loss: 4768978.8507\n",
      "Epoch 872/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3839151.4474 - val_loss: 4766639.9432\n",
      "Epoch 873/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3836028.2485 - val_loss: 4774295.2666\n",
      "Epoch 874/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3833753.5625 - val_loss: 4772765.6499\n",
      "Epoch 875/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3834562.2584 - val_loss: 4778051.5818\n",
      "Epoch 876/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3838880.7118 - val_loss: 4777730.7088\n",
      "Epoch 877/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3832133.3564 - val_loss: 4779495.3339\n",
      "Epoch 878/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3832377.3884 - val_loss: 4787027.3781\n",
      "Epoch 879/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3836555.1313 - val_loss: 4773866.1455\n",
      "Epoch 880/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3832578.4957 - val_loss: 4775960.2617\n",
      "Epoch 881/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3831849.7782 - val_loss: 4790162.0509\n",
      "Epoch 882/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3836509.1217 - val_loss: 4786491.0937\n",
      "Epoch 883/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3830941.0849 - val_loss: 4767095.1240\n",
      "Epoch 884/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3829175.9197 - val_loss: 4790701.9794\n",
      "Epoch 885/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3830443.1619 - val_loss: 4787341.0972\n",
      "Epoch 886/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3830312.6898 - val_loss: 4775437.1727\n",
      "Epoch 887/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3832310.1418 - val_loss: 4787675.5622\n",
      "Epoch 888/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3833634.0553 - val_loss: 4772268.0658\n",
      "Epoch 889/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3831138.7018 - val_loss: 4777156.9016\n",
      "Epoch 890/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3828020.4632 - val_loss: 4781506.2329\n",
      "Epoch 891/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3829008.6094 - val_loss: 4774001.4705\n",
      "Epoch 892/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3827379.5355 - val_loss: 4767107.8786\n",
      "Epoch 893/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3827583.9456 - val_loss: 4774064.2047\n",
      "Epoch 894/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3826935.4475 - val_loss: 4768927.2560\n",
      "Epoch 895/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3827785.6970 - val_loss: 4792398.8338\n",
      "Epoch 896/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3826377.5089 - val_loss: 4781471.7521\n",
      "Epoch 897/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3827839.7959 - val_loss: 4777191.7629\n",
      "Epoch 898/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3826846.9170 - val_loss: 4769934.5061\n",
      "Epoch 899/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3825113.0885 - val_loss: 4772731.3171\n",
      "Epoch 900/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3824078.9343 - val_loss: 4785945.5413\n",
      "Epoch 901/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3825293.4576 - val_loss: 4774585.7383\n",
      "Epoch 902/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3823356.3059 - val_loss: 4773746.0354\n",
      "Epoch 903/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3822465.2404 - val_loss: 4769284.3058\n",
      "Epoch 904/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3820963.5580 - val_loss: 4776195.1220\n",
      "Epoch 905/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3824773.4537 - val_loss: 4781286.6193\n",
      "Epoch 906/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3822187.0105 - val_loss: 4765069.6908\n",
      "Epoch 907/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3823653.8991 - val_loss: 4764489.6096\n",
      "Epoch 908/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3820549.9525 - val_loss: 4778529.3037\n",
      "Epoch 909/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3820671.9835 - val_loss: 4765302.9699\n",
      "Epoch 910/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3820959.9439 - val_loss: 4777060.4348\n",
      "Epoch 911/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3821770.2006 - val_loss: 4773398.7421\n",
      "Epoch 912/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3826544.7955 - val_loss: 4782908.2862\n",
      "Epoch 913/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3821502.3158 - val_loss: 4763746.3250\n",
      "Epoch 914/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3822531.6944 - val_loss: 4762246.3485\n",
      "Epoch 915/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3820216.0051 - val_loss: 4765176.1365\n",
      "Epoch 916/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3817604.9188 - val_loss: 4788754.5511\n",
      "Epoch 917/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3817205.3648 - val_loss: 4776274.6662\n",
      "Epoch 918/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3815020.3200 - val_loss: 4760667.9012\n",
      "Epoch 919/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3820005.7965 - val_loss: 4768833.6957\n",
      "Epoch 920/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3818063.2394 - val_loss: 4775032.0093\n",
      "Epoch 921/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3813593.6575 - val_loss: 4776256.1871\n",
      "Epoch 922/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3814524.3668 - val_loss: 4774518.0811\n",
      "Epoch 923/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3815679.3188 - val_loss: 4776262.0731\n",
      "Epoch 924/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3814493.4783 - val_loss: 4768269.3959\n",
      "Epoch 925/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3814598.0944 - val_loss: 4766965.4351\n",
      "Epoch 926/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3816646.8684 - val_loss: 4774200.7292\n",
      "Epoch 927/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3816724.6358 - val_loss: 4773533.9783\n",
      "Epoch 928/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3814877.7155 - val_loss: 4781399.4934\n",
      "Epoch 929/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3815974.4994 - val_loss: 4775860.4773\n",
      "Epoch 930/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3812160.8777 - val_loss: 4767119.2907\n",
      "Epoch 931/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3811342.2978 - val_loss: 4757787.3734\n",
      "Epoch 932/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3812016.7417 - val_loss: 4769928.6979\n",
      "Epoch 933/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3811759.8655 - val_loss: 4779068.9125\n",
      "Epoch 934/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3807803.9836 - val_loss: 4805355.1812\n",
      "Epoch 935/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3810262.0991 - val_loss: 4778691.6750\n",
      "Epoch 936/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3813516.2273 - val_loss: 4782388.8144\n",
      "Epoch 937/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3807622.1200 - val_loss: 4767996.5128\n",
      "Epoch 938/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3811726.3694 - val_loss: 4768515.5381\n",
      "Epoch 939/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3804299.3951 - val_loss: 4786887.4712\n",
      "Epoch 940/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3806388.6896 - val_loss: 4786471.6865\n",
      "Epoch 941/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3809014.4071 - val_loss: 4767767.2861\n",
      "Epoch 942/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3807119.4006 - val_loss: 4785095.5620\n",
      "Epoch 943/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3807557.1316 - val_loss: 4797241.9328\n",
      "Epoch 944/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3807673.6729 - val_loss: 4763826.7231\n",
      "Epoch 945/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3804359.5982 - val_loss: 4779872.5704\n",
      "Epoch 946/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3802694.3118 - val_loss: 4782646.6742\n",
      "Epoch 947/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3802920.4734 - val_loss: 4778736.3681\n",
      "Epoch 948/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3806362.3277 - val_loss: 4781355.5756\n",
      "Epoch 949/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3803348.9384 - val_loss: 4773333.2258\n",
      "Epoch 950/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3805973.1691 - val_loss: 4778039.4715\n",
      "Epoch 951/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3806495.6444 - val_loss: 4777106.3391\n",
      "Epoch 952/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3805222.8564 - val_loss: 4770160.8404\n",
      "Epoch 953/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3800338.8297 - val_loss: 4767914.8752\n",
      "Epoch 954/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3800319.7094 - val_loss: 4786163.4103\n",
      "Epoch 955/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3806345.8380 - val_loss: 4781167.8348\n",
      "Epoch 956/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3799779.7882 - val_loss: 4769134.5217\n",
      "Epoch 957/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3803566.0095 - val_loss: 4775584.4105\n",
      "Epoch 958/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3800945.9993 - val_loss: 4772416.4959\n",
      "Epoch 959/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3798891.8916 - val_loss: 4790845.9969\n",
      "Epoch 960/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3798285.5201 - val_loss: 4774923.7273\n",
      "Epoch 961/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3799630.9240 - val_loss: 4777534.7208\n",
      "Epoch 962/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3797629.6543 - val_loss: 4765461.0038\n",
      "Epoch 963/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3799625.9055 - val_loss: 4769980.8486\n",
      "Epoch 964/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3792825.8928 - val_loss: 4770426.0075\n",
      "Epoch 965/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3797152.5427 - val_loss: 4785410.2248\n",
      "Epoch 966/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3804815.2664 - val_loss: 4796737.4907\n",
      "Epoch 967/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3795014.2119 - val_loss: 4793679.0781\n",
      "Epoch 968/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3795500.8760 - val_loss: 4765788.0461\n",
      "Epoch 969/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3795548.0733 - val_loss: 4773701.3504\n",
      "Epoch 970/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3794016.9790 - val_loss: 4776513.1602\n",
      "Epoch 971/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3800744.7304 - val_loss: 4772907.7457\n",
      "Epoch 972/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3792825.1194 - val_loss: 4773438.3372\n",
      "Epoch 973/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3793072.4587 - val_loss: 4769932.1607\n",
      "Epoch 974/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3790938.7356 - val_loss: 4779241.1934\n",
      "Epoch 975/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3793466.9505 - val_loss: 4777637.4295\n",
      "Epoch 976/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3790974.2707 - val_loss: 4784980.6940\n",
      "Epoch 977/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3791739.6478 - val_loss: 4773869.9291\n",
      "Epoch 978/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3791472.4931 - val_loss: 4780650.7885\n",
      "Epoch 979/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3787913.5868 - val_loss: 4810537.0419\n",
      "Epoch 980/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3794863.3151 - val_loss: 4776073.5370\n",
      "Epoch 981/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3790710.1287 - val_loss: 4794707.8611\n",
      "Epoch 982/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3788881.0690 - val_loss: 4797649.9831\n",
      "Epoch 983/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3791405.2832 - val_loss: 4770658.8437\n",
      "Epoch 984/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3789434.5583 - val_loss: 4773046.4181\n",
      "Epoch 985/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3786919.1818 - val_loss: 4789267.3992\n",
      "Epoch 986/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3789924.7004 - val_loss: 4787881.6527\n",
      "Epoch 987/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3791598.3532 - val_loss: 4771720.0657\n",
      "Epoch 988/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3788221.0813 - val_loss: 4781168.1144\n",
      "Epoch 989/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3788840.4574 - val_loss: 4798498.9143\n",
      "Epoch 990/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3788310.8186 - val_loss: 4769856.1049\n",
      "Epoch 991/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3784925.2340 - val_loss: 4772408.8439\n",
      "Epoch 992/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3791053.5337 - val_loss: 4794433.4739\n",
      "Epoch 993/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3787854.7507 - val_loss: 4769472.1634\n",
      "Epoch 994/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3786051.0950 - val_loss: 4762015.2517\n",
      "Epoch 995/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3788108.6540 - val_loss: 4778404.2504\n",
      "Epoch 996/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3781572.9453 - val_loss: 4793179.5342\n",
      "Epoch 997/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3785874.9136 - val_loss: 4782945.7220\n",
      "Epoch 998/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3786082.3270 - val_loss: 4778951.3536\n",
      "Epoch 999/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3782924.8981 - val_loss: 4789949.3873\n",
      "Epoch 1000/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3783943.9435 - val_loss: 4771123.8237\n",
      "Epoch 1001/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3782028.3307 - val_loss: 4773152.5966\n",
      "Epoch 1002/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3785687.2197 - val_loss: 4775100.5237\n",
      "Epoch 1003/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3788432.9335 - val_loss: 4778841.5242\n",
      "Epoch 1004/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3782313.7214 - val_loss: 4771761.9740\n",
      "Epoch 1005/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3780584.3481 - val_loss: 4773568.3634\n",
      "Epoch 1006/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3782159.4402 - val_loss: 4773179.5822\n",
      "Epoch 1007/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3779168.4463 - val_loss: 4777864.7523\n",
      "Epoch 1008/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3779690.1916 - val_loss: 4792263.2447\n",
      "Epoch 1009/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3780189.4940 - val_loss: 4784451.0829\n",
      "Epoch 1010/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3780243.6117 - val_loss: 4779948.6943\n",
      "Epoch 1011/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3780264.6072 - val_loss: 4788645.5418\n",
      "Epoch 1012/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3780723.9155 - val_loss: 4785677.4462\n",
      "Epoch 1013/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3780160.4495 - val_loss: 4778650.4568\n",
      "Epoch 1014/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3781363.0258 - val_loss: 4789064.0552\n",
      "Epoch 1015/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3783582.5823 - val_loss: 4783566.1534\n",
      "Epoch 1016/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3778255.1905 - val_loss: 4776904.1620\n",
      "Epoch 1017/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3777372.3308 - val_loss: 4770817.8980\n",
      "Epoch 1018/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3778034.5198 - val_loss: 4779501.7491\n",
      "Epoch 1019/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3776251.8506 - val_loss: 4783219.4854\n",
      "Epoch 1020/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3779104.5545 - val_loss: 4776360.3511\n",
      "Epoch 1021/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3781336.1257 - val_loss: 4788354.1343\n",
      "Epoch 1022/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3775200.9346 - val_loss: 4780202.6763\n",
      "Epoch 1023/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3775616.8996 - val_loss: 4785118.0585\n",
      "Epoch 1024/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3780565.7494 - val_loss: 4775226.8551\n",
      "Epoch 1025/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3779184.8574 - val_loss: 4779919.7806\n",
      "Epoch 1026/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3774249.1487 - val_loss: 4796608.7096\n",
      "Epoch 1027/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3777277.4378 - val_loss: 4779147.3817\n",
      "Epoch 1028/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3778001.4404 - val_loss: 4789053.7483\n",
      "Epoch 1029/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3776944.1920 - val_loss: 4783004.9681\n",
      "Epoch 1030/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3776836.7161 - val_loss: 4790302.9196\n",
      "Epoch 1031/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3774261.5753 - val_loss: 4777829.5515\n",
      "Epoch 1032/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3776023.7647 - val_loss: 4789129.0100\n",
      "Epoch 1033/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3776161.6743 - val_loss: 4802165.3242\n",
      "Epoch 1034/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3773232.1508 - val_loss: 4773518.0176\n",
      "Epoch 1035/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3776987.1474 - val_loss: 4782815.7083\n",
      "Epoch 1036/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3773171.6648 - val_loss: 4779031.5346\n",
      "Epoch 1037/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3774455.8443 - val_loss: 4765127.4347\n",
      "Epoch 1038/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3772021.7814 - val_loss: 4790915.5112\n",
      "Epoch 1039/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3774510.5789 - val_loss: 4808274.1219\n",
      "Epoch 1040/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3778126.6820 - val_loss: 4775897.7745\n",
      "Epoch 1041/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3772304.4050 - val_loss: 4779272.9149\n",
      "Epoch 1042/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3772273.1709 - val_loss: 4774381.5839\n",
      "Epoch 1043/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3772512.3345 - val_loss: 4786629.4354\n",
      "Epoch 1044/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3772373.6145 - val_loss: 4777597.5827\n",
      "Epoch 1045/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3770532.3496 - val_loss: 4792516.0743\n",
      "Epoch 1046/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3771200.4760 - val_loss: 4793143.2189\n",
      "Epoch 1047/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3767650.6166 - val_loss: 4782095.9954\n",
      "Epoch 1048/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3767191.5082 - val_loss: 4788666.3934\n",
      "Epoch 1049/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3769242.4127 - val_loss: 4792691.6897\n",
      "Epoch 1050/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3768390.5206 - val_loss: 4782027.4674\n",
      "Epoch 1051/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3769576.3079 - val_loss: 4781582.2630\n",
      "Epoch 1052/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3768818.8169 - val_loss: 4780799.0923\n",
      "Epoch 1053/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3768226.2776 - val_loss: 4781613.8318\n",
      "Epoch 1054/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3770766.5910 - val_loss: 4784599.3562\n",
      "Epoch 1055/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3770649.6578 - val_loss: 4777089.2120\n",
      "Epoch 1056/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3770484.6397 - val_loss: 4783408.9680\n",
      "Epoch 1057/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3767338.5388 - val_loss: 4793548.5596\n",
      "Epoch 1058/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3768548.5690 - val_loss: 4787197.3461\n",
      "Epoch 1059/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3770638.7735 - val_loss: 4785125.8071\n",
      "Epoch 1060/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3767404.8492 - val_loss: 4795974.1722\n",
      "Epoch 1061/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3766807.2993 - val_loss: 4786567.6997\n",
      "Epoch 1062/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3766802.9780 - val_loss: 4779104.0648\n",
      "Epoch 1063/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3766004.5891 - val_loss: 4778657.9605\n",
      "Epoch 1064/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3769233.5020 - val_loss: 4779207.9677\n",
      "Epoch 1065/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3764277.1003 - val_loss: 4785659.0123\n",
      "Epoch 1066/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3768021.8808 - val_loss: 4787487.6951\n",
      "Epoch 1067/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3765966.9676 - val_loss: 4777574.0626\n",
      "Epoch 1068/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3766762.6046 - val_loss: 4788060.6686\n",
      "Epoch 1069/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3763969.3380 - val_loss: 4789878.7179\n",
      "Epoch 1070/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3763391.6357 - val_loss: 4794292.6575\n",
      "Epoch 1071/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3762894.5870 - val_loss: 4786383.8316\n",
      "Epoch 1072/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3763241.5150 - val_loss: 4789281.4139\n",
      "Epoch 1073/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3766507.3055 - val_loss: 4778846.1737\n",
      "Epoch 1074/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3764415.6106 - val_loss: 4794008.1032\n",
      "Epoch 1075/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3761046.5052 - val_loss: 4791220.2515\n",
      "Epoch 1076/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3763206.7776 - val_loss: 4788258.5517\n",
      "Epoch 1077/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3763444.2107 - val_loss: 4780589.5499\n",
      "Epoch 1078/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3766870.3770 - val_loss: 4789623.7002\n",
      "Epoch 1079/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3763431.8363 - val_loss: 4790756.5385\n",
      "Epoch 1080/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3762546.5866 - val_loss: 4804224.3884\n",
      "Epoch 1081/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3761106.8988 - val_loss: 4779712.2688\n",
      "Epoch 1082/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3762014.9223 - val_loss: 4778965.8943\n",
      "Epoch 1083/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3758892.6468 - val_loss: 4811038.0950\n",
      "Epoch 1084/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3762281.0895 - val_loss: 4785378.6022\n",
      "Epoch 1085/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3762120.2432 - val_loss: 4789383.8391\n",
      "Epoch 1086/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3759548.9788 - val_loss: 4781212.3654\n",
      "Epoch 1087/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3760097.1417 - val_loss: 4790542.1334\n",
      "Epoch 1088/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3761414.4282 - val_loss: 4797739.6496\n",
      "Epoch 1089/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3758048.5500 - val_loss: 4789093.4035\n",
      "Epoch 1090/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3758438.6391 - val_loss: 4782763.5579\n",
      "Epoch 1091/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3759927.9625 - val_loss: 4780173.1387\n",
      "Epoch 1092/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3758217.1510 - val_loss: 4804158.4184\n",
      "Epoch 1093/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3762696.1620 - val_loss: 4783248.2706\n",
      "Epoch 1094/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3761659.1296 - val_loss: 4783844.9873\n",
      "Epoch 1095/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3762639.6871 - val_loss: 4781015.2884\n",
      "Epoch 1096/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3759980.8911 - val_loss: 4779803.7750\n",
      "Epoch 1097/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3755932.3634 - val_loss: 4800107.7141\n",
      "Epoch 1098/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3759858.6125 - val_loss: 4779339.7098\n",
      "Epoch 1099/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3756452.7646 - val_loss: 4796309.3470\n",
      "Epoch 1100/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3758246.4504 - val_loss: 4789139.4447\n",
      "Epoch 1101/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3759148.1064 - val_loss: 4790072.0001\n",
      "Epoch 1102/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3759328.8055 - val_loss: 4784896.6868\n",
      "Epoch 1103/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3755526.5509 - val_loss: 4778185.0929\n",
      "Epoch 1104/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3757103.7464 - val_loss: 4787942.0530\n",
      "Epoch 1105/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3758918.4011 - val_loss: 4782666.1182\n",
      "Epoch 1106/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3758137.7146 - val_loss: 4819461.2006\n",
      "Epoch 1107/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3757619.9870 - val_loss: 4792858.5300\n",
      "Epoch 1108/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3759039.8727 - val_loss: 4791561.8305\n",
      "Epoch 1109/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3756138.4659 - val_loss: 4803313.6097\n",
      "Epoch 1110/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3762030.7917 - val_loss: 4798769.0254\n",
      "Epoch 1111/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3755257.8754 - val_loss: 4795398.4782\n",
      "Epoch 1112/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3756844.7575 - val_loss: 4787339.1473\n",
      "Epoch 1113/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3757009.2335 - val_loss: 4799582.4860\n",
      "Epoch 1114/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3755697.0100 - val_loss: 4786399.1004\n",
      "Epoch 1115/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3759134.9232 - val_loss: 4786002.3002\n",
      "Epoch 1116/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3755536.6678 - val_loss: 4787551.9402\n",
      "Epoch 1117/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3754533.4829 - val_loss: 4797378.2376\n",
      "Epoch 1118/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3755614.7257 - val_loss: 4776151.7649\n",
      "Epoch 1119/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3754883.2207 - val_loss: 4784453.3643\n",
      "Epoch 1120/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3754056.3899 - val_loss: 4784804.9320\n",
      "Epoch 1121/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3751599.6588 - val_loss: 4784034.0310\n",
      "Epoch 1122/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3754507.8169 - val_loss: 4779682.9509\n",
      "Epoch 1123/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3752358.1920 - val_loss: 4786750.2802\n",
      "Epoch 1124/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3752354.9093 - val_loss: 4792396.8784\n",
      "Epoch 1125/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3750313.8022 - val_loss: 4777112.6014\n",
      "Epoch 1126/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3747888.2539 - val_loss: 4781921.6196\n",
      "Epoch 1127/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3753916.0334 - val_loss: 4774881.3918\n",
      "Epoch 1128/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3755832.4531 - val_loss: 4831664.8641\n",
      "Epoch 1129/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3757135.0845 - val_loss: 4791231.4531\n",
      "Epoch 1130/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3751334.4261 - val_loss: 4798020.2137\n",
      "Epoch 1131/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3748614.1545 - val_loss: 4797751.7462\n",
      "Epoch 1132/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3752562.1687 - val_loss: 4796051.2046\n",
      "Epoch 1133/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3749636.6567 - val_loss: 4794400.9036\n",
      "Epoch 1134/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3752536.6698 - val_loss: 4793837.6230\n",
      "Epoch 1135/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3749878.0783 - val_loss: 4779389.7445\n",
      "Epoch 1136/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3747894.9322 - val_loss: 4782164.3117\n",
      "Epoch 1137/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3751678.5104 - val_loss: 4795703.8927\n",
      "Epoch 1138/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3751906.1200 - val_loss: 4789364.6109\n",
      "Epoch 1139/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3751131.1600 - val_loss: 4794980.0520\n",
      "Epoch 1140/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3752412.2632 - val_loss: 4802356.0647\n",
      "Epoch 1141/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3747823.7647 - val_loss: 4793510.5206\n",
      "Epoch 1142/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3750160.9536 - val_loss: 4784401.7954\n",
      "Epoch 1143/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3747935.7871 - val_loss: 4799753.0979\n",
      "Epoch 1144/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3750566.7917 - val_loss: 4797374.6626\n",
      "Epoch 1145/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3750292.5250 - val_loss: 4795386.8599\n",
      "Epoch 1146/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3750534.2609 - val_loss: 4795195.2531\n",
      "Epoch 1147/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3748791.2405 - val_loss: 4791366.5298\n",
      "Epoch 1148/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3745216.7442 - val_loss: 4791955.0228\n",
      "Epoch 1149/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3746180.1747 - val_loss: 4794560.2389\n",
      "Epoch 1150/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3751915.5027 - val_loss: 4804882.5853\n",
      "Epoch 1151/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3748082.0574 - val_loss: 4791843.6019\n",
      "Epoch 1152/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3746901.6604 - val_loss: 4789616.8313\n",
      "Epoch 1153/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3747647.4273 - val_loss: 4794049.6689\n",
      "Epoch 1154/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3744497.0280 - val_loss: 4787557.2492\n",
      "Epoch 1155/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3746715.7983 - val_loss: 4792554.4522\n",
      "Epoch 1156/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3743934.0779 - val_loss: 4780099.4347\n",
      "Epoch 1157/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3744848.4723 - val_loss: 4801475.8779\n",
      "Epoch 1158/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3747922.2038 - val_loss: 4789922.1370\n",
      "Epoch 1159/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3747289.4565 - val_loss: 4788189.3829\n",
      "Epoch 1160/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3746654.5972 - val_loss: 4805507.9381\n",
      "Epoch 1161/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3745316.6785 - val_loss: 4792871.3599\n",
      "Epoch 1162/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3744056.2442 - val_loss: 4795926.4455\n",
      "Epoch 1163/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3741271.1431 - val_loss: 4786838.8784\n",
      "Epoch 1164/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3747272.8606 - val_loss: 4793663.4056\n",
      "Epoch 1165/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3744690.6525 - val_loss: 4800510.8623\n",
      "Epoch 1166/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3745612.3029 - val_loss: 4796467.3762\n",
      "Epoch 1167/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3742362.4513 - val_loss: 4794240.0242\n",
      "Epoch 1168/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3743782.9796 - val_loss: 4802135.3776\n",
      "Epoch 1169/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3741600.5882 - val_loss: 4778352.8960\n",
      "Epoch 1170/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3740122.0338 - val_loss: 4799502.9630\n",
      "Epoch 1171/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3744868.0294 - val_loss: 4795219.0952\n",
      "Epoch 1172/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3747700.8502 - val_loss: 4791923.5642\n",
      "Epoch 1173/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3741595.5886 - val_loss: 4807710.2881\n",
      "Epoch 1174/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3744673.2096 - val_loss: 4807247.5740\n",
      "Epoch 1175/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3742212.6637 - val_loss: 4797071.8896\n",
      "Epoch 1176/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3739770.7681 - val_loss: 4834144.1729\n",
      "Epoch 1177/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3747445.9724 - val_loss: 4805187.8834\n",
      "Epoch 1178/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3738049.3653 - val_loss: 4808720.2004\n",
      "Epoch 1179/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3741459.8332 - val_loss: 4791078.9463\n",
      "Epoch 1180/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3741112.4788 - val_loss: 4804210.7598\n",
      "Epoch 1181/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3743609.2526 - val_loss: 4788480.4777\n",
      "Epoch 1182/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3745274.8676 - val_loss: 4800817.5953\n",
      "Epoch 1183/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3740553.9918 - val_loss: 4811101.6257\n",
      "Epoch 1184/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3744957.3201 - val_loss: 4790498.6912\n",
      "Epoch 1185/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3740400.8317 - val_loss: 4801295.6333\n",
      "Epoch 1186/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3742362.3156 - val_loss: 4796074.3756\n",
      "Epoch 1187/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3739958.6314 - val_loss: 4783154.3884\n",
      "Epoch 1188/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3740375.4656 - val_loss: 4790138.5899\n",
      "Epoch 1189/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3742519.2981 - val_loss: 4800521.0128\n",
      "Epoch 1190/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3740131.8635 - val_loss: 4796732.6518\n",
      "Epoch 1191/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3743175.9284 - val_loss: 4794741.4605\n",
      "Epoch 1192/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3741754.6280 - val_loss: 4791111.8681\n",
      "Epoch 1193/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3738740.0793 - val_loss: 4787216.1345\n",
      "Epoch 1194/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3746840.8928 - val_loss: 4804791.6874\n",
      "Epoch 1195/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3740562.4254 - val_loss: 4799111.5427\n",
      "Epoch 1196/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3743386.7206 - val_loss: 4803015.1774\n",
      "Epoch 1197/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3735680.3835 - val_loss: 4798513.9756\n",
      "Epoch 1198/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3734219.7406 - val_loss: 4794431.8786\n",
      "Epoch 1199/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3737208.4246 - val_loss: 4786858.2079\n",
      "Epoch 1200/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3735943.1912 - val_loss: 4793018.6159\n",
      "Epoch 1201/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3735269.1080 - val_loss: 4804986.0126\n",
      "Epoch 1202/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3734912.3948 - val_loss: 4793136.6902\n",
      "Epoch 1203/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3736372.7490 - val_loss: 4811537.0938\n",
      "Epoch 1204/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3739737.1667 - val_loss: 4791910.4079\n",
      "Epoch 1205/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3737750.7039 - val_loss: 4789720.6325\n",
      "Epoch 1206/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3735676.5719 - val_loss: 4792494.1945\n",
      "Epoch 1207/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3736412.3433 - val_loss: 4801982.7989\n",
      "Epoch 1208/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3734556.0244 - val_loss: 4802519.1413\n",
      "Epoch 1209/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3735878.7128 - val_loss: 4791312.5488\n",
      "Epoch 1210/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3734220.6212 - val_loss: 4795847.5073\n",
      "Epoch 1211/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3734752.5967 - val_loss: 4815095.7957\n",
      "Epoch 1212/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3734490.7331 - val_loss: 4806858.4086\n",
      "Epoch 1213/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3735556.2352 - val_loss: 4799784.4217\n",
      "Epoch 1214/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3734805.1331 - val_loss: 4805612.8234\n",
      "Epoch 1215/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3733073.6767 - val_loss: 4802782.6651\n",
      "Epoch 1216/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3734211.0388 - val_loss: 4790868.7097\n",
      "Epoch 1217/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3732688.7950 - val_loss: 4789440.4038\n",
      "Epoch 1218/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3742052.6036 - val_loss: 4792207.5162\n",
      "Epoch 1219/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3735902.6197 - val_loss: 4785210.9057\n",
      "Epoch 1220/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3733812.4902 - val_loss: 4789544.2251\n",
      "Epoch 1221/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3734290.2053 - val_loss: 4796575.4038\n",
      "Epoch 1222/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3735558.5896 - val_loss: 4806878.9924\n",
      "Epoch 1223/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3733491.7343 - val_loss: 4801911.6802\n",
      "Epoch 1224/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3734324.4415 - val_loss: 4799145.7953\n",
      "Epoch 1225/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3734765.0822 - val_loss: 4801070.8427\n",
      "Epoch 1226/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3729513.1964 - val_loss: 4826816.4959\n",
      "Epoch 1227/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3734945.2592 - val_loss: 4788913.9419\n",
      "Epoch 1228/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3735862.1423 - val_loss: 4792427.7471\n",
      "Epoch 1229/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3732224.5023 - val_loss: 4798871.6813\n",
      "Epoch 1230/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3731130.8753 - val_loss: 4789859.5435\n",
      "Epoch 1231/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3730996.7866 - val_loss: 4783358.4678\n",
      "Epoch 1232/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3733480.1783 - val_loss: 4786652.4829\n",
      "Epoch 1233/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3731740.9823 - val_loss: 4795206.2438\n",
      "Epoch 1234/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3732815.4020 - val_loss: 4787280.1573\n",
      "Epoch 1235/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3728815.5541 - val_loss: 4788128.0509\n",
      "Epoch 1236/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3731557.2705 - val_loss: 4797668.1677\n",
      "Epoch 1237/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3729977.2253 - val_loss: 4788375.3664\n",
      "Epoch 1238/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3728765.1832 - val_loss: 4795673.0995\n",
      "Epoch 1239/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3729547.8432 - val_loss: 4794497.8498\n",
      "Epoch 1240/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3729647.0009 - val_loss: 4793011.9166\n",
      "Epoch 1241/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3731611.8778 - val_loss: 4787890.7398\n",
      "Epoch 1242/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3728771.5453 - val_loss: 4798159.8886\n",
      "Epoch 1243/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3724063.1629 - val_loss: 4797537.6534\n",
      "Epoch 1244/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3728850.0320 - val_loss: 4800852.0999\n",
      "Epoch 1245/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3726998.4669 - val_loss: 4787798.3844\n",
      "Epoch 1246/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3727073.5018 - val_loss: 4783098.2762\n",
      "Epoch 1247/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3727682.4230 - val_loss: 4794184.4267\n",
      "Epoch 1248/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3724712.0733 - val_loss: 4794008.2167\n",
      "Epoch 1249/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3727334.1708 - val_loss: 4792450.8716\n",
      "Epoch 1250/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3724792.5192 - val_loss: 4798262.3115\n",
      "Epoch 1251/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3723136.8053 - val_loss: 4795531.2219\n",
      "Epoch 1252/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3726321.7074 - val_loss: 4801263.6434\n",
      "Epoch 1253/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3726595.8888 - val_loss: 4784326.0408\n",
      "Epoch 1254/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3722979.5387 - val_loss: 4803198.4359\n",
      "Epoch 1255/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3722938.2939 - val_loss: 4802728.8096\n",
      "Epoch 1256/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3724771.6313 - val_loss: 4804483.9962\n",
      "Epoch 1257/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3721780.9438 - val_loss: 4802046.7386\n",
      "Epoch 1258/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3722872.1058 - val_loss: 4784443.9071\n",
      "Epoch 1259/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3723819.2612 - val_loss: 4799989.2298\n",
      "Epoch 1260/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3723480.2912 - val_loss: 4813986.8922\n",
      "Epoch 1261/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3723205.9147 - val_loss: 4790519.2270\n",
      "Epoch 1262/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3720295.4234 - val_loss: 4794658.5348\n",
      "Epoch 1263/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3720168.4679 - val_loss: 4791546.2611\n",
      "Epoch 1264/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3725705.6117 - val_loss: 4806960.7174\n",
      "Epoch 1265/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3724065.0011 - val_loss: 4791781.4473\n",
      "Epoch 1266/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3721935.9190 - val_loss: 4807504.0308\n",
      "Epoch 1267/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3718961.3101 - val_loss: 4788095.7039\n",
      "Epoch 1268/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3722622.0000 - val_loss: 4781102.8383\n",
      "Epoch 1269/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3722373.7540 - val_loss: 4791549.0355\n",
      "Epoch 1270/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3724258.9465 - val_loss: 4793443.0107\n",
      "Epoch 1271/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3721139.9338 - val_loss: 4792241.4364\n",
      "Epoch 1272/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3720177.1882 - val_loss: 4800770.9611\n",
      "Epoch 1273/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3723151.1116 - val_loss: 4795149.8537\n",
      "Epoch 1274/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3719922.5562 - val_loss: 4796053.1819\n",
      "Epoch 1275/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3721130.3802 - val_loss: 4801903.0442\n",
      "Epoch 1276/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3721305.9342 - val_loss: 4805079.6223\n",
      "Epoch 1277/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3721230.5096 - val_loss: 4792352.4233\n",
      "Epoch 1278/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3718282.3482 - val_loss: 4780006.3413\n",
      "Epoch 1279/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3717424.4963 - val_loss: 4793060.9762\n",
      "Epoch 1280/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3720505.5227 - val_loss: 4794457.0978\n",
      "Epoch 1281/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3723532.5770 - val_loss: 4798647.5458\n",
      "Epoch 1282/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3720583.4610 - val_loss: 4788979.6698\n",
      "Epoch 1283/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3719409.1298 - val_loss: 4793250.6784\n",
      "Epoch 1284/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3716754.0200 - val_loss: 4787471.2860\n",
      "Epoch 1285/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3714356.2754 - val_loss: 4784519.7870\n",
      "Epoch 1286/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3718114.5876 - val_loss: 4794403.8091\n",
      "Epoch 1287/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3720365.0105 - val_loss: 4776523.4381\n",
      "Epoch 1288/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3720807.6380 - val_loss: 4786194.7188\n",
      "Epoch 1289/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3719874.7986 - val_loss: 4798642.3385\n",
      "Epoch 1290/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3721046.5964 - val_loss: 4790118.3973\n",
      "Epoch 1291/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3719443.4777 - val_loss: 4806670.8753\n",
      "Epoch 1292/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3717467.3943 - val_loss: 4792047.6107\n",
      "Epoch 1293/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3718323.2714 - val_loss: 4798435.9479\n",
      "Epoch 1294/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3717223.5975 - val_loss: 4790488.8133\n",
      "Epoch 1295/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3721002.8823 - val_loss: 4788204.4979\n",
      "Epoch 1296/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3718737.6999 - val_loss: 4786643.9930\n",
      "Epoch 1297/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3717278.4564 - val_loss: 4783982.3727\n",
      "Epoch 1298/5000\n",
      "40850/40850 [==============================] - 1s 22us/sample - loss: 3720154.8239 - val_loss: 4806364.6753\n",
      "Epoch 1299/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3718719.8334 - val_loss: 4796007.0928\n",
      "Epoch 1300/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3715809.2619 - val_loss: 4788251.0400\n",
      "Epoch 1301/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3722386.1993 - val_loss: 4795997.6821\n",
      "Epoch 1302/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3715858.7867 - val_loss: 4781482.7002\n",
      "Epoch 1303/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3715447.8904 - val_loss: 4809555.0212\n",
      "Epoch 1304/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3722024.0708 - val_loss: 4792823.9153\n",
      "Epoch 1305/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3714345.2827 - val_loss: 4793585.6113\n",
      "Epoch 1306/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3716528.8855 - val_loss: 4794249.4063\n",
      "Epoch 1307/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3713822.1552 - val_loss: 4792242.4981\n",
      "Epoch 1308/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3715347.9497 - val_loss: 4804225.7878\n",
      "Epoch 1309/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3719686.5598 - val_loss: 4786538.9271\n",
      "Epoch 1310/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3716207.1160 - val_loss: 4787370.9342\n",
      "Epoch 1311/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3712863.7963 - val_loss: 4805822.8530\n",
      "Epoch 1312/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3716558.5533 - val_loss: 4816529.3224\n",
      "Epoch 1313/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3712569.8016 - val_loss: 4793532.9680\n",
      "Epoch 1314/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3713714.0061 - val_loss: 4780424.2861\n",
      "Epoch 1315/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3715777.9593 - val_loss: 4803537.3966\n",
      "Epoch 1316/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3716014.0179 - val_loss: 4791207.8681\n",
      "Epoch 1317/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3716623.7136 - val_loss: 4798467.2239\n",
      "Epoch 1318/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3715749.2538 - val_loss: 4813415.1590\n",
      "Epoch 1319/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3713854.5950 - val_loss: 4807761.7820\n",
      "Epoch 1320/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3713657.8513 - val_loss: 4807365.0765\n",
      "Epoch 1321/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3714315.1065 - val_loss: 4806321.1461\n",
      "Epoch 1322/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3718901.5647 - val_loss: 4785370.5709\n",
      "Epoch 1323/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3711983.2171 - val_loss: 4801839.0574\n",
      "Epoch 1324/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3710304.1485 - val_loss: 4788434.8612\n",
      "Epoch 1325/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3709119.3450 - val_loss: 4791127.0499\n",
      "Epoch 1326/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3712029.9378 - val_loss: 4799413.8190\n",
      "Epoch 1327/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3711554.8313 - val_loss: 4785095.6830\n",
      "Epoch 1328/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3712379.4345 - val_loss: 4803011.6036\n",
      "Epoch 1329/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3711292.0693 - val_loss: 4790166.1303\n",
      "Epoch 1330/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3712401.7697 - val_loss: 4804462.6858\n",
      "Epoch 1331/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3711909.9970 - val_loss: 4800985.4287\n",
      "Epoch 1332/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3712423.1372 - val_loss: 4811697.7727\n",
      "Epoch 1333/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3716011.9652 - val_loss: 4799536.8782\n",
      "Epoch 1334/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3711437.0265 - val_loss: 4799228.6169\n",
      "Epoch 1335/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3707361.8718 - val_loss: 4801907.0707\n",
      "Epoch 1336/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3710728.5639 - val_loss: 4796995.3145\n",
      "Epoch 1337/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3710321.8463 - val_loss: 4810100.3225\n",
      "Epoch 1338/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3708526.9377 - val_loss: 4789235.8321\n",
      "Epoch 1339/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3708549.0250 - val_loss: 4798143.4571\n",
      "Epoch 1340/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3708389.0944 - val_loss: 4797120.7956\n",
      "Epoch 1341/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3712196.7828 - val_loss: 4794921.5177\n",
      "Epoch 1342/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3712329.2760 - val_loss: 4797037.2462\n",
      "Epoch 1343/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3712659.2069 - val_loss: 4804287.6824\n",
      "Epoch 1344/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3711001.2768 - val_loss: 4794176.8631\n",
      "Epoch 1345/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3709301.4455 - val_loss: 4794941.2900\n",
      "Epoch 1346/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3708215.1465 - val_loss: 4812244.2235\n",
      "Epoch 1347/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3710522.9934 - val_loss: 4793478.6824\n",
      "Epoch 1348/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3708237.0587 - val_loss: 4798684.3555\n",
      "Epoch 1349/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3707808.1409 - val_loss: 4801078.0767\n",
      "Epoch 1350/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3710400.0466 - val_loss: 4799041.8243\n",
      "Epoch 1351/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3708125.1163 - val_loss: 4799088.9606\n",
      "Epoch 1352/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3710581.2264 - val_loss: 4794085.7361\n",
      "Epoch 1353/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3706594.3106 - val_loss: 4818085.4677\n",
      "Epoch 1354/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3707609.3343 - val_loss: 4796121.1265\n",
      "Epoch 1355/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3707951.2025 - val_loss: 4805590.6630\n",
      "Epoch 1356/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3709232.3535 - val_loss: 4798026.0651\n",
      "Epoch 1357/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3707212.5811 - val_loss: 4801326.8892\n",
      "Epoch 1358/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3704901.7052 - val_loss: 4791746.0837\n",
      "Epoch 1359/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3707042.9382 - val_loss: 4799527.8634\n",
      "Epoch 1360/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3704112.6239 - val_loss: 4793444.5135\n",
      "Epoch 1361/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3707810.1258 - val_loss: 4800022.3359\n",
      "Epoch 1362/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3710470.3542 - val_loss: 4789909.9417\n",
      "Epoch 1363/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3708511.7174 - val_loss: 4801706.4184\n",
      "Epoch 1364/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3706931.8845 - val_loss: 4803796.5033\n",
      "Epoch 1365/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3708720.9457 - val_loss: 4788040.4088\n",
      "Epoch 1366/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3706538.4998 - val_loss: 4791088.7254\n",
      "Epoch 1367/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3704695.0860 - val_loss: 4800188.5333\n",
      "Epoch 1368/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3704904.9267 - val_loss: 4802602.4877\n",
      "Epoch 1369/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3708230.9002 - val_loss: 4810423.0359\n",
      "Epoch 1370/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3704255.9472 - val_loss: 4786839.8458\n",
      "Epoch 1371/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3702641.0869 - val_loss: 4787923.3788\n",
      "Epoch 1372/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3704321.6329 - val_loss: 4790084.2600\n",
      "Epoch 1373/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3701952.4769 - val_loss: 4792118.2981\n",
      "Epoch 1374/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3705452.8621 - val_loss: 4785879.1712\n",
      "Epoch 1375/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3705470.5998 - val_loss: 4793725.2841\n",
      "Epoch 1376/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3704301.8135 - val_loss: 4795637.2458\n",
      "Epoch 1377/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3704698.6384 - val_loss: 4794712.0144\n",
      "Epoch 1378/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3703350.5047 - val_loss: 4777340.5019\n",
      "Epoch 1379/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3703231.8992 - val_loss: 4818430.5575\n",
      "Epoch 1380/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3702779.5418 - val_loss: 4787806.9066\n",
      "Epoch 1381/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3703143.0459 - val_loss: 4794583.0244\n",
      "Epoch 1382/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3699462.9853 - val_loss: 4798085.2929\n",
      "Epoch 1383/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3704229.9891 - val_loss: 4793518.1364\n",
      "Epoch 1384/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3703918.0367 - val_loss: 4817120.7836\n",
      "Epoch 1385/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3703813.5660 - val_loss: 4786953.6923\n",
      "Epoch 1386/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3701626.1828 - val_loss: 4786360.6709\n",
      "Epoch 1387/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3701967.2558 - val_loss: 4796070.6171\n",
      "Epoch 1388/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3702777.5577 - val_loss: 4807801.0764\n",
      "Epoch 1389/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3700137.7390 - val_loss: 4798373.9285\n",
      "Epoch 1390/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3700987.3132 - val_loss: 4813587.6503\n",
      "Epoch 1391/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3701651.0749 - val_loss: 4806625.7527\n",
      "Epoch 1392/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3694766.1381 - val_loss: 4785611.6990\n",
      "Epoch 1393/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3701176.3263 - val_loss: 4789090.0204\n",
      "Epoch 1394/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3696766.2172 - val_loss: 4798907.8564\n",
      "Epoch 1395/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3702556.1375 - val_loss: 4795735.8733\n",
      "Epoch 1396/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3702076.9447 - val_loss: 4788437.1630\n",
      "Epoch 1397/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3702955.4605 - val_loss: 4792770.9711\n",
      "Epoch 1398/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3699484.2933 - val_loss: 4793958.7727\n",
      "Epoch 1399/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3695806.3065 - val_loss: 4772712.4572\n",
      "Epoch 1400/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3699201.9427 - val_loss: 4797411.1848\n",
      "Epoch 1401/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3700056.8349 - val_loss: 4798759.1590\n",
      "Epoch 1402/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3696924.6312 - val_loss: 4814558.3196\n",
      "Epoch 1403/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3698817.2241 - val_loss: 4788849.6152\n",
      "Epoch 1404/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3696467.9157 - val_loss: 4797858.9985\n",
      "Epoch 1405/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3691924.7634 - val_loss: 4802265.1169\n",
      "Epoch 1406/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3702576.4941 - val_loss: 4795821.4601\n",
      "Epoch 1407/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3698783.5829 - val_loss: 4817282.5211\n",
      "Epoch 1408/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3698460.1360 - val_loss: 4802752.0078\n",
      "Epoch 1409/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3703820.1745 - val_loss: 4786143.2351\n",
      "Epoch 1410/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3693993.3668 - val_loss: 4800149.1145\n",
      "Epoch 1411/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3693895.1970 - val_loss: 4801364.2241\n",
      "Epoch 1412/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3695058.3724 - val_loss: 4809204.4433\n",
      "Epoch 1413/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3695642.0306 - val_loss: 4808263.4915\n",
      "Epoch 1414/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3696094.8030 - val_loss: 4799110.6762\n",
      "Epoch 1415/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3695406.1117 - val_loss: 4791289.3904\n",
      "Epoch 1416/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3701043.3684 - val_loss: 4783814.9704\n",
      "Epoch 1417/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3694465.6020 - val_loss: 4799228.6799\n",
      "Epoch 1418/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3695523.0450 - val_loss: 4821062.1354\n",
      "Epoch 1419/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3695515.0693 - val_loss: 4795785.3287\n",
      "Epoch 1420/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3694837.2976 - val_loss: 4804241.7953\n",
      "Epoch 1421/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3693698.7385 - val_loss: 4800448.4295\n",
      "Epoch 1422/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3691597.6382 - val_loss: 4781823.8101\n",
      "Epoch 1423/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3691978.7304 - val_loss: 4798691.4317\n",
      "Epoch 1424/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3695506.5991 - val_loss: 4786349.2576\n",
      "Epoch 1425/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3691719.4782 - val_loss: 4784313.5051\n",
      "Epoch 1426/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3694549.0726 - val_loss: 4819664.2143\n",
      "Epoch 1427/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3695369.9702 - val_loss: 4797247.7112\n",
      "Epoch 1428/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3690812.9848 - val_loss: 4798606.8032\n",
      "Epoch 1429/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3695366.1951 - val_loss: 4795086.9268\n",
      "Epoch 1430/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3689667.0559 - val_loss: 4800931.5813\n",
      "Epoch 1431/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3692437.5718 - val_loss: 4798841.0973\n",
      "Epoch 1432/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3693666.3377 - val_loss: 4797677.4708\n",
      "Epoch 1433/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3689733.5100 - val_loss: 4811148.3320\n",
      "Epoch 1434/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3688748.8019 - val_loss: 4812145.6833\n",
      "Epoch 1435/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3693502.9350 - val_loss: 4813438.8692\n",
      "Epoch 1436/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3691366.9967 - val_loss: 4808476.6587\n",
      "Epoch 1437/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3692147.4052 - val_loss: 4788047.5441\n",
      "Epoch 1438/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3691436.3899 - val_loss: 4793121.2534\n",
      "Epoch 1439/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3689883.4368 - val_loss: 4795016.1304\n",
      "Epoch 1440/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3690580.1760 - val_loss: 4797147.3461\n",
      "Epoch 1441/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3692120.2492 - val_loss: 4793459.5773\n",
      "Epoch 1442/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3689866.6761 - val_loss: 4798635.5240\n",
      "Epoch 1443/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3693061.5744 - val_loss: 4799431.6173\n",
      "Epoch 1444/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3689102.3596 - val_loss: 4811233.2300\n",
      "Epoch 1445/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3689329.8483 - val_loss: 4795051.1899\n",
      "Epoch 1446/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3690373.9908 - val_loss: 4792699.8760\n",
      "Epoch 1447/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3689267.7077 - val_loss: 4799461.7715\n",
      "Epoch 1448/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3692575.9881 - val_loss: 4803356.9256\n",
      "Epoch 1449/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3690238.5629 - val_loss: 4800585.8428\n",
      "Epoch 1450/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3689061.4010 - val_loss: 4804111.5364\n",
      "Epoch 1451/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3690323.3856 - val_loss: 4806179.7002\n",
      "Epoch 1452/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3688067.3196 - val_loss: 4795671.9151\n",
      "Epoch 1453/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3691767.1219 - val_loss: 4803637.2687\n",
      "Epoch 1454/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3689060.7731 - val_loss: 4794818.2414\n",
      "Epoch 1455/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3690148.8561 - val_loss: 4798316.3778\n",
      "Epoch 1456/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3686298.2022 - val_loss: 4817721.3159\n",
      "Epoch 1457/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3685563.2884 - val_loss: 4793465.0766\n",
      "Epoch 1458/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3687090.9189 - val_loss: 4805368.1856\n",
      "Epoch 1459/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3683979.5461 - val_loss: 4791994.6914\n",
      "Epoch 1460/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3685410.8809 - val_loss: 4783068.4650\n",
      "Epoch 1461/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3684871.9920 - val_loss: 4799406.7574\n",
      "Epoch 1462/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3686985.7902 - val_loss: 4790494.2156\n",
      "Epoch 1463/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3687899.8674 - val_loss: 4792108.7916\n",
      "Epoch 1464/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3686024.5695 - val_loss: 4815163.9771\n",
      "Epoch 1465/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3687825.7663 - val_loss: 4802385.8240\n",
      "Epoch 1466/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3687356.6351 - val_loss: 4789399.9113\n",
      "Epoch 1467/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3682708.0029 - val_loss: 4787713.4948\n",
      "Epoch 1468/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3683828.5290 - val_loss: 4796766.2463\n",
      "Epoch 1469/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3686452.8083 - val_loss: 4804181.1087\n",
      "Epoch 1470/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3684555.2162 - val_loss: 4797899.4765\n",
      "Epoch 1471/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3683654.1957 - val_loss: 4809074.2250\n",
      "Epoch 1472/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3686572.4006 - val_loss: 4798599.2071\n",
      "Epoch 1473/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3678996.6848 - val_loss: 4789687.5733\n",
      "Epoch 1474/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3685064.5765 - val_loss: 4802509.7217\n",
      "Epoch 1475/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3683553.6966 - val_loss: 4794868.9678\n",
      "Epoch 1476/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3679503.5098 - val_loss: 4811186.2373\n",
      "Epoch 1477/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3681828.0069 - val_loss: 4788017.3319\n",
      "Epoch 1478/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3681604.0743 - val_loss: 4795229.5621\n",
      "Epoch 1479/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3685201.3562 - val_loss: 4789395.9742\n",
      "Epoch 1480/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3680601.1543 - val_loss: 4786681.5850\n",
      "Epoch 1481/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3682122.4929 - val_loss: 4794398.5795\n",
      "Epoch 1482/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3677199.6329 - val_loss: 4784747.4759\n",
      "Epoch 1483/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3682925.1016 - val_loss: 4796508.8346\n",
      "Epoch 1484/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3681524.7319 - val_loss: 4801346.6315\n",
      "Epoch 1485/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3675972.2457 - val_loss: 4790419.4963\n",
      "Epoch 1486/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3677335.7418 - val_loss: 4787655.8600\n",
      "Epoch 1487/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3682477.4495 - val_loss: 4789506.6069\n",
      "Epoch 1488/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3678260.1446 - val_loss: 4798098.3690\n",
      "Epoch 1489/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3678606.5774 - val_loss: 4831248.1169\n",
      "Epoch 1490/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3676260.8645 - val_loss: 4818028.7433\n",
      "Epoch 1491/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3680296.7715 - val_loss: 4793973.0469\n",
      "Epoch 1492/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3681616.2732 - val_loss: 4788991.2193\n",
      "Epoch 1493/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3680582.5518 - val_loss: 4792944.4190\n",
      "Epoch 1494/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3679439.5183 - val_loss: 4787027.7608\n",
      "Epoch 1495/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3676291.9768 - val_loss: 4791468.5500\n",
      "Epoch 1496/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3678482.1110 - val_loss: 4795257.8881\n",
      "Epoch 1497/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3675496.8195 - val_loss: 4780972.0370\n",
      "Epoch 1498/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3676331.6926 - val_loss: 4776659.8900\n",
      "Epoch 1499/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3677401.2588 - val_loss: 4785022.4859\n",
      "Epoch 1500/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3675410.4151 - val_loss: 4785650.6615\n",
      "Epoch 1501/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3677673.3271 - val_loss: 4805038.4023\n",
      "Epoch 1502/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3676826.0201 - val_loss: 4785755.1657\n",
      "Epoch 1503/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3678356.9816 - val_loss: 4787345.1261\n",
      "Epoch 1504/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3678821.9127 - val_loss: 4789627.0619\n",
      "Epoch 1505/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3673058.7335 - val_loss: 4781491.4006\n",
      "Epoch 1506/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3674741.5015 - val_loss: 4799042.7127\n",
      "Epoch 1507/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3674818.3665 - val_loss: 4793703.7438\n",
      "Epoch 1508/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3676766.3792 - val_loss: 4793192.9621\n",
      "Epoch 1509/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3677469.1721 - val_loss: 4794562.1175\n",
      "Epoch 1510/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3675056.3500 - val_loss: 4794514.1281\n",
      "Epoch 1511/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3674136.3971 - val_loss: 4779356.7691\n",
      "Epoch 1512/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3677164.3222 - val_loss: 4789495.2315\n",
      "Epoch 1513/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3676418.0127 - val_loss: 4786604.7879\n",
      "Epoch 1514/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3674473.7495 - val_loss: 4786360.1243\n",
      "Epoch 1515/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3673916.8599 - val_loss: 4795604.6464\n",
      "Epoch 1516/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3677792.7636 - val_loss: 4808189.9695\n",
      "Epoch 1517/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3673954.3350 - val_loss: 4797201.6795\n",
      "Epoch 1518/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3675092.4089 - val_loss: 4781309.3357\n",
      "Epoch 1519/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3675746.9652 - val_loss: 4776667.9071\n",
      "Epoch 1520/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3673656.3213 - val_loss: 4791428.2275\n",
      "Epoch 1521/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3672720.4313 - val_loss: 4792281.5532\n",
      "Epoch 1522/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3674548.3216 - val_loss: 4785258.8440\n",
      "Epoch 1523/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3673483.6229 - val_loss: 4804811.2674\n",
      "Epoch 1524/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3673400.2000 - val_loss: 4802082.8387\n",
      "Epoch 1525/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3674340.8325 - val_loss: 4796968.1496\n",
      "Epoch 1526/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3671901.0993 - val_loss: 4798634.5813\n",
      "Epoch 1527/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3676885.2060 - val_loss: 4789141.5844\n",
      "Epoch 1528/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3670524.7665 - val_loss: 4807400.0093\n",
      "Epoch 1529/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3675919.2592 - val_loss: 4793810.9813\n",
      "Epoch 1530/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3672087.4888 - val_loss: 4786245.4171\n",
      "Epoch 1531/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3671530.2091 - val_loss: 4793863.6968\n",
      "Epoch 1532/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3672679.0456 - val_loss: 4791403.8402\n",
      "Epoch 1533/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3671489.6385 - val_loss: 4796865.7318\n",
      "Epoch 1534/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3668960.9033 - val_loss: 4805733.1004\n",
      "Epoch 1535/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3673693.9434 - val_loss: 4781197.3489\n",
      "Epoch 1536/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3668652.3677 - val_loss: 4807277.0584\n",
      "Epoch 1537/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3671513.8531 - val_loss: 4798422.5738\n",
      "Epoch 1538/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3672355.8169 - val_loss: 4781064.0079\n",
      "Epoch 1539/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3670272.4026 - val_loss: 4784115.6680\n",
      "Epoch 1540/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3671052.6805 - val_loss: 4807821.7508\n",
      "Epoch 1541/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3673361.4256 - val_loss: 4791223.3666\n",
      "Epoch 1542/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3671227.2881 - val_loss: 4783071.2721\n",
      "Epoch 1543/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3672672.1405 - val_loss: 4809366.1520\n",
      "Epoch 1544/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3672394.6569 - val_loss: 4801773.9982\n",
      "Epoch 1545/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3669106.2764 - val_loss: 4775012.0137\n",
      "Epoch 1546/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3669650.1291 - val_loss: 4791893.9244\n",
      "Epoch 1547/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3670414.8328 - val_loss: 4777868.7099\n",
      "Epoch 1548/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3672282.8865 - val_loss: 4799719.1855\n",
      "Epoch 1549/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3667525.1978 - val_loss: 4777004.9011\n",
      "Epoch 1550/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3671822.3412 - val_loss: 4788180.7957\n",
      "Epoch 1551/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3669925.1655 - val_loss: 4774366.4637\n",
      "Epoch 1552/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3668363.6582 - val_loss: 4796177.9998\n",
      "Epoch 1553/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3668559.7199 - val_loss: 4775702.2223\n",
      "Epoch 1554/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3669033.0072 - val_loss: 4794390.4724\n",
      "Epoch 1555/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3667045.2707 - val_loss: 4818694.3741\n",
      "Epoch 1556/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3670469.8084 - val_loss: 4803430.1012\n",
      "Epoch 1557/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3667668.9350 - val_loss: 4801671.4830\n",
      "Epoch 1558/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3669928.4963 - val_loss: 4793510.3854\n",
      "Epoch 1559/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3669949.6959 - val_loss: 4791246.8008\n",
      "Epoch 1560/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3666219.5942 - val_loss: 4784189.0421\n",
      "Epoch 1561/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3667988.9534 - val_loss: 4793423.5563\n",
      "Epoch 1562/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3667335.1679 - val_loss: 4775414.7451\n",
      "Epoch 1563/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3668191.5376 - val_loss: 4784207.3203\n",
      "Epoch 1564/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3668439.1459 - val_loss: 4794640.7636\n",
      "Epoch 1565/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3667811.8891 - val_loss: 4809312.1501\n",
      "Epoch 1566/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3666645.6609 - val_loss: 4797465.6253\n",
      "Epoch 1567/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3668483.3818 - val_loss: 4788860.1558\n",
      "Epoch 1568/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3666310.5641 - val_loss: 4791831.0090\n",
      "Epoch 1569/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3667597.4372 - val_loss: 4797606.5006\n",
      "Epoch 1570/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3664819.1033 - val_loss: 4787665.4979\n",
      "Epoch 1571/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3666136.4902 - val_loss: 4800533.6277\n",
      "Epoch 1572/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3670817.0018 - val_loss: 4789355.7192\n",
      "Epoch 1573/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3665346.9826 - val_loss: 4774990.9100\n",
      "Epoch 1574/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3663392.8088 - val_loss: 4785475.9016\n",
      "Epoch 1575/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3663717.1758 - val_loss: 4803054.9261\n",
      "Epoch 1576/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3665870.2603 - val_loss: 4792117.4206\n",
      "Epoch 1577/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3664056.6825 - val_loss: 4783655.8237\n",
      "Epoch 1578/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3664828.3541 - val_loss: 4785672.6935\n",
      "Epoch 1579/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3667787.5834 - val_loss: 4793805.6600\n",
      "Epoch 1580/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3665298.4981 - val_loss: 4789117.7912\n",
      "Epoch 1581/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3665006.1211 - val_loss: 4787659.9165\n",
      "Epoch 1582/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3668858.3771 - val_loss: 4789819.7942\n",
      "Epoch 1583/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3667202.2118 - val_loss: 4776312.8408\n",
      "Epoch 1584/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3666618.7523 - val_loss: 4786216.6814\n",
      "Epoch 1585/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3667785.8458 - val_loss: 4791518.5788\n",
      "Epoch 1586/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3668835.1350 - val_loss: 4794554.9852\n",
      "Epoch 1587/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3664680.9739 - val_loss: 4788218.5503\n",
      "Epoch 1588/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3665167.3382 - val_loss: 4789025.4471\n",
      "Epoch 1589/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3664535.5666 - val_loss: 4783165.2141\n",
      "Epoch 1590/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3664597.6639 - val_loss: 4788310.5431\n",
      "Epoch 1591/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3664154.4723 - val_loss: 4800334.5064\n",
      "Epoch 1592/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3666092.9878 - val_loss: 4781638.7770\n",
      "Epoch 1593/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3667439.8508 - val_loss: 4801762.6774\n",
      "Epoch 1594/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3662179.7185 - val_loss: 4773223.4007\n",
      "Epoch 1595/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3663508.7511 - val_loss: 4790125.8789\n",
      "Epoch 1596/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3662355.6572 - val_loss: 4804104.5290\n",
      "Epoch 1597/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3663911.6169 - val_loss: 4797990.7338\n",
      "Epoch 1598/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3663989.5638 - val_loss: 4793980.9710\n",
      "Epoch 1599/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3663635.9732 - val_loss: 4791925.7095\n",
      "Epoch 1600/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3664324.1878 - val_loss: 4785461.6728\n",
      "Epoch 1601/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3663596.8101 - val_loss: 4797605.7818\n",
      "Epoch 1602/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3663688.8402 - val_loss: 4785441.0169\n",
      "Epoch 1603/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3663561.6647 - val_loss: 4794621.2578\n",
      "Epoch 1604/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3665051.5895 - val_loss: 4785404.9471\n",
      "Epoch 1605/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3661801.7276 - val_loss: 4778170.8347\n",
      "Epoch 1606/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3662609.2660 - val_loss: 4788092.7358\n",
      "Epoch 1607/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3663684.6205 - val_loss: 4787860.8640\n",
      "Epoch 1608/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3662577.7172 - val_loss: 4792644.3555\n",
      "Epoch 1609/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3661071.9001 - val_loss: 4770267.1091\n",
      "Epoch 1610/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3662710.0017 - val_loss: 4778566.0237\n",
      "Epoch 1611/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3662231.6837 - val_loss: 4789495.1232\n",
      "Epoch 1612/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3659650.1174 - val_loss: 4781604.8797\n",
      "Epoch 1613/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3660547.9902 - val_loss: 4799860.9954\n",
      "Epoch 1614/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3663139.3903 - val_loss: 4777968.7340\n",
      "Epoch 1615/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3660451.7433 - val_loss: 4787711.1005\n",
      "Epoch 1616/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3661731.2206 - val_loss: 4778967.5086\n",
      "Epoch 1617/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3661525.5778 - val_loss: 4780890.3678\n",
      "Epoch 1618/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3660922.4563 - val_loss: 4823117.0643\n",
      "Epoch 1619/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3661796.6617 - val_loss: 4785274.7221\n",
      "Epoch 1620/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3660764.9665 - val_loss: 4800528.8661\n",
      "Epoch 1621/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3659932.6328 - val_loss: 4801348.8273\n",
      "Epoch 1622/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3661767.1169 - val_loss: 4787284.1953\n",
      "Epoch 1623/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3660942.7107 - val_loss: 4781368.6688\n",
      "Epoch 1624/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3654175.8599 - val_loss: 4781331.8497\n",
      "Epoch 1625/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3661333.8079 - val_loss: 4786811.1793\n",
      "Epoch 1626/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3657059.5828 - val_loss: 4809013.9102\n",
      "Epoch 1627/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3661909.2076 - val_loss: 4784924.6429\n",
      "Epoch 1628/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3658665.8897 - val_loss: 4779997.8596\n",
      "Epoch 1629/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3658980.8830 - val_loss: 4788820.5489\n",
      "Epoch 1630/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3657928.7282 - val_loss: 4784063.2261\n",
      "Epoch 1631/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3660739.2380 - val_loss: 4794615.2832\n",
      "Epoch 1632/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3657828.9713 - val_loss: 4799960.9006\n",
      "Epoch 1633/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3656495.6520 - val_loss: 4789934.9169\n",
      "Epoch 1634/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3659026.5751 - val_loss: 4795001.5320\n",
      "Epoch 1635/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3659473.6350 - val_loss: 4786792.8571\n",
      "Epoch 1636/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3658178.5977 - val_loss: 4800358.3408\n",
      "Epoch 1637/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3654285.1597 - val_loss: 4779127.0148\n",
      "Epoch 1638/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3656881.5590 - val_loss: 4810918.5110\n",
      "Epoch 1639/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3659722.8750 - val_loss: 4788193.7969\n",
      "Epoch 1640/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3656055.3542 - val_loss: 4788059.5060\n",
      "Epoch 1641/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3656557.9498 - val_loss: 4780091.3887\n",
      "Epoch 1642/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3655496.4804 - val_loss: 4790830.4124\n",
      "Epoch 1643/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3658455.1999 - val_loss: 4790982.8160\n",
      "Epoch 1644/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3662841.9419 - val_loss: 4802560.2978\n",
      "Epoch 1645/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3654953.1888 - val_loss: 4800873.8560\n",
      "Epoch 1646/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3654229.8970 - val_loss: 4781014.6876\n",
      "Epoch 1647/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3656963.9921 - val_loss: 4789699.0575\n",
      "Epoch 1648/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3655437.2686 - val_loss: 4794181.0644\n",
      "Epoch 1649/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3656338.4493 - val_loss: 4791272.4527\n",
      "Epoch 1650/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3656622.7694 - val_loss: 4784261.0335\n",
      "Epoch 1651/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3655255.9250 - val_loss: 4778997.7835\n",
      "Epoch 1652/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3657848.9969 - val_loss: 4788605.6446\n",
      "Epoch 1653/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3653124.4605 - val_loss: 4773815.0300\n",
      "Epoch 1654/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3660467.5370 - val_loss: 4792804.6522\n",
      "Epoch 1655/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3657122.2285 - val_loss: 4775091.6196\n",
      "Epoch 1656/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3653246.1617 - val_loss: 4790063.3099\n",
      "Epoch 1657/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3660181.9887 - val_loss: 4775998.1748\n",
      "Epoch 1658/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3654722.4254 - val_loss: 4800377.1576\n",
      "Epoch 1659/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3654035.7298 - val_loss: 4791578.1780\n",
      "Epoch 1660/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3653540.9309 - val_loss: 4806732.0540\n",
      "Epoch 1661/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3658587.2458 - val_loss: 4780004.8428\n",
      "Epoch 1662/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3654186.2284 - val_loss: 4784459.8662\n",
      "Epoch 1663/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3656098.2208 - val_loss: 4822284.3437\n",
      "Epoch 1664/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3656550.5586 - val_loss: 4786470.9234\n",
      "Epoch 1665/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3656710.2800 - val_loss: 4773298.6180\n",
      "Epoch 1666/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3651561.9289 - val_loss: 4799289.0695\n",
      "Epoch 1667/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3656538.6982 - val_loss: 4790745.6332\n",
      "Epoch 1668/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3654958.2517 - val_loss: 4793740.7669\n",
      "Epoch 1669/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3651835.7979 - val_loss: 4798812.8315\n",
      "Epoch 1670/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3653141.4543 - val_loss: 4780269.9029\n",
      "Epoch 1671/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3654362.8094 - val_loss: 4769964.6921\n",
      "Epoch 1672/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3651366.0256 - val_loss: 4793240.3930\n",
      "Epoch 1673/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3650208.0803 - val_loss: 4800158.1684\n",
      "Epoch 1674/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3654501.0776 - val_loss: 4801678.4388\n",
      "Epoch 1675/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3652205.8348 - val_loss: 4783827.9218\n",
      "Epoch 1676/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3652620.1217 - val_loss: 4779441.6362\n",
      "Epoch 1677/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3651953.2527 - val_loss: 4792759.7581\n",
      "Epoch 1678/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3657813.9769 - val_loss: 4785123.1659\n",
      "Epoch 1679/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3649789.8487 - val_loss: 4773634.7908\n",
      "Epoch 1680/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3651858.7302 - val_loss: 4790507.4225\n",
      "Epoch 1681/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3653676.5571 - val_loss: 4784084.5422\n",
      "Epoch 1682/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3653166.0717 - val_loss: 4795292.4469\n",
      "Epoch 1683/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3655278.8233 - val_loss: 4799208.2507\n",
      "Epoch 1684/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3651048.9246 - val_loss: 4788662.2294\n",
      "Epoch 1685/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3651841.2985 - val_loss: 4784139.2077\n",
      "Epoch 1686/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3648992.6409 - val_loss: 4790933.8467\n",
      "Epoch 1687/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3655005.4939 - val_loss: 4795165.3501\n",
      "Epoch 1688/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3650762.7715 - val_loss: 4778208.1593\n",
      "Epoch 1689/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3650932.0553 - val_loss: 4790221.3152\n",
      "Epoch 1690/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3651199.5781 - val_loss: 4789116.1116\n",
      "Epoch 1691/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3649387.2686 - val_loss: 4776258.6433\n",
      "Epoch 1692/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3651564.2934 - val_loss: 4769614.3979\n",
      "Epoch 1693/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3656188.5858 - val_loss: 4777073.7631\n",
      "Epoch 1694/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3648926.2376 - val_loss: 4793394.7307\n",
      "Epoch 1695/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3649616.2047 - val_loss: 4793575.7089\n",
      "Epoch 1696/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3652642.9712 - val_loss: 4773739.6426\n",
      "Epoch 1697/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3646659.6337 - val_loss: 4792036.7019\n",
      "Epoch 1698/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3649353.3310 - val_loss: 4797555.9148\n",
      "Epoch 1699/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3649719.7372 - val_loss: 4774422.7247\n",
      "Epoch 1700/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3645253.8718 - val_loss: 4795710.0639\n",
      "Epoch 1701/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3647463.0088 - val_loss: 4784267.4877\n",
      "Epoch 1702/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3645473.2558 - val_loss: 4789831.6288\n",
      "Epoch 1703/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3647873.2991 - val_loss: 4796595.9672\n",
      "Epoch 1704/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3648220.6816 - val_loss: 4792513.8325\n",
      "Epoch 1705/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3647905.4134 - val_loss: 4808822.7905\n",
      "Epoch 1706/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3645869.8002 - val_loss: 4788441.4071\n",
      "Epoch 1707/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3642982.2089 - val_loss: 4770660.9525\n",
      "Epoch 1708/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3645537.6647 - val_loss: 4775509.0330\n",
      "Epoch 1709/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3646840.8256 - val_loss: 4782905.5486\n",
      "Epoch 1710/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3646007.4030 - val_loss: 4788928.8889\n",
      "Epoch 1711/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3646583.1371 - val_loss: 4772384.4454\n",
      "Epoch 1712/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3643455.2437 - val_loss: 4776337.7289\n",
      "Epoch 1713/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3645009.4267 - val_loss: 4774009.9958\n",
      "Epoch 1714/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3643316.8203 - val_loss: 4781950.0535\n",
      "Epoch 1715/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3645244.9894 - val_loss: 4792830.8282\n",
      "Epoch 1716/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3644885.9837 - val_loss: 4799462.0056\n",
      "Epoch 1717/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3641629.0384 - val_loss: 4780823.3945\n",
      "Epoch 1718/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3643869.8326 - val_loss: 4805039.0104\n",
      "Epoch 1719/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3641634.8846 - val_loss: 4801609.1595\n",
      "Epoch 1720/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3643663.5080 - val_loss: 4792703.9677\n",
      "Epoch 1721/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3642945.9684 - val_loss: 4772072.6935\n",
      "Epoch 1722/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3645783.5497 - val_loss: 4786774.6735\n",
      "Epoch 1723/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3642384.3085 - val_loss: 4772704.5970\n",
      "Epoch 1724/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3641757.6564 - val_loss: 4794195.4725\n",
      "Epoch 1725/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3643427.9765 - val_loss: 4791828.0626\n",
      "Epoch 1726/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3641139.3170 - val_loss: 4792469.4037\n",
      "Epoch 1727/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3641266.2788 - val_loss: 4773731.8670\n",
      "Epoch 1728/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3641329.8420 - val_loss: 4790893.2047\n",
      "Epoch 1729/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3638512.8918 - val_loss: 4800387.3017\n",
      "Epoch 1730/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3640854.6853 - val_loss: 4800670.0109\n",
      "Epoch 1731/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3645382.5794 - val_loss: 4792354.8488\n",
      "Epoch 1732/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3643959.0232 - val_loss: 4790147.5997\n",
      "Epoch 1733/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3644032.2498 - val_loss: 4820568.6358\n",
      "Epoch 1734/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3640833.6763 - val_loss: 4791164.7432\n",
      "Epoch 1735/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3638051.8182 - val_loss: 4794331.4199\n",
      "Epoch 1736/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3640918.7617 - val_loss: 4781132.5975\n",
      "Epoch 1737/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3639250.5656 - val_loss: 4798108.2055\n",
      "Epoch 1738/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3641103.8014 - val_loss: 4781293.7023\n",
      "Epoch 1739/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3635134.4416 - val_loss: 4789437.6282\n",
      "Epoch 1740/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3640304.5843 - val_loss: 4784072.0870\n",
      "Epoch 1741/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3643051.9987 - val_loss: 4771363.8583\n",
      "Epoch 1742/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3636295.1595 - val_loss: 4816323.2636\n",
      "Epoch 1743/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3639796.7974 - val_loss: 4780867.3291\n",
      "Epoch 1744/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3635723.8993 - val_loss: 4806589.9664\n",
      "Epoch 1745/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3636674.1713 - val_loss: 4794099.6237\n",
      "Epoch 1746/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3637054.4008 - val_loss: 4805477.4025\n",
      "Epoch 1747/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3638470.3584 - val_loss: 4789854.3776\n",
      "Epoch 1748/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3637778.1459 - val_loss: 4781107.7835\n",
      "Epoch 1749/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3641112.9219 - val_loss: 4796679.3411\n",
      "Epoch 1750/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3635250.2076 - val_loss: 4778398.1795\n",
      "Epoch 1751/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3639185.6436 - val_loss: 4791775.7152\n",
      "Epoch 1752/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3636321.2420 - val_loss: 4805512.5543\n",
      "Epoch 1753/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3639170.2509 - val_loss: 4783698.6579\n",
      "Epoch 1754/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3636415.7992 - val_loss: 4817167.5981\n",
      "Epoch 1755/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3641249.3201 - val_loss: 4782796.6522\n",
      "Epoch 1756/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3637257.9830 - val_loss: 4785695.2988\n",
      "Epoch 1757/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3638188.0451 - val_loss: 4795385.7014\n",
      "Epoch 1758/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3632233.5324 - val_loss: 4789323.5295\n",
      "Epoch 1759/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3635531.6860 - val_loss: 4795127.6197\n",
      "Epoch 1760/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3636025.5182 - val_loss: 4785545.2454\n",
      "Epoch 1761/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3637999.1593 - val_loss: 4800272.9461\n",
      "Epoch 1762/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3637688.8096 - val_loss: 4789410.1757\n",
      "Epoch 1763/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3633109.0932 - val_loss: 4781968.1995\n",
      "Epoch 1764/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3635966.5356 - val_loss: 4796172.0696\n",
      "Epoch 1765/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3635486.2018 - val_loss: 4811524.1231\n",
      "Epoch 1766/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3634910.1215 - val_loss: 4800924.5213\n",
      "Epoch 1767/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3634834.8974 - val_loss: 4791264.3709\n",
      "Epoch 1768/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3633099.3931 - val_loss: 4784133.1798\n",
      "Epoch 1769/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3640548.9394 - val_loss: 4791863.2536\n",
      "Epoch 1770/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3632838.4955 - val_loss: 4797738.4534\n",
      "Epoch 1771/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3637737.4119 - val_loss: 4802639.3944\n",
      "Epoch 1772/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3636754.6994 - val_loss: 4795011.7754\n",
      "Epoch 1773/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3631114.2122 - val_loss: 4784238.4981\n",
      "Epoch 1774/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3634410.9409 - val_loss: 4792784.5370\n",
      "Epoch 1775/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3630644.1745 - val_loss: 4811820.4259\n",
      "Epoch 1776/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3632022.3000 - val_loss: 4812732.1666\n",
      "Epoch 1777/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3638520.6060 - val_loss: 4801436.4520\n",
      "Epoch 1778/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3633667.0179 - val_loss: 4818438.6747\n",
      "Epoch 1779/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3641743.3065 - val_loss: 4803006.6258\n",
      "Epoch 1780/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3637308.7510 - val_loss: 4799270.3277\n",
      "Epoch 1781/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3633449.3818 - val_loss: 4809911.0420\n",
      "Epoch 1782/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3632368.4576 - val_loss: 4813412.9506\n",
      "Epoch 1783/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3635736.0594 - val_loss: 4786055.0012\n",
      "Epoch 1784/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3634828.7694 - val_loss: 4803944.0739\n",
      "Epoch 1785/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3631621.2596 - val_loss: 4789046.6700\n",
      "Epoch 1786/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3633398.6033 - val_loss: 4800106.6072\n",
      "Epoch 1787/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3633722.3371 - val_loss: 4799356.3136\n",
      "Epoch 1788/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3638462.4597 - val_loss: 4814978.0919\n",
      "Epoch 1789/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3630850.4231 - val_loss: 4801771.3203\n",
      "Epoch 1790/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3631758.5867 - val_loss: 4789711.0337\n",
      "Epoch 1791/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3629854.7287 - val_loss: 4816741.9226\n",
      "Epoch 1792/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3630740.9095 - val_loss: 4784257.1729\n",
      "Epoch 1793/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3629249.5902 - val_loss: 4799481.3701\n",
      "Epoch 1794/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3630236.0140 - val_loss: 4817850.8049\n",
      "Epoch 1795/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3630784.9545 - val_loss: 4813531.3887\n",
      "Epoch 1796/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3632079.9851 - val_loss: 4796079.1728\n",
      "Epoch 1797/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3634101.3261 - val_loss: 4803695.6140\n",
      "Epoch 1798/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3631146.9886 - val_loss: 4794566.9689\n",
      "Epoch 1799/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3630014.0659 - val_loss: 4785147.0069\n",
      "Epoch 1800/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3629259.4929 - val_loss: 4810113.9189\n",
      "Epoch 1801/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3634971.1509 - val_loss: 4783152.3522\n",
      "Epoch 1802/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3632257.4748 - val_loss: 4792981.7443\n",
      "Epoch 1803/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3628116.0868 - val_loss: 4786712.8917\n",
      "Epoch 1804/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3627987.7671 - val_loss: 4806742.1609\n",
      "Epoch 1805/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3630147.9821 - val_loss: 4807124.3138\n",
      "Epoch 1806/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3631079.2889 - val_loss: 4795239.8294\n",
      "Epoch 1807/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3635165.5087 - val_loss: 4799577.0070\n",
      "Epoch 1808/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3632215.2789 - val_loss: 4801406.4685\n",
      "Epoch 1809/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3631173.3486 - val_loss: 4800740.9817\n",
      "Epoch 1810/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3631009.6709 - val_loss: 4798284.4578\n",
      "Epoch 1811/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3632240.6223 - val_loss: 4800449.9994\n",
      "Epoch 1812/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3629643.0660 - val_loss: 4785413.9506\n",
      "Epoch 1813/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3630974.0981 - val_loss: 4791905.4586\n",
      "Epoch 1814/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3631738.4268 - val_loss: 4795618.8608\n",
      "Epoch 1815/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3629342.0313 - val_loss: 4803811.2810\n",
      "Epoch 1816/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3632205.7633 - val_loss: 4795375.9444\n",
      "Epoch 1817/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3630428.3156 - val_loss: 4796163.9664\n",
      "Epoch 1818/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3629990.6965 - val_loss: 4796589.9282\n",
      "Epoch 1819/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3630537.1627 - val_loss: 4783944.2305\n",
      "Epoch 1820/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3631004.4137 - val_loss: 4780811.0562\n",
      "Epoch 1821/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3633962.6275 - val_loss: 4793564.4695\n",
      "Epoch 1822/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3630079.1946 - val_loss: 4798457.5465\n",
      "Epoch 1823/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3628008.0380 - val_loss: 4815044.5213\n",
      "Epoch 1824/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3631637.5879 - val_loss: 4792347.1745\n",
      "Epoch 1825/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3627505.3728 - val_loss: 4788730.2525\n",
      "Epoch 1826/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3628063.9445 - val_loss: 4828185.6816\n",
      "Epoch 1827/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3628105.9319 - val_loss: 4798197.1411\n",
      "Epoch 1828/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3630208.8840 - val_loss: 4785932.0195\n",
      "Epoch 1829/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3627012.8585 - val_loss: 4798184.6746\n",
      "Epoch 1830/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3630188.7688 - val_loss: 4789630.4444\n",
      "Epoch 1831/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3632250.4696 - val_loss: 4815620.0028\n",
      "Epoch 1832/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3631278.0012 - val_loss: 4810719.0192\n",
      "Epoch 1833/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3630569.0363 - val_loss: 4797232.6619\n",
      "Epoch 1834/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3627412.6232 - val_loss: 4800574.0190\n",
      "Epoch 1835/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3627597.0973 - val_loss: 4797617.1051\n",
      "Epoch 1836/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3626546.8474 - val_loss: 4810079.6761\n",
      "Epoch 1837/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3626371.2706 - val_loss: 4801130.3709\n",
      "Epoch 1838/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3630087.8912 - val_loss: 4794871.5711\n",
      "Epoch 1839/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3628192.9905 - val_loss: 4800904.9473\n",
      "Epoch 1840/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3626693.6900 - val_loss: 4787571.6663\n",
      "Epoch 1841/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3629848.9553 - val_loss: 4798201.2002\n",
      "Epoch 1842/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3626395.6344 - val_loss: 4807983.2046\n",
      "Epoch 1843/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3625027.8490 - val_loss: 4802182.9274\n",
      "Epoch 1844/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3630229.6629 - val_loss: 4804705.7527\n",
      "Epoch 1845/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3628589.4376 - val_loss: 4807961.6954\n",
      "Epoch 1846/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3626761.3197 - val_loss: 4795800.1200\n",
      "Epoch 1847/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3628837.7721 - val_loss: 4796650.4675\n",
      "Epoch 1848/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3630921.8614 - val_loss: 4790034.3090\n",
      "Epoch 1849/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3628012.9417 - val_loss: 4806907.5555\n",
      "Epoch 1850/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3626013.7540 - val_loss: 4804535.4633\n",
      "Epoch 1851/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3625804.4165 - val_loss: 4796242.0838\n",
      "Epoch 1852/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3625019.2348 - val_loss: 4788315.2899\n",
      "Epoch 1853/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3627407.4380 - val_loss: 4792865.2092\n",
      "Epoch 1854/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3626016.2946 - val_loss: 4799210.5498\n",
      "Epoch 1855/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3626527.8004 - val_loss: 4796846.6674\n",
      "Epoch 1856/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3626016.9123 - val_loss: 4822624.3415\n",
      "Epoch 1857/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3625307.7317 - val_loss: 4794934.3691\n",
      "Epoch 1858/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3625894.6273 - val_loss: 4799924.2176\n",
      "Epoch 1859/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3622775.2798 - val_loss: 4784674.8878\n",
      "Epoch 1860/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3625462.8172 - val_loss: 4801659.0458\n",
      "Epoch 1861/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3623409.2447 - val_loss: 4806545.3251\n",
      "Epoch 1862/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3625030.4942 - val_loss: 4797533.7636\n",
      "Epoch 1863/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3627760.4384 - val_loss: 4793080.2080\n",
      "Epoch 1864/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3624806.8486 - val_loss: 4817946.4969\n",
      "Epoch 1865/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3623885.7182 - val_loss: 4797768.6592\n",
      "Epoch 1866/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3628491.7411 - val_loss: 4814286.9100\n",
      "Epoch 1867/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3628124.6545 - val_loss: 4817041.6888\n",
      "Epoch 1868/5000\n",
      "40850/40850 [==============================] - 1s 21us/sample - loss: 3622813.3065 - val_loss: 4787404.3038\n",
      "Epoch 1869/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3621530.2568 - val_loss: 4810361.6040\n",
      "Epoch 1870/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3627328.5429 - val_loss: 4797548.6999\n",
      "Epoch 1871/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3621259.6078 - val_loss: 4807238.2577\n",
      "Epoch 1872/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3625774.2227 - val_loss: 4796099.4704\n",
      "Epoch 1873/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3624040.8484 - val_loss: 4804949.0581\n",
      "Epoch 1874/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3629124.4202 - val_loss: 4796846.6227\n",
      "Epoch 1875/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3621492.3678 - val_loss: 4797538.8126\n",
      "Epoch 1876/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3623237.6152 - val_loss: 4800282.9345\n",
      "Epoch 1877/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3626478.0504 - val_loss: 4808495.6422\n",
      "Epoch 1878/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3626794.4242 - val_loss: 4787130.4877\n",
      "Epoch 1879/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3626332.3390 - val_loss: 4805558.8479\n",
      "Epoch 1880/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3619806.5718 - val_loss: 4799270.4175\n",
      "Epoch 1881/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3624161.5591 - val_loss: 4799056.9467\n",
      "Epoch 1882/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3624405.4298 - val_loss: 4805186.4061\n",
      "Epoch 1883/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3621481.5338 - val_loss: 4838049.3971\n",
      "Epoch 1884/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3622219.4582 - val_loss: 4801414.4585\n",
      "Epoch 1885/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3623860.9980 - val_loss: 4806245.5288\n",
      "Epoch 1886/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3621657.6767 - val_loss: 4800203.8043\n",
      "Epoch 1887/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3620999.4031 - val_loss: 4792945.7734\n",
      "Epoch 1888/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3623538.8348 - val_loss: 4801325.9696\n",
      "Epoch 1889/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3625786.1804 - val_loss: 4816882.8363\n",
      "Epoch 1890/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3624458.7188 - val_loss: 4791959.7690\n",
      "Epoch 1891/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3622786.9393 - val_loss: 4809047.6163\n",
      "Epoch 1892/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3624972.7131 - val_loss: 4792664.6361\n",
      "Epoch 1893/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3623763.4905 - val_loss: 4812473.7716\n",
      "Epoch 1894/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3622109.9695 - val_loss: 4796633.3772\n",
      "Epoch 1895/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3623064.6449 - val_loss: 4803576.2716\n",
      "Epoch 1896/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3623116.8657 - val_loss: 4818859.1724\n",
      "Epoch 1897/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3623818.8371 - val_loss: 4797585.9921\n",
      "Epoch 1898/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3625411.7900 - val_loss: 4809518.6638\n",
      "Epoch 1899/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3618264.8253 - val_loss: 4793920.9775\n",
      "Epoch 1900/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3621021.0682 - val_loss: 4824819.0930\n",
      "Epoch 1901/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3621360.4746 - val_loss: 4803255.9517\n",
      "Epoch 1902/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3619385.2261 - val_loss: 4805675.9903\n",
      "Epoch 1903/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3618703.6173 - val_loss: 4797254.5571\n",
      "Epoch 1904/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3623924.9371 - val_loss: 4798353.4209\n",
      "Epoch 1905/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3618279.7906 - val_loss: 4804439.6797\n",
      "Epoch 1906/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3618573.1575 - val_loss: 4782319.7339\n",
      "Epoch 1907/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3618557.0401 - val_loss: 4800541.1339\n",
      "Epoch 1908/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3617764.0282 - val_loss: 4804531.7609\n",
      "Epoch 1909/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3619629.7249 - val_loss: 4801467.6178\n",
      "Epoch 1910/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3623695.5837 - val_loss: 4807991.4996\n",
      "Epoch 1911/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3619492.8003 - val_loss: 4789316.3329\n",
      "Epoch 1912/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3617867.8553 - val_loss: 4787918.2474\n",
      "Epoch 1913/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3618231.7543 - val_loss: 4812045.3204\n",
      "Epoch 1914/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3618320.1178 - val_loss: 4797860.8648\n",
      "Epoch 1915/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3617025.9623 - val_loss: 4793541.2677\n",
      "Epoch 1916/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3615276.0225 - val_loss: 4828948.6570\n",
      "Epoch 1917/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3620353.4543 - val_loss: 4811012.7407\n",
      "Epoch 1918/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3615790.9880 - val_loss: 4793185.7148\n",
      "Epoch 1919/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3621883.9128 - val_loss: 4792902.0819\n",
      "Epoch 1920/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3616611.6030 - val_loss: 4795968.7032\n",
      "Epoch 1921/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3624265.7734 - val_loss: 4810520.2573\n",
      "Epoch 1922/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3616948.9171 - val_loss: 4795749.4265\n",
      "Epoch 1923/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3614860.3179 - val_loss: 4823082.9475\n",
      "Epoch 1924/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3619964.1836 - val_loss: 4811159.9519\n",
      "Epoch 1925/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3615139.3248 - val_loss: 4799363.4303\n",
      "Epoch 1926/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3618005.5265 - val_loss: 4811564.4274\n",
      "Epoch 1927/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3621637.9073 - val_loss: 4795035.7882\n",
      "Epoch 1928/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3613823.6670 - val_loss: 4792880.2566\n",
      "Epoch 1929/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3617693.9895 - val_loss: 4800881.5372\n",
      "Epoch 1930/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3615770.2316 - val_loss: 4798491.8314\n",
      "Epoch 1931/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3614303.2754 - val_loss: 4791487.3201\n",
      "Epoch 1932/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3614498.3533 - val_loss: 4804963.5354\n",
      "Epoch 1933/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3613299.3396 - val_loss: 4794884.5649\n",
      "Epoch 1934/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3614972.3007 - val_loss: 4808234.2386\n",
      "Epoch 1935/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3615294.9512 - val_loss: 4803906.7158\n",
      "Epoch 1936/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3614761.4927 - val_loss: 4819036.0035\n",
      "Epoch 1937/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3612738.9693 - val_loss: 4800127.8467\n",
      "Epoch 1938/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3618093.3331 - val_loss: 4800563.6058\n",
      "Epoch 1939/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3617588.6676 - val_loss: 4796521.9394\n",
      "Epoch 1940/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3617618.0562 - val_loss: 4817033.2821\n",
      "Epoch 1941/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3615345.5054 - val_loss: 4801134.1937\n",
      "Epoch 1942/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3617614.7209 - val_loss: 4813466.6581\n",
      "Epoch 1943/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3615659.0118 - val_loss: 4799869.7458\n",
      "Epoch 1944/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3613643.9189 - val_loss: 4807466.3889\n",
      "Epoch 1945/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3616313.9114 - val_loss: 4807979.6637\n",
      "Epoch 1946/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3612968.6071 - val_loss: 4803244.8319\n",
      "Epoch 1947/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3616214.9276 - val_loss: 4807327.1392\n",
      "Epoch 1948/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3611616.0665 - val_loss: 4804653.9888\n",
      "Epoch 1949/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3615827.2755 - val_loss: 4815169.4933\n",
      "Epoch 1950/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3613276.3398 - val_loss: 4819004.3308\n",
      "Epoch 1951/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3616726.5527 - val_loss: 4817233.8377\n",
      "Epoch 1952/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3614161.5643 - val_loss: 4794677.0601\n",
      "Epoch 1953/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3615810.4883 - val_loss: 4821034.9377\n",
      "Epoch 1954/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3615703.8506 - val_loss: 4814860.0123\n",
      "Epoch 1955/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3613332.9144 - val_loss: 4787442.1904\n",
      "Epoch 1956/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3615093.2253 - val_loss: 4814638.9621\n",
      "Epoch 1957/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3612950.1501 - val_loss: 4802657.5560\n",
      "Epoch 1958/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3616159.9794 - val_loss: 4792947.7803\n",
      "Epoch 1959/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3612596.8408 - val_loss: 4805570.4117\n",
      "Epoch 1960/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3616763.9904 - val_loss: 4814914.8287\n",
      "Epoch 1961/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3616500.9682 - val_loss: 4804096.4142\n",
      "Epoch 1962/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3610003.0572 - val_loss: 4793536.9137\n",
      "Epoch 1963/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3614259.9643 - val_loss: 4802089.4008\n",
      "Epoch 1964/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3609805.8815 - val_loss: 4807652.4254\n",
      "Epoch 1965/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3619826.5897 - val_loss: 4812496.8536\n",
      "Epoch 1966/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3618894.1451 - val_loss: 4799714.6562\n",
      "Epoch 1967/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3615075.4063 - val_loss: 4842558.7759\n",
      "Epoch 1968/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3615156.5229 - val_loss: 4796674.0876\n",
      "Epoch 1969/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3611597.4910 - val_loss: 4802200.1562\n",
      "Epoch 1970/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3613864.8557 - val_loss: 4812926.7927\n",
      "Epoch 1971/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3613095.1981 - val_loss: 4805968.0470\n",
      "Epoch 1972/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3612004.4604 - val_loss: 4824072.2162\n",
      "Epoch 1973/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3612386.1040 - val_loss: 4807282.4256\n",
      "Epoch 1974/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3611939.5007 - val_loss: 4813537.6465\n",
      "Epoch 1975/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3612013.0222 - val_loss: 4796445.0317\n",
      "Epoch 1976/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3610342.3562 - val_loss: 4791866.1793\n",
      "Epoch 1977/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3611906.7171 - val_loss: 4788671.5474\n",
      "Epoch 1978/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3611329.2144 - val_loss: 4805040.8656\n",
      "Epoch 1979/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3611111.1751 - val_loss: 4798000.9641\n",
      "Epoch 1980/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3609704.6264 - val_loss: 4808548.5740\n",
      "Epoch 1981/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3611523.5679 - val_loss: 4803395.1471\n",
      "Epoch 1982/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3613689.8406 - val_loss: 4811682.6578\n",
      "Epoch 1983/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3612825.7450 - val_loss: 4806149.8558\n",
      "Epoch 1984/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3615721.9740 - val_loss: 4799774.2441\n",
      "Epoch 1985/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3608020.7724 - val_loss: 4812318.5186\n",
      "Epoch 1986/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3614138.6607 - val_loss: 4784230.4730\n",
      "Epoch 1987/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3613525.7875 - val_loss: 4805583.6817\n",
      "Epoch 1988/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3614465.9205 - val_loss: 4824362.7871\n",
      "Epoch 1989/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3608625.3347 - val_loss: 4775753.9210\n",
      "Epoch 1990/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3611337.8652 - val_loss: 4797869.9324\n",
      "Epoch 1991/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3611025.6388 - val_loss: 4798623.8810\n",
      "Epoch 1992/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3612200.0516 - val_loss: 4798163.4927\n",
      "Epoch 1993/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3610141.3029 - val_loss: 4789855.5245\n",
      "Epoch 1994/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3608599.9854 - val_loss: 4809278.9302\n",
      "Epoch 1995/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3606608.3963 - val_loss: 4820248.2864\n",
      "Epoch 1996/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3612172.7380 - val_loss: 4798623.8148\n",
      "Epoch 1997/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3612820.1253 - val_loss: 4830252.4747\n",
      "Epoch 1998/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3611410.4024 - val_loss: 4801456.3826\n",
      "Epoch 1999/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3610203.0850 - val_loss: 4820887.4863\n",
      "Epoch 2000/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3611278.4664 - val_loss: 4810479.4181\n",
      "Epoch 2001/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3608844.6363 - val_loss: 4820952.5312\n",
      "Epoch 2002/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3609400.8071 - val_loss: 4811548.2957\n",
      "Epoch 2003/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3613304.4251 - val_loss: 4799464.0151\n",
      "Epoch 2004/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3613421.1050 - val_loss: 4780855.7367\n",
      "Epoch 2005/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3609579.6090 - val_loss: 4808385.3524\n",
      "Epoch 2006/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3608944.5587 - val_loss: 4806972.5767\n",
      "Epoch 2007/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3607901.8823 - val_loss: 4792860.7654\n",
      "Epoch 2008/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3608057.6703 - val_loss: 4788878.7575\n",
      "Epoch 2009/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3610651.7480 - val_loss: 4805123.5241\n",
      "Epoch 2010/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3609641.3647 - val_loss: 4806835.6544\n",
      "Epoch 2011/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3609452.3470 - val_loss: 4799569.0372\n",
      "Epoch 2012/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3608254.0700 - val_loss: 4803326.3265\n",
      "Epoch 2013/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3606117.9388 - val_loss: 4793089.6068\n",
      "Epoch 2014/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3608040.8571 - val_loss: 4796506.1254\n",
      "Epoch 2015/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3609343.4316 - val_loss: 4800558.4359\n",
      "Epoch 2016/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3608265.6730 - val_loss: 4797493.3486\n",
      "Epoch 2017/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3605419.1766 - val_loss: 4788246.3715\n",
      "Epoch 2018/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3608443.1828 - val_loss: 4795983.2071\n",
      "Epoch 2019/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3604884.2689 - val_loss: 4797580.8855\n",
      "Epoch 2020/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3604472.4804 - val_loss: 4792974.1161\n",
      "Epoch 2021/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3606898.3736 - val_loss: 4792220.4229\n",
      "Epoch 2022/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3607205.3300 - val_loss: 4802655.9528\n",
      "Epoch 2023/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3607182.4222 - val_loss: 4791689.7712\n",
      "Epoch 2024/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3607568.6177 - val_loss: 4802637.3297\n",
      "Epoch 2025/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3607944.0692 - val_loss: 4792390.5669\n",
      "Epoch 2026/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3607014.8870 - val_loss: 4783302.5095\n",
      "Epoch 2027/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3610430.2425 - val_loss: 4816346.3499\n",
      "Epoch 2028/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3606462.5068 - val_loss: 4811254.7618\n",
      "Epoch 2029/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3609820.2918 - val_loss: 4783430.7343\n",
      "Epoch 2030/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3604496.9223 - val_loss: 4793023.4235\n",
      "Epoch 2031/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3606584.4093 - val_loss: 4802838.5756\n",
      "Epoch 2032/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3603774.6831 - val_loss: 4803090.4567\n",
      "Epoch 2033/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3607595.1828 - val_loss: 4806244.4606\n",
      "Epoch 2034/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3608164.1664 - val_loss: 4793640.8122\n",
      "Epoch 2035/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3611520.4726 - val_loss: 4792212.1284\n",
      "Epoch 2036/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3608010.8020 - val_loss: 4785190.9984\n",
      "Epoch 2037/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3610172.9965 - val_loss: 4799633.7524\n",
      "Epoch 2038/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3603528.3117 - val_loss: 4786294.3560\n",
      "Epoch 2039/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3607011.1033 - val_loss: 4809449.6948\n",
      "Epoch 2040/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3606171.2663 - val_loss: 4794435.5821\n",
      "Epoch 2041/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3606324.1804 - val_loss: 4797184.2644\n",
      "Epoch 2042/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3602636.5785 - val_loss: 4798533.1752\n",
      "Epoch 2043/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3603403.0188 - val_loss: 4808278.3316\n",
      "Epoch 2044/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3608061.1108 - val_loss: 4786023.0668\n",
      "Epoch 2045/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3603182.7502 - val_loss: 4797865.9249\n",
      "Epoch 2046/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3605584.5395 - val_loss: 4798114.4262\n",
      "Epoch 2047/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3604444.9022 - val_loss: 4778393.2580\n",
      "Epoch 2048/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3608806.5749 - val_loss: 4811903.1782\n",
      "Epoch 2049/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3612788.4622 - val_loss: 4782152.3667\n",
      "Epoch 2050/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3604136.9479 - val_loss: 4791009.5410\n",
      "Epoch 2051/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3603034.1829 - val_loss: 4795730.2132\n",
      "Epoch 2052/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3605805.8612 - val_loss: 4810549.3756\n",
      "Epoch 2053/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3604347.3050 - val_loss: 4801377.2751\n",
      "Epoch 2054/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3603478.1552 - val_loss: 4798333.6270\n",
      "Epoch 2055/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3607129.2110 - val_loss: 4794780.1406\n",
      "Epoch 2056/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3607931.5843 - val_loss: 4804048.4157\n",
      "Epoch 2057/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3606428.6009 - val_loss: 4787744.2109\n",
      "Epoch 2058/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3604508.2690 - val_loss: 4801847.0500\n",
      "Epoch 2059/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3605382.6487 - val_loss: 4799530.9975\n",
      "Epoch 2060/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3602666.9153 - val_loss: 4787913.6892\n",
      "Epoch 2061/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3606401.7457 - val_loss: 4805949.9736\n",
      "Epoch 2062/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3604124.1461 - val_loss: 4794016.2433\n",
      "Epoch 2063/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3603046.0895 - val_loss: 4806606.4332\n",
      "Epoch 2064/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3606748.1975 - val_loss: 4803417.7111\n",
      "Epoch 2065/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3608297.6762 - val_loss: 4775251.0661\n",
      "Epoch 2066/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3605526.8172 - val_loss: 4802886.2067\n",
      "Epoch 2067/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3604190.0624 - val_loss: 4783175.3172\n",
      "Epoch 2068/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3605827.7433 - val_loss: 4808890.4054\n",
      "Epoch 2069/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3603087.4017 - val_loss: 4799796.3423\n",
      "Epoch 2070/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3608294.1313 - val_loss: 4798093.5885\n",
      "Epoch 2071/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3601674.6316 - val_loss: 4784516.8383\n",
      "Epoch 2072/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3601899.3441 - val_loss: 4800558.5304\n",
      "Epoch 2073/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3603087.5991 - val_loss: 4782621.2074\n",
      "Epoch 2074/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3606533.3658 - val_loss: 4779307.7963\n",
      "Epoch 2075/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3604075.7345 - val_loss: 4814545.0533\n",
      "Epoch 2076/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3602209.1404 - val_loss: 4793619.5750\n",
      "Epoch 2077/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3604379.0325 - val_loss: 4787093.3773\n",
      "Epoch 2078/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3603063.4598 - val_loss: 4783508.4482\n",
      "Epoch 2079/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3603132.0841 - val_loss: 4803059.7209\n",
      "Epoch 2080/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3602776.7920 - val_loss: 4798400.2425\n",
      "Epoch 2081/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3604141.8659 - val_loss: 4807494.6849\n",
      "Epoch 2082/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3604243.9428 - val_loss: 4809656.6229\n",
      "Epoch 2083/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3605134.1375 - val_loss: 4806817.0308\n",
      "Epoch 2084/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3602677.8815 - val_loss: 4791668.6205\n",
      "Epoch 2085/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3605055.8803 - val_loss: 4795069.6520\n",
      "Epoch 2086/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3603140.7468 - val_loss: 4797199.7341\n",
      "Epoch 2087/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3600678.8159 - val_loss: 4814521.9036\n",
      "Epoch 2088/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3601022.0320 - val_loss: 4784740.4160\n",
      "Epoch 2089/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3603579.5038 - val_loss: 4794057.1621\n",
      "Epoch 2090/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3604368.0847 - val_loss: 4789095.6343\n",
      "Epoch 2091/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3601572.1921 - val_loss: 4817659.2238\n",
      "Epoch 2092/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3604973.5621 - val_loss: 4799285.3870\n",
      "Epoch 2093/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3605998.9868 - val_loss: 4797195.8489\n",
      "Epoch 2094/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3601557.8217 - val_loss: 4813898.2374\n",
      "Epoch 2095/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3602050.9294 - val_loss: 4788182.5633\n",
      "Epoch 2096/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3602054.4473 - val_loss: 4791589.6558\n",
      "Epoch 2097/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3602039.6239 - val_loss: 4812157.4483\n",
      "Epoch 2098/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3601768.4852 - val_loss: 4796504.3566\n",
      "Epoch 2099/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3602072.2712 - val_loss: 4786904.2857\n",
      "Epoch 2100/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3600825.6188 - val_loss: 4806524.7740\n",
      "Epoch 2101/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3606247.5950 - val_loss: 4801584.7292\n",
      "Epoch 2102/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3602261.6651 - val_loss: 4799754.1555\n",
      "Epoch 2103/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3600402.4889 - val_loss: 4797671.4964\n",
      "Epoch 2104/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3599293.5157 - val_loss: 4783713.3544\n",
      "Epoch 2105/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3601428.1749 - val_loss: 4802631.8720\n",
      "Epoch 2106/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3602678.1156 - val_loss: 4809362.8197\n",
      "Epoch 2107/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3599074.8324 - val_loss: 4806238.6577\n",
      "Epoch 2108/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3602705.7269 - val_loss: 4810836.0733\n",
      "Epoch 2109/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3602760.4822 - val_loss: 4786710.8966\n",
      "Epoch 2110/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3604564.0109 - val_loss: 4786882.8049\n",
      "Epoch 2111/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3602112.6270 - val_loss: 4785096.5887\n",
      "Epoch 2112/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3600899.4063 - val_loss: 4789659.8526\n",
      "Epoch 2113/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3598308.5544 - val_loss: 4805964.6741\n",
      "Epoch 2114/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3601991.2174 - val_loss: 4786600.9569\n",
      "Epoch 2115/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3599060.3577 - val_loss: 4805715.3472\n",
      "Epoch 2116/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3600962.5300 - val_loss: 4812707.9790\n",
      "Epoch 2117/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3598699.5309 - val_loss: 4785624.7002\n",
      "Epoch 2118/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3603211.5422 - val_loss: 4800040.9004\n",
      "Epoch 2119/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3597796.9028 - val_loss: 4811845.0093\n",
      "Epoch 2120/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3598270.1615 - val_loss: 4793902.2086\n",
      "Epoch 2121/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3597023.9325 - val_loss: 4815346.8886\n",
      "Epoch 2122/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3599284.0471 - val_loss: 4807149.9291\n",
      "Epoch 2123/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3595666.1061 - val_loss: 4795018.0998\n",
      "Epoch 2124/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3602012.7765 - val_loss: 4786215.5007\n",
      "Epoch 2125/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3597313.9059 - val_loss: 4789277.5824\n",
      "Epoch 2126/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3600835.9095 - val_loss: 4810142.3918\n",
      "Epoch 2127/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3598039.1728 - val_loss: 4798071.4131\n",
      "Epoch 2128/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3601247.4431 - val_loss: 4814580.0803\n",
      "Epoch 2129/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3598860.1040 - val_loss: 4799986.9417\n",
      "Epoch 2130/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3598522.4478 - val_loss: 4810486.1153\n",
      "Epoch 2131/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3599874.3581 - val_loss: 4852352.8902\n",
      "Epoch 2132/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3602773.3546 - val_loss: 4817339.9173\n",
      "Epoch 2133/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3594382.8303 - val_loss: 4792784.0267\n",
      "Epoch 2134/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3598219.7358 - val_loss: 4796511.8035\n",
      "Epoch 2135/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3598844.4221 - val_loss: 4797805.2585\n",
      "Epoch 2136/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3601094.2249 - val_loss: 4792576.9192\n",
      "Epoch 2137/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3597234.9891 - val_loss: 4824051.1319\n",
      "Epoch 2138/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3597138.1404 - val_loss: 4804678.0964\n",
      "Epoch 2139/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3595705.8299 - val_loss: 4808899.9373\n",
      "Epoch 2140/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3596538.2865 - val_loss: 4803135.1313\n",
      "Epoch 2141/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3596187.4022 - val_loss: 4798000.0949\n",
      "Epoch 2142/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3595752.8486 - val_loss: 4816086.5541\n",
      "Epoch 2143/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3593896.7286 - val_loss: 4806945.4459\n",
      "Epoch 2144/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3596531.2158 - val_loss: 4813803.6673\n",
      "Epoch 2145/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3597984.0089 - val_loss: 4795926.8976\n",
      "Epoch 2146/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3595592.7258 - val_loss: 4803141.0673\n",
      "Epoch 2147/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3598292.4924 - val_loss: 4806954.1771\n",
      "Epoch 2148/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3597177.8966 - val_loss: 4801609.7082\n",
      "Epoch 2149/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3595613.9926 - val_loss: 4804581.0988\n",
      "Epoch 2150/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3591794.4471 - val_loss: 4797951.4009\n",
      "Epoch 2151/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3595507.4922 - val_loss: 4812340.2375\n",
      "Epoch 2152/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3595055.1205 - val_loss: 4807960.7523\n",
      "Epoch 2153/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3593854.0833 - val_loss: 4823941.9107\n",
      "Epoch 2154/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3595647.4749 - val_loss: 4811894.9920\n",
      "Epoch 2155/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3596046.8815 - val_loss: 4786894.3336\n",
      "Epoch 2156/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3593719.7566 - val_loss: 4787953.6146\n",
      "Epoch 2157/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3596295.8490 - val_loss: 4825901.7938\n",
      "Epoch 2158/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3597387.1497 - val_loss: 4798390.7019\n",
      "Epoch 2159/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3593284.1784 - val_loss: 4817700.1301\n",
      "Epoch 2160/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3597861.9098 - val_loss: 4795797.3639\n",
      "Epoch 2161/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3596163.5421 - val_loss: 4809717.5217\n",
      "Epoch 2162/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3595964.4079 - val_loss: 4814103.9564\n",
      "Epoch 2163/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3592444.0276 - val_loss: 4804008.0723\n",
      "Epoch 2164/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3596355.9547 - val_loss: 4811319.0860\n",
      "Epoch 2165/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3595602.0527 - val_loss: 4800686.1608\n",
      "Epoch 2166/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3597988.8441 - val_loss: 4806710.3993\n",
      "Epoch 2167/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3594327.7687 - val_loss: 4809056.7117\n",
      "Epoch 2168/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3599637.2062 - val_loss: 4805016.1116\n",
      "Epoch 2169/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3595232.5073 - val_loss: 4802807.9856\n",
      "Epoch 2170/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3595735.6527 - val_loss: 4815284.2985\n",
      "Epoch 2171/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3592540.0995 - val_loss: 4813620.3757\n",
      "Epoch 2172/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3592501.8011 - val_loss: 4817103.8069\n",
      "Epoch 2173/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3599652.8909 - val_loss: 4822267.9717\n",
      "Epoch 2174/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3594973.4612 - val_loss: 4801241.4396\n",
      "Epoch 2175/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3596968.3437 - val_loss: 4812377.0176\n",
      "Epoch 2176/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3592550.8300 - val_loss: 4793821.9058\n",
      "Epoch 2177/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3590156.5000 - val_loss: 4801214.4026\n",
      "Epoch 2178/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3593506.2220 - val_loss: 4782969.4381\n",
      "Epoch 2179/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3593090.0924 - val_loss: 4789010.3095\n",
      "Epoch 2180/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3593999.6299 - val_loss: 4826524.9899\n",
      "Epoch 2181/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3592403.9103 - val_loss: 4810542.5423\n",
      "Epoch 2182/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3594239.7195 - val_loss: 4802689.6127\n",
      "Epoch 2183/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3597726.5355 - val_loss: 4798614.7698\n",
      "Epoch 2184/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3591360.7086 - val_loss: 4827867.6874\n",
      "Epoch 2185/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3593475.5406 - val_loss: 4805986.9959\n",
      "Epoch 2186/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3591722.6759 - val_loss: 4812132.5951\n",
      "Epoch 2187/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3595438.8217 - val_loss: 4808012.5231\n",
      "Epoch 2188/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3595698.9606 - val_loss: 4827190.4806\n",
      "Epoch 2189/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3593838.1791 - val_loss: 4841608.4391\n",
      "Epoch 2190/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3595847.9033 - val_loss: 4809256.9081\n",
      "Epoch 2191/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3591892.5562 - val_loss: 4804524.2726\n",
      "Epoch 2192/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3598578.2844 - val_loss: 4815300.6158\n",
      "Epoch 2193/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3591730.5832 - val_loss: 4814732.5831\n",
      "Epoch 2194/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3591990.6069 - val_loss: 4814177.1309\n",
      "Epoch 2195/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3595661.8927 - val_loss: 4828803.7203\n",
      "Epoch 2196/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3591326.2481 - val_loss: 4810574.0820\n",
      "Epoch 2197/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3593642.5844 - val_loss: 4805960.5120\n",
      "Epoch 2198/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3588817.3365 - val_loss: 4825391.6859\n",
      "Epoch 2199/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3592912.3694 - val_loss: 4813174.4938\n",
      "Epoch 2200/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3592566.2792 - val_loss: 4796012.8786\n",
      "Epoch 2201/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3593443.6884 - val_loss: 4805782.1194\n",
      "Epoch 2202/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3594347.9113 - val_loss: 4838418.5586\n",
      "Epoch 2203/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3590810.5200 - val_loss: 4801426.3208\n",
      "Epoch 2204/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3592623.2171 - val_loss: 4790293.6392\n",
      "Epoch 2205/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3589926.1254 - val_loss: 4798903.8717\n",
      "Epoch 2206/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3593173.0593 - val_loss: 4799795.9461\n",
      "Epoch 2207/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3591831.4622 - val_loss: 4800358.3434\n",
      "Epoch 2208/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3593183.5455 - val_loss: 4845647.7011\n",
      "Epoch 2209/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3592510.4640 - val_loss: 4813518.1491\n",
      "Epoch 2210/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3588733.4779 - val_loss: 4810673.2454\n",
      "Epoch 2211/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3593887.5871 - val_loss: 4818512.1946\n",
      "Epoch 2212/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3589527.9448 - val_loss: 4808069.2084\n",
      "Epoch 2213/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3591871.3469 - val_loss: 4830899.0791\n",
      "Epoch 2214/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3592234.1571 - val_loss: 4825702.1673\n",
      "Epoch 2215/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3591409.0867 - val_loss: 4831327.7792\n",
      "Epoch 2216/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3592727.0012 - val_loss: 4823148.0703\n",
      "Epoch 2217/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3593580.2451 - val_loss: 4788787.1620\n",
      "Epoch 2218/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3593854.8362 - val_loss: 4819223.8966\n",
      "Epoch 2219/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3590439.9569 - val_loss: 4808874.8275\n",
      "Epoch 2220/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3590608.8917 - val_loss: 4796356.7284\n",
      "Epoch 2221/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3587131.1315 - val_loss: 4802746.4190\n",
      "Epoch 2222/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3588616.3354 - val_loss: 4804634.2876\n",
      "Epoch 2223/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3590784.6287 - val_loss: 4822581.2166\n",
      "Epoch 2224/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3588981.7023 - val_loss: 4835184.6712\n",
      "Epoch 2225/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3592218.1101 - val_loss: 4813960.1658\n",
      "Epoch 2226/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3590389.9352 - val_loss: 4826295.2388\n",
      "Epoch 2227/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3587861.8951 - val_loss: 4802730.3629\n",
      "Epoch 2228/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3588367.4418 - val_loss: 4814171.9906\n",
      "Epoch 2229/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3594188.4853 - val_loss: 4808477.5061\n",
      "Epoch 2230/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3586581.5192 - val_loss: 4813098.9598\n",
      "Epoch 2231/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3590013.8078 - val_loss: 4828657.7487\n",
      "Epoch 2232/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3585676.9885 - val_loss: 4839685.8528\n",
      "Epoch 2233/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3590289.3905 - val_loss: 4816324.7075\n",
      "Epoch 2234/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3593443.3153 - val_loss: 4820524.4240\n",
      "Epoch 2235/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3592942.7864 - val_loss: 4819635.3613\n",
      "Epoch 2236/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3589792.8151 - val_loss: 4819546.1312\n",
      "Epoch 2237/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3589163.7577 - val_loss: 4829646.8032\n",
      "Epoch 2238/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3592427.1036 - val_loss: 4831655.1109\n",
      "Epoch 2239/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3588055.6514 - val_loss: 4812609.6617\n",
      "Epoch 2240/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3589617.5485 - val_loss: 4808347.9624\n",
      "Epoch 2241/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3588693.0153 - val_loss: 4831295.5698\n",
      "Epoch 2242/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3589073.4868 - val_loss: 4803226.7140\n",
      "Epoch 2243/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3587635.2833 - val_loss: 4827371.1310\n",
      "Epoch 2244/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3586727.7711 - val_loss: 4877810.9074\n",
      "Epoch 2245/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3590595.0568 - val_loss: 4829614.3932\n",
      "Epoch 2246/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3587007.4798 - val_loss: 4820572.7665\n",
      "Epoch 2247/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3589758.1633 - val_loss: 4796646.1940\n",
      "Epoch 2248/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3586498.8141 - val_loss: 4803769.4615\n",
      "Epoch 2249/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3586513.1812 - val_loss: 4841572.0082\n",
      "Epoch 2250/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3591384.4235 - val_loss: 4801505.5716\n",
      "Epoch 2251/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3586573.0314 - val_loss: 4818556.8738\n",
      "Epoch 2252/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3587803.8395 - val_loss: 4836121.9425\n",
      "Epoch 2253/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3591884.0847 - val_loss: 4812362.4053\n",
      "Epoch 2254/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3588625.1609 - val_loss: 4810235.0062\n",
      "Epoch 2255/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3587300.0199 - val_loss: 4797418.4546\n",
      "Epoch 2256/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3585535.6462 - val_loss: 4821787.6434\n",
      "Epoch 2257/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3587572.5743 - val_loss: 4799548.1280\n",
      "Epoch 2258/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3591006.0888 - val_loss: 4818777.9296\n",
      "Epoch 2259/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3586537.4646 - val_loss: 4801035.9302\n",
      "Epoch 2260/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3584408.1852 - val_loss: 4830315.2842\n",
      "Epoch 2261/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3589958.5603 - val_loss: 4823609.7281\n",
      "Epoch 2262/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3588670.9367 - val_loss: 4791765.8814\n",
      "Epoch 2263/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3586961.5660 - val_loss: 4796348.6872\n",
      "Epoch 2264/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3585063.4789 - val_loss: 4844147.2824\n",
      "Epoch 2265/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3590908.6905 - val_loss: 4830769.0336\n",
      "Epoch 2266/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3587558.2427 - val_loss: 4826252.4032\n",
      "Epoch 2267/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3585403.7167 - val_loss: 4819875.0116\n",
      "Epoch 2268/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3592958.8746 - val_loss: 4821104.2895\n",
      "Epoch 2269/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3589633.4242 - val_loss: 4835249.0943\n",
      "Epoch 2270/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3586626.9378 - val_loss: 4821609.4296\n",
      "Epoch 2271/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3589072.3795 - val_loss: 4829646.9793\n",
      "Epoch 2272/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3590652.8433 - val_loss: 4822404.8713\n",
      "Epoch 2273/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3589064.0216 - val_loss: 4817957.7564\n",
      "Epoch 2274/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3589761.2059 - val_loss: 4809732.4657\n",
      "Epoch 2275/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3589509.6418 - val_loss: 4817433.5712\n",
      "Epoch 2276/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3587923.4791 - val_loss: 4813349.8230\n",
      "Epoch 2277/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3586859.6691 - val_loss: 4823287.8781\n",
      "Epoch 2278/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3586195.0216 - val_loss: 4825010.7385\n",
      "Epoch 2279/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3584368.0757 - val_loss: 4827604.3699\n",
      "Epoch 2280/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3584412.9658 - val_loss: 4826257.1085\n",
      "Epoch 2281/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3588454.5524 - val_loss: 4835280.6486\n",
      "Epoch 2282/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3585286.4947 - val_loss: 4812770.6055\n",
      "Epoch 2283/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3587548.7325 - val_loss: 4820262.7165\n",
      "Epoch 2284/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3585562.5653 - val_loss: 4822298.4941\n",
      "Epoch 2285/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3584985.9939 - val_loss: 4811569.4816\n",
      "Epoch 2286/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3585243.8988 - val_loss: 4812168.4433\n",
      "Epoch 2287/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3582603.2301 - val_loss: 4813867.8330\n",
      "Epoch 2288/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3589377.3649 - val_loss: 4810383.1827\n",
      "Epoch 2289/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3587876.9539 - val_loss: 4810972.2878\n",
      "Epoch 2290/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3585674.6974 - val_loss: 4832213.6395\n",
      "Epoch 2291/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3584867.7547 - val_loss: 4821900.4107\n",
      "Epoch 2292/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3586682.2729 - val_loss: 4827841.9698\n",
      "Epoch 2293/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3587402.8971 - val_loss: 4829705.1576\n",
      "Epoch 2294/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3584158.3781 - val_loss: 4864947.5667\n",
      "Epoch 2295/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3587347.8868 - val_loss: 4840796.4677\n",
      "Epoch 2296/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3583682.4112 - val_loss: 4838644.2128\n",
      "Epoch 2297/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3587681.8343 - val_loss: 4817411.2683\n",
      "Epoch 2298/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3584672.5858 - val_loss: 4832298.7690\n",
      "Epoch 2299/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3589245.1774 - val_loss: 4812929.5455\n",
      "Epoch 2300/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3584026.3748 - val_loss: 4836682.6944\n",
      "Epoch 2301/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3586678.9703 - val_loss: 4818867.9019\n",
      "Epoch 2302/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3585660.4554 - val_loss: 4817370.9248\n",
      "Epoch 2303/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3585217.8451 - val_loss: 4824782.9989\n",
      "Epoch 2304/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3587414.3271 - val_loss: 4806780.1779\n",
      "Epoch 2305/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3583223.9981 - val_loss: 4838580.3350\n",
      "Epoch 2306/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3586748.7018 - val_loss: 4848696.5720\n",
      "Epoch 2307/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3581257.1227 - val_loss: 4827270.8495\n",
      "Epoch 2308/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3581495.2881 - val_loss: 4834941.1929\n",
      "Epoch 2309/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3583071.0074 - val_loss: 4807557.8218\n",
      "Epoch 2310/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3580107.7141 - val_loss: 4814712.8137\n",
      "Epoch 2311/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3584242.7822 - val_loss: 4828836.5127\n",
      "Epoch 2312/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3582721.3642 - val_loss: 4827484.8813\n",
      "Epoch 2313/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3584653.3546 - val_loss: 4831501.4452\n",
      "Epoch 2314/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3582340.2636 - val_loss: 4852699.1800\n",
      "Epoch 2315/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3585655.2666 - val_loss: 4833754.1304\n",
      "Epoch 2316/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3581718.4389 - val_loss: 4818881.5368\n",
      "Epoch 2317/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3582729.5256 - val_loss: 4808231.8623\n",
      "Epoch 2318/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3583457.0762 - val_loss: 4845287.6243\n",
      "Epoch 2319/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3583143.1748 - val_loss: 4833387.3025\n",
      "Epoch 2320/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3585943.4698 - val_loss: 4812672.0912\n",
      "Epoch 2321/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3587055.2041 - val_loss: 4824707.7440\n",
      "Epoch 2322/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3583385.2030 - val_loss: 4813427.0882\n",
      "Epoch 2323/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3588512.9829 - val_loss: 4838342.6218\n",
      "Epoch 2324/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3587979.5206 - val_loss: 4815780.2260\n",
      "Epoch 2325/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3587603.2371 - val_loss: 4834897.4571\n",
      "Epoch 2326/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3581165.3236 - val_loss: 4830986.0263\n",
      "Epoch 2327/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3589161.5846 - val_loss: 4832470.4730\n",
      "Epoch 2328/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3585177.4161 - val_loss: 4817151.8091\n",
      "Epoch 2329/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3585835.8745 - val_loss: 4831351.7508\n",
      "Epoch 2330/5000\n",
      "40850/40850 [==============================] - ETA: 0s - loss: 3564737.628 - 1s 16us/sample - loss: 3580216.8771 - val_loss: 4822093.6257\n",
      "Epoch 2331/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3580448.3938 - val_loss: 4822879.3481\n",
      "Epoch 2332/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3587129.1615 - val_loss: 4814979.5602\n",
      "Epoch 2333/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3582852.7866 - val_loss: 4811562.7921\n",
      "Epoch 2334/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3581070.5876 - val_loss: 4825013.8687\n",
      "Epoch 2335/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3579005.3491 - val_loss: 4855403.5883\n",
      "Epoch 2336/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3582250.7506 - val_loss: 4820604.1265\n",
      "Epoch 2337/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3581578.0709 - val_loss: 4828702.0581\n",
      "Epoch 2338/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3588650.4827 - val_loss: 4822847.4400\n",
      "Epoch 2339/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3586285.5947 - val_loss: 4816349.5913\n",
      "Epoch 2340/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3584577.2552 - val_loss: 4840370.9749\n",
      "Epoch 2341/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3582493.2939 - val_loss: 4837334.3401\n",
      "Epoch 2342/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3585772.0339 - val_loss: 4817336.2740\n",
      "Epoch 2343/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3586259.9228 - val_loss: 4823881.8895\n",
      "Epoch 2344/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3583436.5932 - val_loss: 4829107.4659\n",
      "Epoch 2345/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3581097.9311 - val_loss: 4827774.4153\n",
      "Epoch 2346/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3586240.6040 - val_loss: 4822133.4999\n",
      "Epoch 2347/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3579466.6088 - val_loss: 4846896.0588\n",
      "Epoch 2348/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3580298.0853 - val_loss: 4815688.1157\n",
      "Epoch 2349/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3581778.6445 - val_loss: 4832915.4291\n",
      "Epoch 2350/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3585548.5637 - val_loss: 4805712.1640\n",
      "Epoch 2351/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3585746.9383 - val_loss: 4826762.8400\n",
      "Epoch 2352/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3579980.9971 - val_loss: 4823586.2228\n",
      "Epoch 2353/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3581605.2439 - val_loss: 4853955.0308\n",
      "Epoch 2354/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3582179.0110 - val_loss: 4863768.2396\n",
      "Epoch 2355/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3581889.0853 - val_loss: 4819072.6161\n",
      "Epoch 2356/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3579227.6433 - val_loss: 4831946.8900\n",
      "Epoch 2357/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3583332.5821 - val_loss: 4819804.7169\n",
      "Epoch 2358/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3579770.4326 - val_loss: 4856662.9724\n",
      "Epoch 2359/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3580751.5072 - val_loss: 4831439.0760\n",
      "Epoch 2360/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3580711.9024 - val_loss: 4836736.4048\n",
      "Epoch 2361/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3580313.7294 - val_loss: 4829507.9522\n",
      "Epoch 2362/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3582253.9078 - val_loss: 4848831.5802\n",
      "Epoch 2363/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3581055.4638 - val_loss: 4825318.9139\n",
      "Epoch 2364/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3582306.8614 - val_loss: 4827414.1989\n",
      "Epoch 2365/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3579422.8167 - val_loss: 4853291.6403\n",
      "Epoch 2366/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3582243.0391 - val_loss: 4846061.1241\n",
      "Epoch 2367/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3580539.3526 - val_loss: 4842289.4530\n",
      "Epoch 2368/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3580828.1533 - val_loss: 4828220.0843\n",
      "Epoch 2369/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3583351.5270 - val_loss: 4833281.2575\n",
      "Epoch 2370/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3579780.3491 - val_loss: 4819740.6612\n",
      "Epoch 2371/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3578538.4649 - val_loss: 4849299.4917\n",
      "Epoch 2372/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3579667.6785 - val_loss: 4849772.5885\n",
      "Epoch 2373/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3582169.0363 - val_loss: 4829108.5271\n",
      "Epoch 2374/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3578389.6107 - val_loss: 4826334.7738\n",
      "Epoch 2375/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3580095.9185 - val_loss: 4820322.2238\n",
      "Epoch 2376/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3581290.2133 - val_loss: 4828231.5192\n",
      "Epoch 2377/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3580483.4054 - val_loss: 4829293.1124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2378/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3578042.5868 - val_loss: 4814738.5823\n",
      "Epoch 2379/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3582658.4121 - val_loss: 4832985.6124\n",
      "Epoch 2380/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3583064.3207 - val_loss: 4851952.2285\n",
      "Epoch 2381/5000\n",
      "40850/40850 [==============================] - ETA: 0s - loss: 3576053.490 - 1s 17us/sample - loss: 3579898.2039 - val_loss: 4840317.0962\n",
      "Epoch 2382/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3577054.5011 - val_loss: 4820241.5611\n",
      "Epoch 2383/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3580823.5220 - val_loss: 4818957.8724\n",
      "Epoch 2384/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3575499.8230 - val_loss: 4837951.4315\n",
      "Epoch 2385/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3577069.6962 - val_loss: 4846732.7539\n",
      "Epoch 2386/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3583139.2847 - val_loss: 4842196.2207\n",
      "Epoch 2387/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3579795.5031 - val_loss: 4819223.3843\n",
      "Epoch 2388/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3576893.6198 - val_loss: 4849558.8307\n",
      "Epoch 2389/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3578894.7256 - val_loss: 4848458.2787\n",
      "Epoch 2390/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3576738.4846 - val_loss: 4845125.4691\n",
      "Epoch 2391/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3581121.2736 - val_loss: 4832184.8337\n",
      "Epoch 2392/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3578508.2652 - val_loss: 4835855.3436\n",
      "Epoch 2393/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3578542.6728 - val_loss: 4831890.8796\n",
      "Epoch 2394/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3576794.0920 - val_loss: 4848144.0460\n",
      "Epoch 2395/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3579584.7207 - val_loss: 4827223.6990\n",
      "Epoch 2396/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3582196.4066 - val_loss: 4861432.6897\n",
      "Epoch 2397/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3578408.7887 - val_loss: 4833614.9374\n",
      "Epoch 2398/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3577538.3853 - val_loss: 4833278.0351\n",
      "Epoch 2399/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3576248.0192 - val_loss: 4830561.3682\n",
      "Epoch 2400/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3578487.9005 - val_loss: 4838487.4896\n",
      "Epoch 2401/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3578225.2550 - val_loss: 4821061.7270\n",
      "Epoch 2402/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3577551.2092 - val_loss: 4851869.2314\n",
      "Epoch 2403/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3576551.8397 - val_loss: 4833054.5635\n",
      "Epoch 2404/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3580695.6210 - val_loss: 4837399.4631\n",
      "Epoch 2405/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3582017.6617 - val_loss: 4848714.4247\n",
      "Epoch 2406/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3581545.5570 - val_loss: 4841804.5965\n",
      "Epoch 2407/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3577643.1259 - val_loss: 4839435.7449\n",
      "Epoch 2408/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3576625.0615 - val_loss: 4845168.2404\n",
      "Epoch 2409/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3582227.6262 - val_loss: 4837788.8418\n",
      "Epoch 2410/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3577955.7981 - val_loss: 4845905.3208\n",
      "Epoch 2411/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3576812.7279 - val_loss: 4824187.9177\n",
      "Epoch 2412/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3576514.1246 - val_loss: 4829916.8739\n",
      "Epoch 2413/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3578912.5088 - val_loss: 4831008.3916\n",
      "Epoch 2414/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3581296.6178 - val_loss: 4856812.1495\n",
      "Epoch 2415/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3581352.2549 - val_loss: 4850520.7504\n",
      "Epoch 2416/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3580726.9881 - val_loss: 4822073.8879\n",
      "Epoch 2417/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3578602.6492 - val_loss: 4838773.5546\n",
      "Epoch 2418/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3577515.9321 - val_loss: 4832901.3899\n",
      "Epoch 2419/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3576655.8753 - val_loss: 4839931.2839\n",
      "Epoch 2420/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3577634.0874 - val_loss: 4855617.5680\n",
      "Epoch 2421/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3572278.4826 - val_loss: 4848071.1901\n",
      "Epoch 2422/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3579923.5708 - val_loss: 4853808.0766\n",
      "Epoch 2423/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3578017.4485 - val_loss: 4828923.3321\n",
      "Epoch 2424/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3574845.4626 - val_loss: 4836251.2372\n",
      "Epoch 2425/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3581147.1806 - val_loss: 4839637.7607\n",
      "Epoch 2426/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3573559.6244 - val_loss: 4840847.2934\n",
      "Epoch 2427/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3582429.4985 - val_loss: 4837482.5264\n",
      "Epoch 2428/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3577280.8652 - val_loss: 4827011.9452\n",
      "Epoch 2429/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3575163.2812 - val_loss: 4832635.5174\n",
      "Epoch 2430/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3576558.3143 - val_loss: 4831595.2714\n",
      "Epoch 2431/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3577512.8366 - val_loss: 4851229.3298\n",
      "Epoch 2432/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3575136.5877 - val_loss: 4835815.6891\n",
      "Epoch 2433/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3573051.9684 - val_loss: 4829219.0355\n",
      "Epoch 2434/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3574431.5037 - val_loss: 4827995.2731\n",
      "Epoch 2435/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3577852.1230 - val_loss: 4839283.2329\n",
      "Epoch 2436/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3581491.1901 - val_loss: 4843453.6940\n",
      "Epoch 2437/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3573261.3770 - val_loss: 4859112.8616\n",
      "Epoch 2438/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3572581.2529 - val_loss: 4845600.9280\n",
      "Epoch 2439/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3577133.6376 - val_loss: 4836322.5073\n",
      "Epoch 2440/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3577150.8319 - val_loss: 4873702.7924\n",
      "Epoch 2441/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3575828.1701 - val_loss: 4835288.2681\n",
      "Epoch 2442/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3576605.6355 - val_loss: 4831521.0451\n",
      "Epoch 2443/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3576952.3557 - val_loss: 4837050.7432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2444/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3572655.5768 - val_loss: 4844977.5873\n",
      "Epoch 2445/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3573481.1396 - val_loss: 4853830.4086\n",
      "Epoch 2446/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3573602.3567 - val_loss: 4830245.4951\n",
      "Epoch 2447/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3572422.0943 - val_loss: 4841262.9341\n",
      "Epoch 2448/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3574165.8943 - val_loss: 4845800.4603\n",
      "Epoch 2449/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3574707.8065 - val_loss: 4865445.9848\n",
      "Epoch 2450/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3574221.8088 - val_loss: 4830689.6978\n",
      "Epoch 2451/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3572751.5759 - val_loss: 4837433.3499\n",
      "Epoch 2452/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3574254.1387 - val_loss: 4832330.9115\n",
      "Epoch 2453/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3571173.5443 - val_loss: 4829144.8559\n",
      "Epoch 2454/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3576008.0754 - val_loss: 4837956.7300\n",
      "Epoch 2455/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3572076.5760 - val_loss: 4858116.8940\n",
      "Epoch 2456/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3576512.9921 - val_loss: 4859139.6358\n",
      "Epoch 2457/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3574354.8123 - val_loss: 4837483.8569\n",
      "Epoch 2458/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3573077.7654 - val_loss: 4858287.9974\n",
      "Epoch 2459/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3574339.9122 - val_loss: 4839871.2138\n",
      "Epoch 2460/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3571999.8679 - val_loss: 4846528.7798\n",
      "Epoch 2461/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3573434.8983 - val_loss: 4838643.5359\n",
      "Epoch 2462/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3571932.1754 - val_loss: 4831304.8498\n",
      "Epoch 2463/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3570088.7631 - val_loss: 4847517.5419\n",
      "Epoch 2464/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3572381.5200 - val_loss: 4853812.7100\n",
      "Epoch 2465/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3571770.7768 - val_loss: 4845713.4189\n",
      "Epoch 2466/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3574137.8519 - val_loss: 4849857.0697\n",
      "Epoch 2467/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3571027.6991 - val_loss: 4857080.9963\n",
      "Epoch 2468/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3577060.5873 - val_loss: 4849436.8308\n",
      "Epoch 2469/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3573901.7225 - val_loss: 4829117.4670\n",
      "Epoch 2470/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3577617.2561 - val_loss: 4827858.0336\n",
      "Epoch 2471/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3572608.4117 - val_loss: 4876778.4119\n",
      "Epoch 2472/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3570745.0139 - val_loss: 4855600.0366\n",
      "Epoch 2473/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3573569.6312 - val_loss: 4859245.0808\n",
      "Epoch 2474/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3572323.7846 - val_loss: 4853404.4307\n",
      "Epoch 2475/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3571526.1850 - val_loss: 4842465.0991\n",
      "Epoch 2476/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3574212.6077 - val_loss: 4855755.4589\n",
      "Epoch 2477/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3570293.2187 - val_loss: 4847297.9641\n",
      "Epoch 2478/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3572912.4106 - val_loss: 4851299.1887\n",
      "Epoch 2479/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3573786.3208 - val_loss: 4852238.6559\n",
      "Epoch 2480/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3572162.6610 - val_loss: 4861331.7665\n",
      "Epoch 2481/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3575458.3802 - val_loss: 4850738.7033\n",
      "Epoch 2482/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3571750.8387 - val_loss: 4851085.5839\n",
      "Epoch 2483/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3569179.3552 - val_loss: 4857992.4878\n",
      "Epoch 2484/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3574331.0516 - val_loss: 4835740.1840\n",
      "Epoch 2485/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3572675.8616 - val_loss: 4864906.7375\n",
      "Epoch 2486/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3572595.7795 - val_loss: 4858881.3752\n",
      "Epoch 2487/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3569243.5602 - val_loss: 4863609.5113\n",
      "Epoch 2488/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3570275.8274 - val_loss: 4860954.2247\n",
      "Epoch 2489/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3571652.8431 - val_loss: 4849337.1842\n",
      "Epoch 2490/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3571395.7629 - val_loss: 4863932.3092\n",
      "Epoch 2491/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3569962.4004 - val_loss: 4862157.2040\n",
      "Epoch 2492/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3569199.1674 - val_loss: 4835229.5446\n",
      "Epoch 2493/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3570548.3624 - val_loss: 4824588.1889\n",
      "Epoch 2494/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3572395.1834 - val_loss: 4855693.7069\n",
      "Epoch 2495/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3571936.0237 - val_loss: 4875214.1749\n",
      "Epoch 2496/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3572836.9442 - val_loss: 4841239.0386\n",
      "Epoch 2497/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3569906.0375 - val_loss: 4851880.8369\n",
      "Epoch 2498/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3568940.0066 - val_loss: 4855235.1435\n",
      "Epoch 2499/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3569123.9627 - val_loss: 4858196.4273\n",
      "Epoch 2500/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3568687.0750 - val_loss: 4853463.4466\n",
      "Epoch 2501/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3569552.7918 - val_loss: 4846871.1279\n",
      "Epoch 2502/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3569485.6485 - val_loss: 4894388.9826\n",
      "Epoch 2503/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3573295.8792 - val_loss: 4859455.2413\n",
      "Epoch 2504/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3568573.8099 - val_loss: 4851945.3601\n",
      "Epoch 2505/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3574252.0085 - val_loss: 4862086.4329\n",
      "Epoch 2506/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3567964.2686 - val_loss: 4846227.5041\n",
      "Epoch 2507/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3568755.5587 - val_loss: 4859963.7812\n",
      "Epoch 2508/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3568165.4268 - val_loss: 4835583.4253\n",
      "Epoch 2509/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3567065.3182 - val_loss: 4853219.9085\n",
      "Epoch 2510/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3567268.4765 - val_loss: 4861521.1738\n",
      "Epoch 2511/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3569547.8208 - val_loss: 4856223.1079\n",
      "Epoch 2512/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3573424.8213 - val_loss: 4874774.0903\n",
      "Epoch 2513/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3569419.7781 - val_loss: 4872103.2611\n",
      "Epoch 2514/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3569129.0135 - val_loss: 4848946.9557\n",
      "Epoch 2515/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3571039.8015 - val_loss: 4862834.9996\n",
      "Epoch 2516/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3570392.5044 - val_loss: 4847309.8729\n",
      "Epoch 2517/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3568665.0089 - val_loss: 4853783.5784\n",
      "Epoch 2518/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3566714.1812 - val_loss: 4871969.2052\n",
      "Epoch 2519/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3572865.5401 - val_loss: 4834170.6087\n",
      "Epoch 2520/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3572591.3004 - val_loss: 4849019.2593\n",
      "Epoch 2521/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3572141.5190 - val_loss: 4871704.7307\n",
      "Epoch 2522/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3569549.4404 - val_loss: 4852669.7819\n",
      "Epoch 2523/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3567953.6686 - val_loss: 4886142.5830\n",
      "Epoch 2524/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3569530.0153 - val_loss: 4849721.5405\n",
      "Epoch 2525/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3563221.7084 - val_loss: 4864218.7093\n",
      "Epoch 2526/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3568242.0463 - val_loss: 4866971.6907\n",
      "Epoch 2527/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3569602.8051 - val_loss: 4859703.4851\n",
      "Epoch 2528/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3570407.3229 - val_loss: 4845319.8498\n",
      "Epoch 2529/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3566495.6797 - val_loss: 4858792.3524\n",
      "Epoch 2530/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3564523.2345 - val_loss: 4881857.0468\n",
      "Epoch 2531/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3569727.8126 - val_loss: 4873535.2031\n",
      "Epoch 2532/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3570282.7127 - val_loss: 4875202.6413\n",
      "Epoch 2533/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565051.6116 - val_loss: 4849972.8721\n",
      "Epoch 2534/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3566441.9971 - val_loss: 4884798.0197\n",
      "Epoch 2535/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3569338.1404 - val_loss: 4855584.2173\n",
      "Epoch 2536/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3568393.3306 - val_loss: 4885040.3743\n",
      "Epoch 2537/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3568288.0286 - val_loss: 4866420.1319\n",
      "Epoch 2538/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3573530.9059 - val_loss: 4868724.0154\n",
      "Epoch 2539/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3565286.0071 - val_loss: 4881539.2863\n",
      "Epoch 2540/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3567973.2087 - val_loss: 4859551.3117\n",
      "Epoch 2541/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3566085.4956 - val_loss: 4882194.6003\n",
      "Epoch 2542/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3572830.6089 - val_loss: 4891881.5654\n",
      "Epoch 2543/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3566720.9193 - val_loss: 4863812.4396\n",
      "Epoch 2544/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3567600.2620 - val_loss: 4852282.7622\n",
      "Epoch 2545/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3568222.1493 - val_loss: 4868683.0355\n",
      "Epoch 2546/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3566917.4625 - val_loss: 4876265.5787\n",
      "Epoch 2547/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3568431.9902 - val_loss: 4874155.1565\n",
      "Epoch 2548/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3564533.6766 - val_loss: 4860327.3543\n",
      "Epoch 2549/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3569092.5000 - val_loss: 4859654.2195\n",
      "Epoch 2550/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3563278.3808 - val_loss: 4868249.3055\n",
      "Epoch 2551/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3566991.0672 - val_loss: 4851377.3157\n",
      "Epoch 2552/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3570079.3203 - val_loss: 4887229.7268\n",
      "Epoch 2553/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3565598.0154 - val_loss: 4878651.2481\n",
      "Epoch 2554/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3569976.6361 - val_loss: 4890581.7307\n",
      "Epoch 2555/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3567971.8535 - val_loss: 4855351.6136\n",
      "Epoch 2556/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3567071.3087 - val_loss: 4855815.3171\n",
      "Epoch 2557/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3568229.4788 - val_loss: 4887938.9630\n",
      "Epoch 2558/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3564792.3126 - val_loss: 4854170.2220\n",
      "Epoch 2559/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3565110.1042 - val_loss: 4874685.5131\n",
      "Epoch 2560/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3566801.0293 - val_loss: 4878843.6569\n",
      "Epoch 2561/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3568887.6004 - val_loss: 4857540.5566\n",
      "Epoch 2562/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3565903.1035 - val_loss: 4863831.3360\n",
      "Epoch 2563/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3567227.9899 - val_loss: 4861540.5416\n",
      "Epoch 2564/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3564075.3611 - val_loss: 4884226.2687\n",
      "Epoch 2565/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3561741.3745 - val_loss: 4880452.3472\n",
      "Epoch 2566/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3568732.8735 - val_loss: 4865725.2641\n",
      "Epoch 2567/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3569249.8397 - val_loss: 4887016.4381\n",
      "Epoch 2568/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3565389.6756 - val_loss: 4873195.2439\n",
      "Epoch 2569/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3563862.7518 - val_loss: 4839438.5329\n",
      "Epoch 2570/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3565433.0258 - val_loss: 4871428.8284\n",
      "Epoch 2571/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3569861.2979 - val_loss: 4879976.3081\n",
      "Epoch 2572/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3565672.6701 - val_loss: 4877560.8549\n",
      "Epoch 2573/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3564868.4326 - val_loss: 4891031.3797\n",
      "Epoch 2574/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3565452.4217 - val_loss: 4865350.3892\n",
      "Epoch 2575/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3563971.6162 - val_loss: 4889391.5403\n",
      "Epoch 2576/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3565886.4642 - val_loss: 4882113.3336\n",
      "Epoch 2577/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3569465.6184 - val_loss: 4862438.8629\n",
      "Epoch 2578/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3567122.0091 - val_loss: 4875160.8298\n",
      "Epoch 2579/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3563467.8692 - val_loss: 4880763.0152\n",
      "Epoch 2580/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3564380.2235 - val_loss: 4870615.9494\n",
      "Epoch 2581/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3564998.5466 - val_loss: 4875102.0810\n",
      "Epoch 2582/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3565009.7503 - val_loss: 4873553.2893\n",
      "Epoch 2583/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3565280.4773 - val_loss: 4879429.7744\n",
      "Epoch 2584/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3564287.5311 - val_loss: 4899240.5261\n",
      "Epoch 2585/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3562137.8344 - val_loss: 4873914.9671\n",
      "Epoch 2586/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3564811.6902 - val_loss: 4883608.0668\n",
      "Epoch 2587/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565318.0684 - val_loss: 4868924.9577\n",
      "Epoch 2588/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3563719.1955 - val_loss: 4901412.5671\n",
      "Epoch 2589/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3561585.8754 - val_loss: 4842883.2954\n",
      "Epoch 2590/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3562838.0663 - val_loss: 4869839.4369\n",
      "Epoch 2591/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3566627.8570 - val_loss: 4860221.0633\n",
      "Epoch 2592/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3564148.0245 - val_loss: 4856120.6440\n",
      "Epoch 2593/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3563230.3207 - val_loss: 4870851.3270\n",
      "Epoch 2594/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3565215.5060 - val_loss: 4868300.5375\n",
      "Epoch 2595/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3566134.4193 - val_loss: 4873368.7201\n",
      "Epoch 2596/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565455.1123 - val_loss: 4877485.8571\n",
      "Epoch 2597/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3567751.3390 - val_loss: 4873286.5347\n",
      "Epoch 2598/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565104.8941 - val_loss: 4853693.7173\n",
      "Epoch 2599/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3561947.5324 - val_loss: 4873953.0014\n",
      "Epoch 2600/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565588.8399 - val_loss: 4879620.9016\n",
      "Epoch 2601/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565825.6073 - val_loss: 4882845.5575\n",
      "Epoch 2602/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565869.7099 - val_loss: 4866376.9028\n",
      "Epoch 2603/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3563990.4302 - val_loss: 4883660.3081\n",
      "Epoch 2604/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3563360.9114 - val_loss: 4900067.3333\n",
      "Epoch 2605/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3566915.4531 - val_loss: 4890601.4545\n",
      "Epoch 2606/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3562398.6295 - val_loss: 4887637.5889\n",
      "Epoch 2607/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565521.8500 - val_loss: 4877887.6151\n",
      "Epoch 2608/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3561711.7095 - val_loss: 4871262.0842\n",
      "Epoch 2609/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3562402.7316 - val_loss: 4871602.8543\n",
      "Epoch 2610/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3564431.4508 - val_loss: 4857674.3841\n",
      "Epoch 2611/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565773.7288 - val_loss: 4899083.3966\n",
      "Epoch 2612/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3566652.0376 - val_loss: 4869361.8819\n",
      "Epoch 2613/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3564424.7767 - val_loss: 4870215.3948\n",
      "Epoch 2614/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565640.8045 - val_loss: 4874523.8904\n",
      "Epoch 2615/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3561823.5552 - val_loss: 4854751.9001\n",
      "Epoch 2616/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3563283.7484 - val_loss: 4873125.8016\n",
      "Epoch 2617/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3564290.2253 - val_loss: 4862984.9013\n",
      "Epoch 2618/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3562615.1638 - val_loss: 4879282.3609\n",
      "Epoch 2619/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3561222.9449 - val_loss: 4880795.9374\n",
      "Epoch 2620/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3563340.3476 - val_loss: 4880086.9903\n",
      "Epoch 2621/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3563322.6257 - val_loss: 4884750.8995\n",
      "Epoch 2622/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3567327.2308 - val_loss: 4863826.6918\n",
      "Epoch 2623/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3561503.2111 - val_loss: 4881319.8973\n",
      "Epoch 2624/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3562115.6404 - val_loss: 4897580.2721\n",
      "Epoch 2625/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3560690.6379 - val_loss: 4874099.8194\n",
      "Epoch 2626/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3563097.8029 - val_loss: 4869907.3234\n",
      "Epoch 2627/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3560121.0143 - val_loss: 4852820.5373\n",
      "Epoch 2628/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3561502.3312 - val_loss: 4869419.4625\n",
      "Epoch 2629/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3566939.3173 - val_loss: 4884475.8943\n",
      "Epoch 2630/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3564119.1293 - val_loss: 4860652.7338\n",
      "Epoch 2631/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3564214.4620 - val_loss: 4889889.2095\n",
      "Epoch 2632/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3560956.0554 - val_loss: 4871607.1018\n",
      "Epoch 2633/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3562200.6313 - val_loss: 4886905.0409\n",
      "Epoch 2634/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3567944.0688 - val_loss: 4893279.1534\n",
      "Epoch 2635/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3561880.8610 - val_loss: 4895008.7827\n",
      "Epoch 2636/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3563509.6127 - val_loss: 4871144.7438\n",
      "Epoch 2637/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3561319.3869 - val_loss: 4882593.0495\n",
      "Epoch 2638/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3564846.9594 - val_loss: 4867396.9580\n",
      "Epoch 2639/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3563191.2645 - val_loss: 4884445.4095\n",
      "Epoch 2640/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3561788.7269 - val_loss: 4874687.0994\n",
      "Epoch 2641/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3564272.6495 - val_loss: 4886394.3842\n",
      "Epoch 2642/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3561305.2224 - val_loss: 4875577.2761\n",
      "Epoch 2643/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3563686.1342 - val_loss: 4870870.0920\n",
      "Epoch 2644/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3561878.1347 - val_loss: 4889768.6830\n",
      "Epoch 2645/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3562648.6490 - val_loss: 4860395.7301\n",
      "Epoch 2646/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3560815.2484 - val_loss: 4871573.7788\n",
      "Epoch 2647/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3559370.4838 - val_loss: 4871943.7205\n",
      "Epoch 2648/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3560514.4195 - val_loss: 4892639.9480\n",
      "Epoch 2649/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3563307.6648 - val_loss: 4876265.3631\n",
      "Epoch 2650/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3563826.8051 - val_loss: 4869239.2403\n",
      "Epoch 2651/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3563412.2012 - val_loss: 4902961.4610\n",
      "Epoch 2652/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3561980.0878 - val_loss: 4891599.9983\n",
      "Epoch 2653/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3561609.5953 - val_loss: 4887419.9491\n",
      "Epoch 2654/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3568972.6164 - val_loss: 4886222.4847\n",
      "Epoch 2655/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3561463.7495 - val_loss: 4914305.4149\n",
      "Epoch 2656/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3563530.5063 - val_loss: 4895282.3941\n",
      "Epoch 2657/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3567581.1844 - val_loss: 4873481.9975\n",
      "Epoch 2658/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3560732.2508 - val_loss: 4872469.2621\n",
      "Epoch 2659/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3564722.9172 - val_loss: 4874029.4674\n",
      "Epoch 2660/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3561837.6121 - val_loss: 4877789.4545\n",
      "Epoch 2661/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565278.4415 - val_loss: 4860226.0894\n",
      "Epoch 2662/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3558764.7491 - val_loss: 4875140.8988\n",
      "Epoch 2663/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565549.1803 - val_loss: 4876505.9140\n",
      "Epoch 2664/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3561253.4930 - val_loss: 4932560.3623\n",
      "Epoch 2665/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3559228.7805 - val_loss: 4890903.7002\n",
      "Epoch 2666/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3562078.4778 - val_loss: 4877178.4485\n",
      "Epoch 2667/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3564911.4188 - val_loss: 4887491.7735\n",
      "Epoch 2668/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3563160.5154 - val_loss: 4900258.6673\n",
      "Epoch 2669/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3561316.3791 - val_loss: 4909470.8350\n",
      "Epoch 2670/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3561686.3828 - val_loss: 4868057.8578\n",
      "Epoch 2671/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3558838.4243 - val_loss: 4877042.0717\n",
      "Epoch 2672/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3561349.0259 - val_loss: 4877502.7376\n",
      "Epoch 2673/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3562514.5728 - val_loss: 4871195.5141\n",
      "Epoch 2674/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3559128.8703 - val_loss: 4882028.7628\n",
      "Epoch 2675/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3559626.3035 - val_loss: 4885228.7140\n",
      "Epoch 2676/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3562670.7740 - val_loss: 4866966.7548\n",
      "Epoch 2677/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3563901.0079 - val_loss: 4917817.2915\n",
      "Epoch 2678/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3559001.8842 - val_loss: 4919234.2234\n",
      "Epoch 2679/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3559450.0760 - val_loss: 4888842.5614\n",
      "Epoch 2680/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3559700.0060 - val_loss: 4879066.2334\n",
      "Epoch 2681/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3558724.4355 - val_loss: 4899338.8949\n",
      "Epoch 2682/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3557096.6512 - val_loss: 4891912.4381\n",
      "Epoch 2683/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3567812.7174 - val_loss: 4893084.3732\n",
      "Epoch 2684/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3559258.2904 - val_loss: 4887099.9534\n",
      "Epoch 2685/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3557675.6907 - val_loss: 4899850.6567\n",
      "Epoch 2686/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3558306.3535 - val_loss: 4875286.2577\n",
      "Epoch 2687/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3560615.4951 - val_loss: 4875376.5421\n",
      "Epoch 2688/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3561785.6121 - val_loss: 4890966.5675\n",
      "Epoch 2689/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3563078.4513 - val_loss: 4876634.1068\n",
      "Epoch 2690/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3557638.3817 - val_loss: 4914580.8653\n",
      "Epoch 2691/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3559382.6880 - val_loss: 4892036.4023\n",
      "Epoch 2692/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3560999.6826 - val_loss: 4900789.4009\n",
      "Epoch 2693/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3565565.7525 - val_loss: 4907941.1252\n",
      "Epoch 2694/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3561470.7416 - val_loss: 4921653.4799\n",
      "Epoch 2695/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3561595.0997 - val_loss: 4860023.5478\n",
      "Epoch 2696/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3560336.8304 - val_loss: 4892570.8266\n",
      "Epoch 2697/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3565380.0460 - val_loss: 4903875.1355\n",
      "Epoch 2698/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3558178.9475 - val_loss: 4896315.2196\n",
      "Epoch 2699/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3559956.1955 - val_loss: 4891932.3472\n",
      "Epoch 2700/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3560309.0848 - val_loss: 4876539.7359\n",
      "Epoch 2701/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3559147.7903 - val_loss: 4883585.3789\n",
      "Epoch 2702/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3556610.7600 - val_loss: 4874483.9735\n",
      "Epoch 2703/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3558780.8648 - val_loss: 4898536.3126\n",
      "Epoch 2704/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3563363.2395 - val_loss: 4876356.6543\n",
      "Epoch 2705/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3555707.8423 - val_loss: 4882993.4984\n",
      "Epoch 2706/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3560884.5369 - val_loss: 4881047.6081\n",
      "Epoch 2707/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3559564.7432 - val_loss: 4879132.6422\n",
      "Epoch 2708/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3560367.9859 - val_loss: 4895793.9567\n",
      "Epoch 2709/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3558952.3583 - val_loss: 4869394.6438\n",
      "Epoch 2710/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3561093.5390 - val_loss: 4888123.7210\n",
      "Epoch 2711/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3556856.0173 - val_loss: 4915663.1485\n",
      "Epoch 2712/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3558981.7308 - val_loss: 4886145.4384\n",
      "Epoch 2713/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3556236.4639 - val_loss: 4900797.9443\n",
      "Epoch 2714/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3555239.0876 - val_loss: 4902064.6125\n",
      "Epoch 2715/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3554892.0647 - val_loss: 4899965.8808\n",
      "Epoch 2716/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3563210.4820 - val_loss: 4891074.2509\n",
      "Epoch 2717/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3557458.8838 - val_loss: 4878637.6194\n",
      "Epoch 2718/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3559249.5637 - val_loss: 4886769.2624\n",
      "Epoch 2719/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3558654.9035 - val_loss: 4877094.8839\n",
      "Epoch 2720/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3555429.6907 - val_loss: 4880850.5923\n",
      "Epoch 2721/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3559943.9300 - val_loss: 4887570.6377\n",
      "Epoch 2722/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3558008.7748 - val_loss: 4883899.3475\n",
      "Epoch 2723/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3557669.3703 - val_loss: 4877711.4929\n",
      "Epoch 2724/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3556874.6131 - val_loss: 4878173.7723\n",
      "Epoch 2725/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3558856.6756 - val_loss: 4884299.7069\n",
      "Epoch 2726/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3556393.8176 - val_loss: 4884051.6432\n",
      "Epoch 2727/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3556175.3227 - val_loss: 4891472.9374\n",
      "Epoch 2728/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3556922.0204 - val_loss: 4904697.2578\n",
      "Epoch 2729/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3555276.7293 - val_loss: 4918858.2831\n",
      "Epoch 2730/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3563405.1917 - val_loss: 4889666.0994\n",
      "Epoch 2731/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3556514.0706 - val_loss: 4889046.8356\n",
      "Epoch 2732/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3554726.2078 - val_loss: 4907407.3517\n",
      "Epoch 2733/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3558360.6541 - val_loss: 4897851.9384\n",
      "Epoch 2734/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3557719.1393 - val_loss: 4886449.6033\n",
      "Epoch 2735/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3557253.1972 - val_loss: 4881185.7471\n",
      "Epoch 2736/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3556917.5187 - val_loss: 4882446.5257\n",
      "Epoch 2737/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3559860.9878 - val_loss: 4934755.4411\n",
      "Epoch 2738/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3555520.5566 - val_loss: 4893260.7398\n",
      "Epoch 2739/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3553741.8540 - val_loss: 4904851.1965\n",
      "Epoch 2740/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3556541.7714 - val_loss: 4882015.9837\n",
      "Epoch 2741/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3559254.1330 - val_loss: 4898155.5429\n",
      "Epoch 2742/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3557646.6338 - val_loss: 4878665.7458\n",
      "Epoch 2743/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3556968.2601 - val_loss: 4884581.0000\n",
      "Epoch 2744/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3557255.0409 - val_loss: 4907260.9244\n",
      "Epoch 2745/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3559714.5317 - val_loss: 4900435.5309\n",
      "Epoch 2746/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3554754.0284 - val_loss: 4925343.8571\n",
      "Epoch 2747/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3557796.6694 - val_loss: 4913781.5014\n",
      "Epoch 2748/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3555801.8798 - val_loss: 4897878.5936\n",
      "Epoch 2749/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3556422.8728 - val_loss: 4895079.1071\n",
      "Epoch 2750/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3553600.7094 - val_loss: 4895579.0622\n",
      "Epoch 2751/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3556768.6280 - val_loss: 4905504.2708\n",
      "Epoch 2752/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3557539.3516 - val_loss: 4907106.2269\n",
      "Epoch 2753/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3557533.8563 - val_loss: 4911722.9093\n",
      "Epoch 2754/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3555646.7072 - val_loss: 4891209.7542\n",
      "Epoch 2755/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3554851.3371 - val_loss: 4922891.2537\n",
      "Epoch 2756/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3557532.3075 - val_loss: 4893976.8673\n",
      "Epoch 2757/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3556470.5562 - val_loss: 4896810.1688\n",
      "Epoch 2758/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3560700.0832 - val_loss: 4912077.7613\n",
      "Epoch 2759/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3557140.0740 - val_loss: 4917883.0059\n",
      "Epoch 2760/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3557494.4900 - val_loss: 4907090.1709\n",
      "Epoch 2761/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3558002.9083 - val_loss: 4907194.2151\n",
      "Epoch 2762/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3555894.4503 - val_loss: 4906528.5271\n",
      "Epoch 2763/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3557310.9788 - val_loss: 4911925.4748\n",
      "Epoch 2764/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3555479.3075 - val_loss: 4923626.1027\n",
      "Epoch 2765/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3555939.1216 - val_loss: 4886279.8624\n",
      "Epoch 2766/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3557343.1206 - val_loss: 4884241.8193\n",
      "Epoch 2767/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3554191.6512 - val_loss: 4922739.6706\n",
      "Epoch 2768/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3556420.7359 - val_loss: 4898348.9705\n",
      "Epoch 2769/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3552931.1143 - val_loss: 4903370.9431\n",
      "Epoch 2770/5000\n",
      "40850/40850 [==============================] - ETA: 0s - loss: 3557768.052 - 1s 15us/sample - loss: 3556633.3312 - val_loss: 4908182.1562\n",
      "Epoch 2771/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3557561.0175 - val_loss: 4898441.8208\n",
      "Epoch 2772/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3554405.3551 - val_loss: 4899715.9196\n",
      "Epoch 2773/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3553665.4733 - val_loss: 4900845.0650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2774/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3557146.1697 - val_loss: 4916338.6079\n",
      "Epoch 2775/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3554699.2540 - val_loss: 4908593.9690\n",
      "Epoch 2776/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3553374.2322 - val_loss: 4918818.2118\n",
      "Epoch 2777/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3554133.1247 - val_loss: 4931468.0592\n",
      "Epoch 2778/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3554253.1441 - val_loss: 4891133.7929\n",
      "Epoch 2779/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3553701.0511 - val_loss: 4892039.2388\n",
      "Epoch 2780/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3553826.1053 - val_loss: 4913600.0052\n",
      "Epoch 2781/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3554422.4313 - val_loss: 4901369.0578\n",
      "Epoch 2782/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3555483.9082 - val_loss: 4909469.8717\n",
      "Epoch 2783/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3553613.0229 - val_loss: 4912774.0721\n",
      "Epoch 2784/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3553503.0286 - val_loss: 4891104.4025\n",
      "Epoch 2785/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3558255.6289 - val_loss: 4908237.3991\n",
      "Epoch 2786/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3551812.2570 - val_loss: 4914051.2190\n",
      "Epoch 2787/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3552318.0460 - val_loss: 4917922.6228\n",
      "Epoch 2788/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3556536.8543 - val_loss: 4905640.1797\n",
      "Epoch 2789/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3553112.3122 - val_loss: 4915774.1200\n",
      "Epoch 2790/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3554191.9142 - val_loss: 4921266.1780\n",
      "Epoch 2791/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3554507.3276 - val_loss: 4929906.2061\n",
      "Epoch 2792/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3557229.6985 - val_loss: 4908000.5876\n",
      "Epoch 2793/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3556524.4135 - val_loss: 4892894.5581\n",
      "Epoch 2794/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3554700.5851 - val_loss: 4888750.7595\n",
      "Epoch 2795/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3554697.9301 - val_loss: 4904475.2202\n",
      "Epoch 2796/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3555991.8953 - val_loss: 4924459.7952\n",
      "Epoch 2797/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3554068.3988 - val_loss: 4925859.9462\n",
      "Epoch 2798/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3557435.4808 - val_loss: 4894621.8221\n",
      "Epoch 2799/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3555013.8197 - val_loss: 4921668.3761\n",
      "Epoch 2800/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3555075.2307 - val_loss: 4885959.7875\n",
      "Epoch 2801/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3550897.8980 - val_loss: 4919287.6906\n",
      "Epoch 2802/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3555807.6965 - val_loss: 4928036.2244\n",
      "Epoch 2803/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3552860.2709 - val_loss: 4893259.8929\n",
      "Epoch 2804/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3554721.3699 - val_loss: 4913310.3730\n",
      "Epoch 2805/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3556525.5331 - val_loss: 4896549.9782\n",
      "Epoch 2806/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3556517.7531 - val_loss: 4902910.4158\n",
      "Epoch 2807/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3549373.3176 - val_loss: 4899177.7334\n",
      "Epoch 2808/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3552477.5626 - val_loss: 4921844.2073\n",
      "Epoch 2809/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3550414.8848 - val_loss: 4900008.6848\n",
      "Epoch 2810/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3551585.3656 - val_loss: 4873142.7876\n",
      "Epoch 2811/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3552638.0749 - val_loss: 4900346.2246\n",
      "Epoch 2812/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3552500.4866 - val_loss: 4894866.1889\n",
      "Epoch 2813/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3553956.9920 - val_loss: 4924718.6618\n",
      "Epoch 2814/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3551509.9712 - val_loss: 4966866.0596\n",
      "Epoch 2815/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3557554.5785 - val_loss: 4921683.3139\n",
      "Epoch 2816/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3552337.3804 - val_loss: 4894296.0009\n",
      "Epoch 2817/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3554060.7492 - val_loss: 4892170.8387\n",
      "Epoch 2818/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3553283.1484 - val_loss: 4915641.3055\n",
      "Epoch 2819/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3555477.9484 - val_loss: 4903025.1364\n",
      "Epoch 2820/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3553037.9044 - val_loss: 4893267.0852\n",
      "Epoch 2821/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3553085.6417 - val_loss: 4918736.1605\n",
      "Epoch 2822/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3552314.2744 - val_loss: 4921593.7231\n",
      "Epoch 2823/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3550898.6047 - val_loss: 4948861.5984\n",
      "Epoch 2824/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3553260.7805 - val_loss: 4896159.3116\n",
      "Epoch 2825/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3551808.9083 - val_loss: 4928366.0285\n",
      "Epoch 2826/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3553439.6555 - val_loss: 4875295.3710\n",
      "Epoch 2827/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3552235.6338 - val_loss: 4916191.0175\n",
      "Epoch 2828/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3557652.9272 - val_loss: 4899420.1746\n",
      "Epoch 2829/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3553584.3005 - val_loss: 4906018.8726\n",
      "Epoch 2830/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3550701.2030 - val_loss: 4928689.9570\n",
      "Epoch 2831/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3553691.7394 - val_loss: 4903605.4975\n",
      "Epoch 2832/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3552028.8955 - val_loss: 4928427.3446\n",
      "Epoch 2833/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3551455.8174 - val_loss: 4906351.4679\n",
      "Epoch 2834/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3553394.6694 - val_loss: 4911077.8369\n",
      "Epoch 2835/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3549676.8518 - val_loss: 4902747.1311\n",
      "Epoch 2836/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3553790.5395 - val_loss: 4893656.6879\n",
      "Epoch 2837/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3549463.5984 - val_loss: 4904919.4878\n",
      "Epoch 2838/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3552724.2541 - val_loss: 4909846.5933\n",
      "Epoch 2839/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3549205.2336 - val_loss: 4907577.0575\n",
      "Epoch 2840/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3550435.2604 - val_loss: 4911982.2239\n",
      "Epoch 2841/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3550718.9452 - val_loss: 4906966.7379\n",
      "Epoch 2842/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3551957.9060 - val_loss: 4911195.9560\n",
      "Epoch 2843/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3552595.8128 - val_loss: 4941811.6634\n",
      "Epoch 2844/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3552840.9593 - val_loss: 4919198.6458\n",
      "Epoch 2845/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3552772.8133 - val_loss: 4895638.1861\n",
      "Epoch 2846/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3551353.1956 - val_loss: 4886747.2411\n",
      "Epoch 2847/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3552951.1027 - val_loss: 4923910.8765\n",
      "Epoch 2848/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3550000.7330 - val_loss: 4913954.4707\n",
      "Epoch 2849/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3557010.6504 - val_loss: 4905499.2253\n",
      "Epoch 2850/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3550875.8154 - val_loss: 4901957.4598\n",
      "Epoch 2851/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3552692.8376 - val_loss: 4914718.2383\n",
      "Epoch 2852/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3547441.9732 - val_loss: 4900716.9645\n",
      "Epoch 2853/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548126.6168 - val_loss: 4894489.5739\n",
      "Epoch 2854/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3548045.1269 - val_loss: 4920304.4315\n",
      "Epoch 2855/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3550768.2699 - val_loss: 4939494.8569\n",
      "Epoch 2856/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3554002.7171 - val_loss: 4899106.5657\n",
      "Epoch 2857/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3549493.8194 - val_loss: 4937197.2139\n",
      "Epoch 2858/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3549388.3969 - val_loss: 4908639.7933\n",
      "Epoch 2859/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3549583.3045 - val_loss: 4926811.2768\n",
      "Epoch 2860/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3556036.6289 - val_loss: 4906506.6399\n",
      "Epoch 2861/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3551988.0439 - val_loss: 4907644.8478\n",
      "Epoch 2862/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3552358.8097 - val_loss: 4926994.4863\n",
      "Epoch 2863/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3550543.2625 - val_loss: 4922429.7717\n",
      "Epoch 2864/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3554482.2535 - val_loss: 4910129.4528\n",
      "Epoch 2865/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3550998.8900 - val_loss: 4928351.4477\n",
      "Epoch 2866/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3549594.9859 - val_loss: 4935503.0300\n",
      "Epoch 2867/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3551656.3099 - val_loss: 4910044.4030\n",
      "Epoch 2868/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3547529.4174 - val_loss: 4905708.9054\n",
      "Epoch 2869/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548826.8982 - val_loss: 4926280.9756\n",
      "Epoch 2870/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3549279.4297 - val_loss: 4931205.0147\n",
      "Epoch 2871/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3546196.2190 - val_loss: 4934192.5408\n",
      "Epoch 2872/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3552974.5961 - val_loss: 4900936.1446\n",
      "Epoch 2873/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3548078.8658 - val_loss: 4919422.3356\n",
      "Epoch 2874/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3548908.7699 - val_loss: 4909282.2378\n",
      "Epoch 2875/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3548773.9257 - val_loss: 4920862.5940\n",
      "Epoch 2876/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3550804.2145 - val_loss: 4900440.9212\n",
      "Epoch 2877/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3548949.7123 - val_loss: 4900199.8923\n",
      "Epoch 2878/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3551373.9692 - val_loss: 4906292.5281\n",
      "Epoch 2879/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548270.8222 - val_loss: 4907817.0375\n",
      "Epoch 2880/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3547990.1881 - val_loss: 4933766.6406\n",
      "Epoch 2881/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3548133.3175 - val_loss: 4912294.3548\n",
      "Epoch 2882/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548677.1380 - val_loss: 4904872.7737\n",
      "Epoch 2883/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3549649.2088 - val_loss: 4915100.4099\n",
      "Epoch 2884/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3551376.8293 - val_loss: 4894568.2807\n",
      "Epoch 2885/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3549444.0160 - val_loss: 4901782.6383\n",
      "Epoch 2886/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3549313.6896 - val_loss: 4897922.8390\n",
      "Epoch 2887/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3551314.6768 - val_loss: 4947666.1942\n",
      "Epoch 2888/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3550445.0016 - val_loss: 4903991.3479\n",
      "Epoch 2889/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3546737.8749 - val_loss: 4933661.7065\n",
      "Epoch 2890/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3546935.3125 - val_loss: 4896625.2847\n",
      "Epoch 2891/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3549440.1090 - val_loss: 4913239.5996\n",
      "Epoch 2892/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3549320.6715 - val_loss: 4937815.2055\n",
      "Epoch 2893/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3553964.4825 - val_loss: 4924904.2136\n",
      "Epoch 2894/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3547646.0243 - val_loss: 4933456.6703\n",
      "Epoch 2895/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548016.9320 - val_loss: 4918323.5045\n",
      "Epoch 2896/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548334.9581 - val_loss: 4915704.0494\n",
      "Epoch 2897/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3550653.9942 - val_loss: 4923957.4304\n",
      "Epoch 2898/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3552728.0963 - val_loss: 4932126.1949\n",
      "Epoch 2899/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3546267.2447 - val_loss: 4938901.7596\n",
      "Epoch 2900/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3550854.3300 - val_loss: 4920591.4107\n",
      "Epoch 2901/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3547587.6893 - val_loss: 4912344.0662\n",
      "Epoch 2902/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3549133.9833 - val_loss: 4909332.5714\n",
      "Epoch 2903/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3547374.1827 - val_loss: 4912204.8115\n",
      "Epoch 2904/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3549279.8949 - val_loss: 4917210.1580\n",
      "Epoch 2905/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3547757.4687 - val_loss: 4907166.3672\n",
      "Epoch 2906/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3546325.5836 - val_loss: 4913304.2562\n",
      "Epoch 2907/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3546996.7350 - val_loss: 4914202.0293\n",
      "Epoch 2908/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3552936.0226 - val_loss: 4914550.3307\n",
      "Epoch 2909/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3548035.7668 - val_loss: 4909350.7203\n",
      "Epoch 2910/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548876.4223 - val_loss: 4940406.0303\n",
      "Epoch 2911/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3546394.0015 - val_loss: 4910587.6614\n",
      "Epoch 2912/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3549188.0009 - val_loss: 4899331.5225\n",
      "Epoch 2913/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3547984.6163 - val_loss: 4905885.1592\n",
      "Epoch 2914/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3552971.2430 - val_loss: 4912443.9502\n",
      "Epoch 2915/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3550276.3946 - val_loss: 4942088.0823\n",
      "Epoch 2916/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3551549.0836 - val_loss: 4914730.0138\n",
      "Epoch 2917/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3546286.1354 - val_loss: 4890383.7908\n",
      "Epoch 2918/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3547666.4587 - val_loss: 4910688.9710\n",
      "Epoch 2919/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3547993.8733 - val_loss: 4920333.8077\n",
      "Epoch 2920/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3544924.2793 - val_loss: 4933860.7026\n",
      "Epoch 2921/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3546793.3053 - val_loss: 4917612.5038\n",
      "Epoch 2922/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3548078.2222 - val_loss: 4918709.5500\n",
      "Epoch 2923/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548264.1421 - val_loss: 4933804.7459\n",
      "Epoch 2924/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3544965.8034 - val_loss: 4923009.2743\n",
      "Epoch 2925/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3544774.7407 - val_loss: 4954583.9400\n",
      "Epoch 2926/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3547761.2338 - val_loss: 4924969.7660\n",
      "Epoch 2927/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3549260.6974 - val_loss: 4937423.5351\n",
      "Epoch 2928/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3549127.5296 - val_loss: 4932158.5425\n",
      "Epoch 2929/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548258.2172 - val_loss: 4902392.1679\n",
      "Epoch 2930/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3545547.4597 - val_loss: 4927247.4020\n",
      "Epoch 2931/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3545232.6999 - val_loss: 4915801.7680\n",
      "Epoch 2932/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3546639.3919 - val_loss: 4923408.9855\n",
      "Epoch 2933/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3546567.3218 - val_loss: 4916726.2669\n",
      "Epoch 2934/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3545528.3999 - val_loss: 4936311.6921\n",
      "Epoch 2935/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3546324.6568 - val_loss: 4915796.1844\n",
      "Epoch 2936/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3548087.1305 - val_loss: 4918805.8442\n",
      "Epoch 2937/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3544594.9465 - val_loss: 4919506.2544\n",
      "Epoch 2938/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3548840.6560 - val_loss: 4941309.9351\n",
      "Epoch 2939/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3543941.4559 - val_loss: 4920775.9707\n",
      "Epoch 2940/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548419.3288 - val_loss: 4917422.3211\n",
      "Epoch 2941/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3547575.0565 - val_loss: 4923520.4956\n",
      "Epoch 2942/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3546945.3006 - val_loss: 4927054.7186\n",
      "Epoch 2943/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3549952.5165 - val_loss: 4951078.0755\n",
      "Epoch 2944/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3548142.8164 - val_loss: 4931566.9920\n",
      "Epoch 2945/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3547737.9641 - val_loss: 4921308.3889\n",
      "Epoch 2946/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3545972.1519 - val_loss: 4911441.4909\n",
      "Epoch 2947/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3546064.4388 - val_loss: 4923502.9269\n",
      "Epoch 2948/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3541840.9268 - val_loss: 4939574.7226\n",
      "Epoch 2949/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3545764.2853 - val_loss: 4929371.3191\n",
      "Epoch 2950/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3544712.7074 - val_loss: 4942277.4573\n",
      "Epoch 2951/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548475.4131 - val_loss: 4908843.2307\n",
      "Epoch 2952/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3543605.2535 - val_loss: 4912062.9089\n",
      "Epoch 2953/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3547835.7865 - val_loss: 4941072.4177\n",
      "Epoch 2954/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3547507.0886 - val_loss: 4956476.9187\n",
      "Epoch 2955/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3546841.1344 - val_loss: 4914626.7668\n",
      "Epoch 2956/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3546492.1201 - val_loss: 4902465.1195\n",
      "Epoch 2957/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3547834.3453 - val_loss: 4916477.5867\n",
      "Epoch 2958/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3547664.6339 - val_loss: 4914768.2301\n",
      "Epoch 2959/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3546855.0224 - val_loss: 4918044.3310\n",
      "Epoch 2960/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3547323.8439 - val_loss: 4925899.1557\n",
      "Epoch 2961/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3545327.3832 - val_loss: 4917853.7510\n",
      "Epoch 2962/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3545653.5922 - val_loss: 4935831.4889\n",
      "Epoch 2963/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3548615.2270 - val_loss: 4929133.6849\n",
      "Epoch 2964/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3546845.5865 - val_loss: 4931445.5194\n",
      "Epoch 2965/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3551115.3203 - val_loss: 4919128.3698\n",
      "Epoch 2966/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3550029.5657 - val_loss: 4910540.1193\n",
      "Epoch 2967/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3542267.4136 - val_loss: 4928261.8812\n",
      "Epoch 2968/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3546797.6130 - val_loss: 4934333.3381\n",
      "Epoch 2969/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3549274.9602 - val_loss: 4938577.9942\n",
      "Epoch 2970/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548102.2282 - val_loss: 4954381.2441\n",
      "Epoch 2971/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3546580.5756 - val_loss: 4927832.9238\n",
      "Epoch 2972/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3544102.9624 - val_loss: 4917229.6757\n",
      "Epoch 2973/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3543424.3130 - val_loss: 4925112.1429\n",
      "Epoch 2974/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3548039.1010 - val_loss: 4923726.7998\n",
      "Epoch 2975/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3550673.8447 - val_loss: 4912783.7833\n",
      "Epoch 2976/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3549183.9110 - val_loss: 4942195.0075\n",
      "Epoch 2977/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3546985.1907 - val_loss: 4928827.4635\n",
      "Epoch 2978/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3544353.6569 - val_loss: 4947720.0619\n",
      "Epoch 2979/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3548359.0657 - val_loss: 4937927.9363\n",
      "Epoch 2980/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3546801.1436 - val_loss: 4902684.9079\n",
      "Epoch 2981/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3545033.2527 - val_loss: 4913808.0824\n",
      "Epoch 2982/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3544769.6309 - val_loss: 4939676.7618\n",
      "Epoch 2983/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3549124.0759 - val_loss: 4939779.6845\n",
      "Epoch 2984/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3545257.5959 - val_loss: 4922226.2966\n",
      "Epoch 2985/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3545325.2603 - val_loss: 4931700.8893\n",
      "Epoch 2986/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3545150.4361 - val_loss: 4909312.5796\n",
      "Epoch 2987/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3544745.8274 - val_loss: 4938218.3898\n",
      "Epoch 2988/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3544688.9707 - val_loss: 4957855.9283\n",
      "Epoch 2989/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3545450.1362 - val_loss: 4955953.6650\n",
      "Epoch 2990/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3545359.3107 - val_loss: 4924975.6548\n",
      "Epoch 2991/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3544669.3189 - val_loss: 4900260.3168\n",
      "Epoch 2992/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3548037.3671 - val_loss: 4922481.4083\n",
      "Epoch 2993/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3544823.1430 - val_loss: 4943446.0717\n",
      "Epoch 2994/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3545894.9459 - val_loss: 4925918.2473\n",
      "Epoch 2995/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3546022.2100 - val_loss: 4919263.6651\n",
      "Epoch 2996/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3546860.9676 - val_loss: 4947274.7559\n",
      "Epoch 2997/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3543726.3436 - val_loss: 4929192.3677\n",
      "Epoch 2998/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3544606.7444 - val_loss: 4933065.5711\n",
      "Epoch 2999/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3540743.7779 - val_loss: 4938905.2318\n",
      "Epoch 3000/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3549952.0022 - val_loss: 4901960.6687\n",
      "Epoch 3001/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3543064.8331 - val_loss: 4928182.6475\n",
      "Epoch 3002/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3546869.7810 - val_loss: 4909810.9698\n",
      "Epoch 3003/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3543233.0496 - val_loss: 4939786.4552\n",
      "Epoch 3004/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3542936.4188 - val_loss: 4921166.9917\n",
      "Epoch 3005/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3539566.4928 - val_loss: 4944742.4220\n",
      "Epoch 3006/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3543587.6639 - val_loss: 4928469.9318\n",
      "Epoch 3007/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3545380.0719 - val_loss: 4921218.5047\n",
      "Epoch 3008/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3545416.0219 - val_loss: 4898506.0770\n",
      "Epoch 3009/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3545795.6183 - val_loss: 4922129.2040\n",
      "Epoch 3010/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3544454.6166 - val_loss: 4940293.8542\n",
      "Epoch 3011/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3546088.6482 - val_loss: 4941698.3143\n",
      "Epoch 3012/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3543648.8263 - val_loss: 4942047.6515\n",
      "Epoch 3013/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3544269.9279 - val_loss: 4917554.5549\n",
      "Epoch 3014/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3545789.7559 - val_loss: 4922158.8093\n",
      "Epoch 3015/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3543764.7288 - val_loss: 4931771.5148\n",
      "Epoch 3016/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3544235.7983 - val_loss: 4930538.9985\n",
      "Epoch 3017/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3540446.1623 - val_loss: 4932668.4824\n",
      "Epoch 3018/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3540883.0709 - val_loss: 4914725.5478\n",
      "Epoch 3019/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3542387.0142 - val_loss: 4932436.4584\n",
      "Epoch 3020/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3546816.9757 - val_loss: 4929466.6811\n",
      "Epoch 3021/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3540333.0832 - val_loss: 4930901.5574\n",
      "Epoch 3022/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3541039.2899 - val_loss: 4928876.3360\n",
      "Epoch 3023/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3539641.2155 - val_loss: 4922962.8890\n",
      "Epoch 3024/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3543694.7574 - val_loss: 4938625.3200\n",
      "Epoch 3025/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3540942.6986 - val_loss: 4936313.3283\n",
      "Epoch 3026/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3545778.3735 - val_loss: 4932313.2642\n",
      "Epoch 3027/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3545432.6518 - val_loss: 4932481.8498\n",
      "Epoch 3028/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3544006.0905 - val_loss: 4920977.3833\n",
      "Epoch 3029/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3541240.4920 - val_loss: 4929683.0142\n",
      "Epoch 3030/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3538673.0909 - val_loss: 4948455.7388\n",
      "Epoch 3031/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3540192.4173 - val_loss: 4929802.2254\n",
      "Epoch 3032/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3543061.4018 - val_loss: 4938697.8427\n",
      "Epoch 3033/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3544383.6284 - val_loss: 4919355.9307\n",
      "Epoch 3034/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3540518.0758 - val_loss: 4917659.4915\n",
      "Epoch 3035/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3539707.0370 - val_loss: 4932376.0183\n",
      "Epoch 3036/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3544534.3240 - val_loss: 4932738.4858\n",
      "Epoch 3037/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3542510.4886 - val_loss: 4923570.8576\n",
      "Epoch 3038/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3544206.7253 - val_loss: 4936405.8899\n",
      "Epoch 3039/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3542293.3588 - val_loss: 4924101.8917\n",
      "Epoch 3040/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3538808.1104 - val_loss: 4930092.7201\n",
      "Epoch 3041/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3543899.9188 - val_loss: 4939007.3001\n",
      "Epoch 3042/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3540723.6594 - val_loss: 4946400.1096\n",
      "Epoch 3043/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3538536.0801 - val_loss: 4939651.4131\n",
      "Epoch 3044/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3547282.0414 - val_loss: 4933136.4381\n",
      "Epoch 3045/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3540012.8877 - val_loss: 4920344.6270\n",
      "Epoch 3046/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3539350.0672 - val_loss: 4942533.0274\n",
      "Epoch 3047/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3543363.5058 - val_loss: 4928751.0040\n",
      "Epoch 3048/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3539804.6725 - val_loss: 4951764.3770\n",
      "Epoch 3049/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3537066.7099 - val_loss: 4975769.0044\n",
      "Epoch 3050/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3545697.8561 - val_loss: 4921337.0170\n",
      "Epoch 3051/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3541872.2333 - val_loss: 4934019.7806\n",
      "Epoch 3052/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3540190.1420 - val_loss: 4938184.0000\n",
      "Epoch 3053/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3543306.9865 - val_loss: 4937416.1352\n",
      "Epoch 3054/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3541969.4527 - val_loss: 4955312.3693\n",
      "Epoch 3055/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3543166.2302 - val_loss: 4927514.0424\n",
      "Epoch 3056/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3542531.2852 - val_loss: 4944387.2376\n",
      "Epoch 3057/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3542784.0696 - val_loss: 4934233.0777\n",
      "Epoch 3058/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3538737.2536 - val_loss: 4941547.0617\n",
      "Epoch 3059/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3539056.7129 - val_loss: 4946789.0969\n",
      "Epoch 3060/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3537286.3779 - val_loss: 4919667.1784\n",
      "Epoch 3061/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3544945.3827 - val_loss: 4926802.2708\n",
      "Epoch 3062/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3537649.9971 - val_loss: 4951936.5602\n",
      "Epoch 3063/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3545507.3273 - val_loss: 4949830.5197\n",
      "Epoch 3064/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3542273.8201 - val_loss: 4939729.1108\n",
      "Epoch 3065/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3540666.0136 - val_loss: 4908603.6779\n",
      "Epoch 3066/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3539510.5303 - val_loss: 4936032.4823\n",
      "Epoch 3067/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3538402.6360 - val_loss: 4973998.1819\n",
      "Epoch 3068/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3540737.8630 - val_loss: 4926439.5391\n",
      "Epoch 3069/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3541713.9356 - val_loss: 4932592.2385\n",
      "Epoch 3070/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3539645.5185 - val_loss: 4949042.8232\n",
      "Epoch 3071/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3540549.6418 - val_loss: 4932376.2734\n",
      "Epoch 3072/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3540908.8150 - val_loss: 4958158.5203\n",
      "Epoch 3073/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3542266.8594 - val_loss: 4958993.4846\n",
      "Epoch 3074/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3541354.2136 - val_loss: 4952688.3748\n",
      "Epoch 3075/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3540480.8198 - val_loss: 4950526.7301\n",
      "Epoch 3076/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3537302.8593 - val_loss: 4941005.0017\n",
      "Epoch 3077/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3541338.0768 - val_loss: 4944238.2207\n",
      "Epoch 3078/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3538229.1600 - val_loss: 4936890.3664\n",
      "Epoch 3079/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3542958.1013 - val_loss: 4946623.1079\n",
      "Epoch 3080/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3538959.9955 - val_loss: 4959364.8776\n",
      "Epoch 3081/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3541286.8935 - val_loss: 4949767.8653\n",
      "Epoch 3082/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3537951.1652 - val_loss: 4933891.8041\n",
      "Epoch 3083/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3539771.8194 - val_loss: 4954998.1552\n",
      "Epoch 3084/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3539400.5726 - val_loss: 4953715.6069\n",
      "Epoch 3085/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3537122.0398 - val_loss: 4918583.5567\n",
      "Epoch 3086/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3540382.2312 - val_loss: 4936013.3101\n",
      "Epoch 3087/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3538043.8042 - val_loss: 4963949.2714\n",
      "Epoch 3088/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3537736.3350 - val_loss: 4934913.8748\n",
      "Epoch 3089/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3542763.9406 - val_loss: 4938388.6733\n",
      "Epoch 3090/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3540323.0713 - val_loss: 4965644.4444\n",
      "Epoch 3091/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3541629.8789 - val_loss: 4944567.5417\n",
      "Epoch 3092/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3538697.1233 - val_loss: 4929184.1632\n",
      "Epoch 3093/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3537305.9921 - val_loss: 4954960.0387\n",
      "Epoch 3094/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3539215.7663 - val_loss: 4936583.5112\n",
      "Epoch 3095/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3539294.5413 - val_loss: 4937312.5273\n",
      "Epoch 3096/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3540257.4539 - val_loss: 4945087.0283\n",
      "Epoch 3097/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3541863.9265 - val_loss: 4980668.4728\n",
      "Epoch 3098/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3539518.1807 - val_loss: 4943363.4990\n",
      "Epoch 3099/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3538763.2706 - val_loss: 4955417.7441\n",
      "Epoch 3100/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3535940.4158 - val_loss: 4956163.4941\n",
      "Epoch 3101/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3538350.7320 - val_loss: 4966047.3425\n",
      "Epoch 3102/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3540081.6470 - val_loss: 4985142.8248\n",
      "Epoch 3103/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3539401.9684 - val_loss: 4942069.5735\n",
      "Epoch 3104/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3540448.3491 - val_loss: 4954325.9505\n",
      "Epoch 3105/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3536088.1690 - val_loss: 4980902.6570\n",
      "Epoch 3106/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3537682.9135 - val_loss: 4933879.2665\n",
      "Epoch 3107/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3537423.5961 - val_loss: 4968375.2426\n",
      "Epoch 3108/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3540291.5057 - val_loss: 4962505.9574\n",
      "Epoch 3109/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3537662.3502 - val_loss: 4945577.0104\n",
      "Epoch 3110/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3534632.3179 - val_loss: 4959660.8781\n",
      "Epoch 3111/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3539166.1672 - val_loss: 4940223.9989\n",
      "Epoch 3112/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3539754.3074 - val_loss: 4954342.1530\n",
      "Epoch 3113/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3542246.3952 - val_loss: 4992507.6570\n",
      "Epoch 3114/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3542668.8245 - val_loss: 4933071.4201\n",
      "Epoch 3115/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3539438.7582 - val_loss: 4932818.7879\n",
      "Epoch 3116/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3537170.5740 - val_loss: 4942387.5731\n",
      "Epoch 3117/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3540132.1559 - val_loss: 4964661.5111\n",
      "Epoch 3118/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3536240.8765 - val_loss: 4962703.8584\n",
      "Epoch 3119/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3538053.6464 - val_loss: 4954902.1111\n",
      "Epoch 3120/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3536737.2298 - val_loss: 4945911.3488\n",
      "Epoch 3121/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3539193.4745 - val_loss: 4966571.6477\n",
      "Epoch 3122/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3534396.9223 - val_loss: 4969494.2708\n",
      "Epoch 3123/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3537425.1757 - val_loss: 4979771.4686\n",
      "Epoch 3124/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3540342.9161 - val_loss: 4965224.2070\n",
      "Epoch 3125/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3535107.5876 - val_loss: 4963970.4380\n",
      "Epoch 3126/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3542071.7430 - val_loss: 4949243.4571\n",
      "Epoch 3127/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3533370.7021 - val_loss: 4968835.4606\n",
      "Epoch 3128/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3538441.8466 - val_loss: 4955409.7654\n",
      "Epoch 3129/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3542063.5921 - val_loss: 4941564.7223\n",
      "Epoch 3130/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3536109.2607 - val_loss: 4969966.0828\n",
      "Epoch 3131/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3537496.0055 - val_loss: 4970691.5776\n",
      "Epoch 3132/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3538994.7182 - val_loss: 4952121.8868\n",
      "Epoch 3133/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3534649.0206 - val_loss: 4954682.7692\n",
      "Epoch 3134/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3541502.0263 - val_loss: 4949348.7306\n",
      "Epoch 3135/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3537015.5176 - val_loss: 4982516.3022\n",
      "Epoch 3136/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3537584.6224 - val_loss: 4944105.8051\n",
      "Epoch 3137/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3534536.5397 - val_loss: 4945880.4619\n",
      "Epoch 3138/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3537650.0705 - val_loss: 4994442.8879\n",
      "Epoch 3139/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3535172.1268 - val_loss: 4957961.7694\n",
      "Epoch 3140/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3539134.2089 - val_loss: 4949340.5812\n",
      "Epoch 3141/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3537759.6565 - val_loss: 4932170.2198\n",
      "Epoch 3142/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3537086.7280 - val_loss: 4951092.3655\n",
      "Epoch 3143/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3536946.4197 - val_loss: 4931516.9957\n",
      "Epoch 3144/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3535974.2570 - val_loss: 4951030.1786\n",
      "Epoch 3145/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3535571.1789 - val_loss: 4958139.4752\n",
      "Epoch 3146/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533218.4500 - val_loss: 4971567.7836\n",
      "Epoch 3147/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3542734.7097 - val_loss: 4948191.3143\n",
      "Epoch 3148/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3539564.9599 - val_loss: 4951027.6338\n",
      "Epoch 3149/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533288.8959 - val_loss: 4960319.5660\n",
      "Epoch 3150/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3537825.4878 - val_loss: 4963883.0196\n",
      "Epoch 3151/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3535012.5452 - val_loss: 4974577.5541\n",
      "Epoch 3152/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3540839.6436 - val_loss: 4956709.9168\n",
      "Epoch 3153/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3537718.8881 - val_loss: 4951496.1679\n",
      "Epoch 3154/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3536776.3040 - val_loss: 4943715.4369\n",
      "Epoch 3155/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3537688.1120 - val_loss: 4979667.5903\n",
      "Epoch 3156/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3537820.4604 - val_loss: 4983522.6896\n",
      "Epoch 3157/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3534082.2609 - val_loss: 4966723.2143\n",
      "Epoch 3158/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3540426.2359 - val_loss: 4989063.8609\n",
      "Epoch 3159/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3536788.6026 - val_loss: 5010602.2644\n",
      "Epoch 3160/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3535677.7505 - val_loss: 4985185.8808\n",
      "Epoch 3161/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3537959.9291 - val_loss: 4969238.3234\n",
      "Epoch 3162/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533215.8359 - val_loss: 4959508.6941\n",
      "Epoch 3163/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533625.6810 - val_loss: 4957343.4739\n",
      "Epoch 3164/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3535660.3468 - val_loss: 4970578.0674\n",
      "Epoch 3165/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3535237.6376 - val_loss: 4998583.3615\n",
      "Epoch 3166/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533734.6300 - val_loss: 4981347.1718\n",
      "Epoch 3167/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3536429.6852 - val_loss: 4984695.2689\n",
      "Epoch 3168/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3538169.8466 - val_loss: 4980469.2306\n",
      "Epoch 3169/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3538439.1468 - val_loss: 4963367.8319\n",
      "Epoch 3170/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3536073.2976 - val_loss: 4973010.1523\n",
      "Epoch 3171/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3533708.3638 - val_loss: 4965966.1789\n",
      "Epoch 3172/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3535190.3671 - val_loss: 4981877.5506\n",
      "Epoch 3173/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3535776.5423 - val_loss: 4967075.4789\n",
      "Epoch 3174/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3535238.1154 - val_loss: 4968085.3563\n",
      "Epoch 3175/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3536676.5870 - val_loss: 4969706.4392\n",
      "Epoch 3176/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3535861.6342 - val_loss: 4969714.7734\n",
      "Epoch 3177/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3536127.1105 - val_loss: 4952945.5447\n",
      "Epoch 3178/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3535005.0196 - val_loss: 4953872.6060\n",
      "Epoch 3179/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3535877.3844 - val_loss: 4964747.1686\n",
      "Epoch 3180/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3533503.0221 - val_loss: 4981375.4222\n",
      "Epoch 3181/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3538013.2329 - val_loss: 4990808.1432\n",
      "Epoch 3182/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3537417.8910 - val_loss: 4956578.3898\n",
      "Epoch 3183/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3534173.3888 - val_loss: 4950716.6413\n",
      "Epoch 3184/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3532756.2571 - val_loss: 5002505.4958\n",
      "Epoch 3185/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3535124.1930 - val_loss: 4978023.7039\n",
      "Epoch 3186/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3535938.4471 - val_loss: 4955859.4568\n",
      "Epoch 3187/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3533151.8488 - val_loss: 4970517.3855\n",
      "Epoch 3188/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3531026.6131 - val_loss: 4959839.3846\n",
      "Epoch 3189/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3533027.2064 - val_loss: 4963451.4972\n",
      "Epoch 3190/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3538448.4523 - val_loss: 4977161.8641\n",
      "Epoch 3191/5000\n",
      "40850/40850 [==============================] - 1s 12us/sample - loss: 3536059.6958 - val_loss: 4997298.1284\n",
      "Epoch 3192/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3535708.0351 - val_loss: 4980473.6203\n",
      "Epoch 3193/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3534850.2099 - val_loss: 4980373.3639\n",
      "Epoch 3194/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3537911.7747 - val_loss: 4991990.8633\n",
      "Epoch 3195/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3537240.7511 - val_loss: 4980869.0070\n",
      "Epoch 3196/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3534493.4761 - val_loss: 4968078.5811\n",
      "Epoch 3197/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3533626.8189 - val_loss: 4979966.3122\n",
      "Epoch 3198/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3532294.7370 - val_loss: 4982311.4914\n",
      "Epoch 3199/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3532726.7611 - val_loss: 4985196.2429\n",
      "Epoch 3200/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3533735.9943 - val_loss: 4954198.0497\n",
      "Epoch 3201/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3538672.1026 - val_loss: 4957998.0427\n",
      "Epoch 3202/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3535863.1156 - val_loss: 4985755.9965\n",
      "Epoch 3203/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3534649.0360 - val_loss: 4978751.2521\n",
      "Epoch 3204/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3532429.3059 - val_loss: 4973696.8754\n",
      "Epoch 3205/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3538229.4329 - val_loss: 4977207.6370\n",
      "Epoch 3206/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3534080.3727 - val_loss: 4977086.5798\n",
      "Epoch 3207/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3536385.9733 - val_loss: 4985143.3520\n",
      "Epoch 3208/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3530190.3462 - val_loss: 4958207.7396\n",
      "Epoch 3209/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3530054.9440 - val_loss: 5007243.0350\n",
      "Epoch 3210/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3533119.2789 - val_loss: 4995450.9886\n",
      "Epoch 3211/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3530986.8971 - val_loss: 4981995.2165\n",
      "Epoch 3212/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3531669.1854 - val_loss: 4959159.1066\n",
      "Epoch 3213/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3536558.5282 - val_loss: 4969935.0715\n",
      "Epoch 3214/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3533677.8967 - val_loss: 4965985.9154\n",
      "Epoch 3215/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533899.5518 - val_loss: 4981260.7939\n",
      "Epoch 3216/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3532855.4227 - val_loss: 4974587.8730\n",
      "Epoch 3217/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3536242.9244 - val_loss: 4972834.4109\n",
      "Epoch 3218/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3531411.3932 - val_loss: 4973895.4548\n",
      "Epoch 3219/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3531428.4929 - val_loss: 4964690.1872\n",
      "Epoch 3220/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3532443.8899 - val_loss: 4978806.9857\n",
      "Epoch 3221/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3532411.4270 - val_loss: 4983600.0910\n",
      "Epoch 3222/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3530909.2192 - val_loss: 4969470.6883\n",
      "Epoch 3223/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533575.2242 - val_loss: 4972118.0451\n",
      "Epoch 3224/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3536929.2647 - val_loss: 4964572.6633\n",
      "Epoch 3225/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3530857.9980 - val_loss: 5009063.9166\n",
      "Epoch 3226/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3532580.0872 - val_loss: 4952590.1773\n",
      "Epoch 3227/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3531907.0044 - val_loss: 4994523.2971\n",
      "Epoch 3228/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3534185.3163 - val_loss: 4986197.9669\n",
      "Epoch 3229/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3532073.4945 - val_loss: 5024819.6536\n",
      "Epoch 3230/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3533924.6636 - val_loss: 4962777.7943\n",
      "Epoch 3231/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3532396.6144 - val_loss: 4956022.2201\n",
      "Epoch 3232/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3536548.7193 - val_loss: 4969599.1357\n",
      "Epoch 3233/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3531787.0898 - val_loss: 4963340.6289\n",
      "Epoch 3234/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3532226.1510 - val_loss: 4988011.6189\n",
      "Epoch 3235/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3532376.2763 - val_loss: 4981621.6419\n",
      "Epoch 3236/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3537586.1636 - val_loss: 5003774.7102\n",
      "Epoch 3237/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3533981.3934 - val_loss: 4963201.6175\n",
      "Epoch 3238/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3537196.9322 - val_loss: 4959785.5987\n",
      "Epoch 3239/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3536130.8255 - val_loss: 4986779.6191\n",
      "Epoch 3240/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3531417.3130 - val_loss: 4959929.1501\n",
      "Epoch 3241/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3535851.7833 - val_loss: 4978836.9988\n",
      "Epoch 3242/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3532322.2021 - val_loss: 4963309.2640\n",
      "Epoch 3243/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3534947.5328 - val_loss: 4982926.3666\n",
      "Epoch 3244/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3533446.7071 - val_loss: 4999431.5901\n",
      "Epoch 3245/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3534792.2671 - val_loss: 5004728.6669\n",
      "Epoch 3246/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3537634.3013 - val_loss: 4985457.2720\n",
      "Epoch 3247/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3535980.5175 - val_loss: 4971785.5627\n",
      "Epoch 3248/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3538645.2011 - val_loss: 4984860.6391\n",
      "Epoch 3249/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3531653.6755 - val_loss: 4982062.7941\n",
      "Epoch 3250/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3530025.6064 - val_loss: 5013018.4745\n",
      "Epoch 3251/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3531250.8783 - val_loss: 5014029.4839\n",
      "Epoch 3252/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3527004.4626 - val_loss: 4986228.6901\n",
      "Epoch 3253/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3530605.3144 - val_loss: 4993066.7567\n",
      "Epoch 3254/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529207.7488 - val_loss: 5017222.0120\n",
      "Epoch 3255/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3531701.0542 - val_loss: 5042398.9639\n",
      "Epoch 3256/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3534935.8352 - val_loss: 4980738.6575\n",
      "Epoch 3257/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533719.1367 - val_loss: 4988118.9085\n",
      "Epoch 3258/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3531333.6022 - val_loss: 4978109.6682\n",
      "Epoch 3259/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3530197.2008 - val_loss: 5013827.6805\n",
      "Epoch 3260/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3535611.0974 - val_loss: 4957247.1104\n",
      "Epoch 3261/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529656.3896 - val_loss: 4965820.5073\n",
      "Epoch 3262/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3531350.3969 - val_loss: 4959905.6307\n",
      "Epoch 3263/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3538850.1902 - val_loss: 4960848.4718\n",
      "Epoch 3264/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3531856.2642 - val_loss: 5014512.1687\n",
      "Epoch 3265/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3530329.0728 - val_loss: 4991856.1806\n",
      "Epoch 3266/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3532094.9090 - val_loss: 4999821.6436\n",
      "Epoch 3267/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3530078.3714 - val_loss: 5004407.5018\n",
      "Epoch 3268/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3534660.5041 - val_loss: 4957143.2407\n",
      "Epoch 3269/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3532488.4305 - val_loss: 4968812.4696\n",
      "Epoch 3270/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3529082.1479 - val_loss: 4976393.0817\n",
      "Epoch 3271/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3530110.2377 - val_loss: 4980409.3844\n",
      "Epoch 3272/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3531482.9257 - val_loss: 5021107.4245\n",
      "Epoch 3273/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3533259.7089 - val_loss: 4988823.2585\n",
      "Epoch 3274/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3532126.2775 - val_loss: 4982317.9869\n",
      "Epoch 3275/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3532212.1071 - val_loss: 4990030.1976\n",
      "Epoch 3276/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3535730.9640 - val_loss: 4993134.5177\n",
      "Epoch 3277/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3531242.4536 - val_loss: 4979620.9256\n",
      "Epoch 3278/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3528155.5116 - val_loss: 4994648.7179\n",
      "Epoch 3279/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3531848.1483 - val_loss: 4980909.7188\n",
      "Epoch 3280/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3534647.0590 - val_loss: 5006078.6569\n",
      "Epoch 3281/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3531603.4541 - val_loss: 4985598.7043\n",
      "Epoch 3282/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529640.0074 - val_loss: 5023234.6163\n",
      "Epoch 3283/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3530844.0003 - val_loss: 5007393.1555\n",
      "Epoch 3284/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533496.6623 - val_loss: 4985729.8404\n",
      "Epoch 3285/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3532482.9932 - val_loss: 4976757.1046\n",
      "Epoch 3286/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3532686.6893 - val_loss: 4992868.5832\n",
      "Epoch 3287/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3530493.2599 - val_loss: 4983536.7619\n",
      "Epoch 3288/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527993.0947 - val_loss: 5018694.0533\n",
      "Epoch 3289/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528229.5734 - val_loss: 4999825.5715\n",
      "Epoch 3290/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3529582.9983 - val_loss: 4989766.3089\n",
      "Epoch 3291/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3530614.8482 - val_loss: 4984675.9840\n",
      "Epoch 3292/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3532148.8348 - val_loss: 5001692.2800\n",
      "Epoch 3293/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3531708.6008 - val_loss: 4994619.8260\n",
      "Epoch 3294/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3526408.7743 - val_loss: 4986288.1024\n",
      "Epoch 3295/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533629.4834 - val_loss: 4982986.9897\n",
      "Epoch 3296/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528210.5350 - val_loss: 4967023.3287\n",
      "Epoch 3297/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3534625.1662 - val_loss: 4983714.0657\n",
      "Epoch 3298/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527621.2292 - val_loss: 4963627.6824\n",
      "Epoch 3299/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3533343.8583 - val_loss: 4979826.1002\n",
      "Epoch 3300/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3526510.2246 - val_loss: 5011058.4117\n",
      "Epoch 3301/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3532751.5559 - val_loss: 4974482.7798\n",
      "Epoch 3302/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3534860.3213 - val_loss: 4977903.7398\n",
      "Epoch 3303/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3531678.9223 - val_loss: 4993860.9079\n",
      "Epoch 3304/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3531131.0413 - val_loss: 4954603.8446\n",
      "Epoch 3305/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528372.0578 - val_loss: 4987129.2532\n",
      "Epoch 3306/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528316.0646 - val_loss: 4986028.6353\n",
      "Epoch 3307/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533309.6033 - val_loss: 5010645.2084\n",
      "Epoch 3308/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3532412.6712 - val_loss: 4959906.7753\n",
      "Epoch 3309/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3532909.5339 - val_loss: 5036453.0338\n",
      "Epoch 3310/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533763.7303 - val_loss: 4993473.2339\n",
      "Epoch 3311/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529981.5708 - val_loss: 4991752.7470\n",
      "Epoch 3312/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527146.3247 - val_loss: 5001749.6358\n",
      "Epoch 3313/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529630.4934 - val_loss: 5004869.7782\n",
      "Epoch 3314/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529722.3035 - val_loss: 4980201.4639\n",
      "Epoch 3315/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3529458.2967 - val_loss: 4982199.7205\n",
      "Epoch 3316/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3526503.9438 - val_loss: 5000072.6959\n",
      "Epoch 3317/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3528686.2316 - val_loss: 4993476.6760\n",
      "Epoch 3318/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3526747.8228 - val_loss: 4963236.0798\n",
      "Epoch 3319/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3530388.4211 - val_loss: 5000482.8583\n",
      "Epoch 3320/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3532337.1001 - val_loss: 5010421.0566\n",
      "Epoch 3321/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3529888.1976 - val_loss: 5003060.2225\n",
      "Epoch 3322/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3528547.7066 - val_loss: 5014328.8918\n",
      "Epoch 3323/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529832.4208 - val_loss: 4997858.0982\n",
      "Epoch 3324/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527701.6275 - val_loss: 5005028.1464\n",
      "Epoch 3325/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3535394.2234 - val_loss: 4981355.8021\n",
      "Epoch 3326/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527062.1121 - val_loss: 5022381.8611\n",
      "Epoch 3327/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3529007.5184 - val_loss: 4984099.2669\n",
      "Epoch 3328/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3531425.5641 - val_loss: 4977440.1099\n",
      "Epoch 3329/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3531656.1935 - val_loss: 5024394.4032\n",
      "Epoch 3330/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529347.7877 - val_loss: 4996406.8611\n",
      "Epoch 3331/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3530310.7272 - val_loss: 5026332.9899\n",
      "Epoch 3332/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3528369.2924 - val_loss: 4998606.8112\n",
      "Epoch 3333/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3531855.9585 - val_loss: 5000061.9547\n",
      "Epoch 3334/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527417.4526 - val_loss: 5004529.9270\n",
      "Epoch 3335/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3529066.6819 - val_loss: 4981443.8308\n",
      "Epoch 3336/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3529063.2317 - val_loss: 4963565.2076\n",
      "Epoch 3337/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528234.2420 - val_loss: 4963927.6552\n",
      "Epoch 3338/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3525278.2330 - val_loss: 4996154.3640\n",
      "Epoch 3339/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3531256.5103 - val_loss: 4992890.6451\n",
      "Epoch 3340/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3531029.7721 - val_loss: 4982408.2021\n",
      "Epoch 3341/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3533519.8481 - val_loss: 4971421.8399\n",
      "Epoch 3342/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3529343.5758 - val_loss: 5002136.2024\n",
      "Epoch 3343/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3532208.5223 - val_loss: 4969312.3051\n",
      "Epoch 3344/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524828.5144 - val_loss: 4999810.1413\n",
      "Epoch 3345/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3526483.2104 - val_loss: 4985770.4110\n",
      "Epoch 3346/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3528621.4882 - val_loss: 4986998.9241\n",
      "Epoch 3347/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528896.4539 - val_loss: 4978058.0526\n",
      "Epoch 3348/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3531220.3341 - val_loss: 5011646.2789\n",
      "Epoch 3349/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3530524.3083 - val_loss: 4975554.3430\n",
      "Epoch 3350/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3536157.7945 - val_loss: 4959528.4089\n",
      "Epoch 3351/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3527076.9459 - val_loss: 4977051.4041\n",
      "Epoch 3352/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529085.5618 - val_loss: 4968280.1963\n",
      "Epoch 3353/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3531467.4038 - val_loss: 4984889.8977\n",
      "Epoch 3354/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3525794.9188 - val_loss: 4996553.9599\n",
      "Epoch 3355/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3533158.8025 - val_loss: 4995340.7859\n",
      "Epoch 3356/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528898.6116 - val_loss: 4998433.3649\n",
      "Epoch 3357/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3526308.7755 - val_loss: 4976761.9683\n",
      "Epoch 3358/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524515.0288 - val_loss: 5013887.7600\n",
      "Epoch 3359/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529582.8792 - val_loss: 4973124.5514\n",
      "Epoch 3360/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3523654.7396 - val_loss: 4971412.3216\n",
      "Epoch 3361/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524701.3397 - val_loss: 4968852.5483\n",
      "Epoch 3362/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3528736.4552 - val_loss: 4989341.7934\n",
      "Epoch 3363/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3527226.3231 - val_loss: 4985329.1908\n",
      "Epoch 3364/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3526029.5531 - val_loss: 5004557.2701\n",
      "Epoch 3365/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528649.0444 - val_loss: 4970515.9359\n",
      "Epoch 3366/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528857.6676 - val_loss: 5021369.8208\n",
      "Epoch 3367/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3526047.2486 - val_loss: 5015295.0415\n",
      "Epoch 3368/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3526892.8086 - val_loss: 4997567.9294\n",
      "Epoch 3369/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3531546.3958 - val_loss: 4963589.2918\n",
      "Epoch 3370/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3524308.3743 - val_loss: 4999777.1151\n",
      "Epoch 3371/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3526155.2144 - val_loss: 5010010.7997\n",
      "Epoch 3372/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3525652.1206 - val_loss: 4998939.5843\n",
      "Epoch 3373/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3526694.9747 - val_loss: 4980759.7003\n",
      "Epoch 3374/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3525114.1064 - val_loss: 4985530.5843\n",
      "Epoch 3375/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3527844.0122 - val_loss: 5003622.0465\n",
      "Epoch 3376/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3524838.9084 - val_loss: 5003814.6616\n",
      "Epoch 3377/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3524880.3842 - val_loss: 5011370.8613\n",
      "Epoch 3378/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3527594.5880 - val_loss: 5009101.5369\n",
      "Epoch 3379/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3529393.8556 - val_loss: 5003781.1542\n",
      "Epoch 3380/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3530651.0921 - val_loss: 4995619.6476\n",
      "Epoch 3381/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3528088.3205 - val_loss: 5009272.6206\n",
      "Epoch 3382/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3530726.8666 - val_loss: 4992622.5014\n",
      "Epoch 3383/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3528283.2536 - val_loss: 4978923.8096\n",
      "Epoch 3384/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3527801.4608 - val_loss: 4998065.7367\n",
      "Epoch 3385/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3530467.2309 - val_loss: 4975256.8579\n",
      "Epoch 3386/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3527018.5627 - val_loss: 4991669.5479\n",
      "Epoch 3387/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3525856.4086 - val_loss: 5016220.8915\n",
      "Epoch 3388/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3530416.6809 - val_loss: 5006341.9052\n",
      "Epoch 3389/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528910.3250 - val_loss: 4993502.4506\n",
      "Epoch 3390/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527680.8238 - val_loss: 4989208.4649\n",
      "Epoch 3391/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529092.7676 - val_loss: 4980660.5254\n",
      "Epoch 3392/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3525241.6830 - val_loss: 5004068.8378\n",
      "Epoch 3393/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3526867.1754 - val_loss: 5007691.3032\n",
      "Epoch 3394/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528907.7316 - val_loss: 4962649.6863\n",
      "Epoch 3395/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524694.3792 - val_loss: 4989439.8051\n",
      "Epoch 3396/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527298.0758 - val_loss: 5014706.3414\n",
      "Epoch 3397/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3525123.6098 - val_loss: 4996647.4117\n",
      "Epoch 3398/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527294.8602 - val_loss: 4995007.3338\n",
      "Epoch 3399/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3528257.9394 - val_loss: 4997303.9623\n",
      "Epoch 3400/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3523330.6180 - val_loss: 4996690.8874\n",
      "Epoch 3401/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524178.3660 - val_loss: 4972798.7564\n",
      "Epoch 3402/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529277.1163 - val_loss: 4995726.9099\n",
      "Epoch 3403/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3526913.1603 - val_loss: 5021433.1693\n",
      "Epoch 3404/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527911.1459 - val_loss: 5009303.5862\n",
      "Epoch 3405/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3529498.6216 - val_loss: 5054259.1128\n",
      "Epoch 3406/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527029.6986 - val_loss: 5001716.1437\n",
      "Epoch 3407/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3523762.9582 - val_loss: 5016590.5659\n",
      "Epoch 3408/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524034.3442 - val_loss: 5009240.8967\n",
      "Epoch 3409/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522764.4736 - val_loss: 4987284.4871\n",
      "Epoch 3410/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527233.2021 - val_loss: 4993583.4354\n",
      "Epoch 3411/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3526123.5744 - val_loss: 5010310.7136\n",
      "Epoch 3412/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3523186.7434 - val_loss: 4963520.5582\n",
      "Epoch 3413/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527079.0361 - val_loss: 4994081.9465\n",
      "Epoch 3414/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3525866.4362 - val_loss: 5036351.4332\n",
      "Epoch 3415/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3525678.2512 - val_loss: 4992235.0811\n",
      "Epoch 3416/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522424.4305 - val_loss: 5016962.3296\n",
      "Epoch 3417/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3525723.1965 - val_loss: 5007872.6485\n",
      "Epoch 3418/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3528201.9230 - val_loss: 5008253.3475\n",
      "Epoch 3419/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3526894.6895 - val_loss: 4983225.1549\n",
      "Epoch 3420/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3525203.7050 - val_loss: 4984520.3228\n",
      "Epoch 3421/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528272.1853 - val_loss: 4986793.7850\n",
      "Epoch 3422/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524292.5012 - val_loss: 5002668.5149\n",
      "Epoch 3423/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524844.1263 - val_loss: 4988407.1875\n",
      "Epoch 3424/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3522781.3688 - val_loss: 4966163.2685\n",
      "Epoch 3425/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3527247.6879 - val_loss: 5011914.5069\n",
      "Epoch 3426/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3529670.6227 - val_loss: 5000846.1535\n",
      "Epoch 3427/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3530488.2470 - val_loss: 5012659.9609\n",
      "Epoch 3428/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3523850.3587 - val_loss: 5005551.6201\n",
      "Epoch 3429/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3522856.1715 - val_loss: 5002156.5885\n",
      "Epoch 3430/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3526494.9292 - val_loss: 4982653.1691\n",
      "Epoch 3431/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3525186.1266 - val_loss: 4989713.5380\n",
      "Epoch 3432/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3526658.6737 - val_loss: 4972332.3112\n",
      "Epoch 3433/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3528607.3536 - val_loss: 4979754.4379\n",
      "Epoch 3434/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3523034.9428 - val_loss: 4970593.8209\n",
      "Epoch 3435/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3523652.6800 - val_loss: 4976829.8586\n",
      "Epoch 3436/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3525776.3540 - val_loss: 4986635.0412\n",
      "Epoch 3437/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3525743.8254 - val_loss: 4977460.1472\n",
      "Epoch 3438/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524286.5483 - val_loss: 5007172.1880\n",
      "Epoch 3439/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3521277.2470 - val_loss: 4972057.8623\n",
      "Epoch 3440/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524404.8532 - val_loss: 4976732.2882\n",
      "Epoch 3441/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3524802.4961 - val_loss: 4954124.0277\n",
      "Epoch 3442/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527791.1331 - val_loss: 4993048.4690\n",
      "Epoch 3443/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3524505.5081 - val_loss: 4989510.4044\n",
      "Epoch 3444/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3525781.3241 - val_loss: 5013510.7368\n",
      "Epoch 3445/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522604.2081 - val_loss: 4994776.3403\n",
      "Epoch 3446/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522122.5455 - val_loss: 4970243.4679\n",
      "Epoch 3447/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522647.2094 - val_loss: 4965677.6641\n",
      "Epoch 3448/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3523649.1321 - val_loss: 4994196.5043\n",
      "Epoch 3449/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3521964.1677 - val_loss: 5002107.4570\n",
      "Epoch 3450/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3521754.8470 - val_loss: 4971537.0627\n",
      "Epoch 3451/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3521738.5586 - val_loss: 4997060.9849\n",
      "Epoch 3452/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3525527.0641 - val_loss: 4982914.4559\n",
      "Epoch 3453/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3525893.4670 - val_loss: 4980361.4856\n",
      "Epoch 3454/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3521902.8109 - val_loss: 4991294.2430\n",
      "Epoch 3455/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3521331.0776 - val_loss: 5003708.4097\n",
      "Epoch 3456/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3523658.1042 - val_loss: 4995771.6685\n",
      "Epoch 3457/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3521862.8994 - val_loss: 4984704.4151\n",
      "Epoch 3458/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3520392.1838 - val_loss: 4968335.4781\n",
      "Epoch 3459/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527540.1999 - val_loss: 4997904.9723\n",
      "Epoch 3460/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3523468.9076 - val_loss: 4976348.1866\n",
      "Epoch 3461/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524523.8132 - val_loss: 4979902.6441\n",
      "Epoch 3462/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522002.2162 - val_loss: 4974991.5151\n",
      "Epoch 3463/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3523874.3580 - val_loss: 5004308.5519\n",
      "Epoch 3464/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3521975.4431 - val_loss: 5004859.1974\n",
      "Epoch 3465/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524175.3894 - val_loss: 4986358.6186\n",
      "Epoch 3466/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3521560.4581 - val_loss: 4965608.1187\n",
      "Epoch 3467/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3523100.8393 - val_loss: 4987812.2941\n",
      "Epoch 3468/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522273.5604 - val_loss: 5000654.7696\n",
      "Epoch 3469/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522185.0300 - val_loss: 4989686.3995\n",
      "Epoch 3470/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3520551.1717 - val_loss: 4970256.0528\n",
      "Epoch 3471/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522142.1117 - val_loss: 4996876.4776\n",
      "Epoch 3472/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3524837.1997 - val_loss: 4972999.3629\n",
      "Epoch 3473/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522513.7495 - val_loss: 4981844.5309\n",
      "Epoch 3474/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524080.6903 - val_loss: 4987004.5416\n",
      "Epoch 3475/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3520397.2007 - val_loss: 4993089.5439\n",
      "Epoch 3476/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3527769.8247 - val_loss: 4986515.5869\n",
      "Epoch 3477/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3519309.3860 - val_loss: 5001392.3435\n",
      "Epoch 3478/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3523351.0557 - val_loss: 5013021.1734\n",
      "Epoch 3479/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3523784.5578 - val_loss: 4968841.1387\n",
      "Epoch 3480/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3523089.4155 - val_loss: 5003536.6830\n",
      "Epoch 3481/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3523426.1636 - val_loss: 5008783.0041\n",
      "Epoch 3482/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3520822.5016 - val_loss: 4980341.6421\n",
      "Epoch 3483/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3526087.1440 - val_loss: 5007706.8888\n",
      "Epoch 3484/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522566.3900 - val_loss: 4975713.7008\n",
      "Epoch 3485/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3520706.4117 - val_loss: 4970830.9357\n",
      "Epoch 3486/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3521248.3761 - val_loss: 5004729.8105\n",
      "Epoch 3487/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3521795.2041 - val_loss: 5006125.6131\n",
      "Epoch 3488/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3519263.3058 - val_loss: 4996051.2433\n",
      "Epoch 3489/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3518545.1843 - val_loss: 5007796.1497\n",
      "Epoch 3490/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3523308.0028 - val_loss: 4997246.7809\n",
      "Epoch 3491/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3523070.8878 - val_loss: 4980498.6199\n",
      "Epoch 3492/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3522393.7716 - val_loss: 5014946.8496\n",
      "Epoch 3493/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3522176.3401 - val_loss: 4993448.4582\n",
      "Epoch 3494/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3522111.4924 - val_loss: 4975233.4332\n",
      "Epoch 3495/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3519165.7372 - val_loss: 4983024.9436\n",
      "Epoch 3496/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3522485.3377 - val_loss: 4977449.0318\n",
      "Epoch 3497/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3520077.1313 - val_loss: 5000669.9842\n",
      "Epoch 3498/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3521113.0482 - val_loss: 4984204.8656\n",
      "Epoch 3499/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3519767.2506 - val_loss: 5028847.8444\n",
      "Epoch 3500/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3523147.9732 - val_loss: 4995385.0803\n",
      "Epoch 3501/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3518507.6096 - val_loss: 4990610.6905\n",
      "Epoch 3502/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3523295.2447 - val_loss: 4975630.3107\n",
      "Epoch 3503/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3519955.6903 - val_loss: 4982428.6219\n",
      "Epoch 3504/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3523713.7107 - val_loss: 5014492.4266\n",
      "Epoch 3505/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3520642.8860 - val_loss: 4977715.8662\n",
      "Epoch 3506/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3521142.3507 - val_loss: 4983672.1319\n",
      "Epoch 3507/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3522782.6079 - val_loss: 5028955.4132\n",
      "Epoch 3508/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3519797.4181 - val_loss: 4962130.7409\n",
      "Epoch 3509/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3518342.0465 - val_loss: 5006004.1885\n",
      "Epoch 3510/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3520020.8791 - val_loss: 4970926.9805\n",
      "Epoch 3511/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3522877.1996 - val_loss: 4975870.4032\n",
      "Epoch 3512/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3519962.0936 - val_loss: 4990284.6194\n",
      "Epoch 3513/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3520481.4140 - val_loss: 4975112.1881\n",
      "Epoch 3514/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3515924.9900 - val_loss: 5000161.4616\n",
      "Epoch 3515/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3525033.0009 - val_loss: 4995860.8977\n",
      "Epoch 3516/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517820.1227 - val_loss: 4994843.9511\n",
      "Epoch 3517/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3526921.4782 - val_loss: 4992125.9103\n",
      "Epoch 3518/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3528414.7976 - val_loss: 5006012.0770\n",
      "Epoch 3519/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3517945.4732 - val_loss: 4977506.0693\n",
      "Epoch 3520/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524549.6170 - val_loss: 5006077.5061\n",
      "Epoch 3521/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3520228.3783 - val_loss: 4986159.9349\n",
      "Epoch 3522/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3516508.9472 - val_loss: 4991281.8396\n",
      "Epoch 3523/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3520240.3036 - val_loss: 4983856.4860\n",
      "Epoch 3524/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3519732.9496 - val_loss: 5001765.1721\n",
      "Epoch 3525/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518756.4718 - val_loss: 4970033.7668\n",
      "Epoch 3526/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3519479.3231 - val_loss: 4983575.9030\n",
      "Epoch 3527/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518823.8541 - val_loss: 5000675.7982\n",
      "Epoch 3528/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518735.1779 - val_loss: 4972047.4655\n",
      "Epoch 3529/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3517244.6214 - val_loss: 4979888.9379\n",
      "Epoch 3530/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3521121.5224 - val_loss: 4981689.7286\n",
      "Epoch 3531/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522275.3469 - val_loss: 5001032.1363\n",
      "Epoch 3532/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518871.7656 - val_loss: 5004905.7063\n",
      "Epoch 3533/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3521487.9318 - val_loss: 4982856.3731\n",
      "Epoch 3534/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3518800.0041 - val_loss: 4989901.5402\n",
      "Epoch 3535/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522562.3742 - val_loss: 5013193.9184\n",
      "Epoch 3536/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515428.0268 - val_loss: 4994455.0691\n",
      "Epoch 3537/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516164.1734 - val_loss: 4991784.4030\n",
      "Epoch 3538/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518022.6649 - val_loss: 4994690.4947\n",
      "Epoch 3539/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3519359.3020 - val_loss: 4981416.1374\n",
      "Epoch 3540/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518766.0796 - val_loss: 4994237.3966\n",
      "Epoch 3541/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516928.3503 - val_loss: 4983051.1471\n",
      "Epoch 3542/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518650.0614 - val_loss: 4996402.5879\n",
      "Epoch 3543/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3520239.4638 - val_loss: 4957787.0421\n",
      "Epoch 3544/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517026.9826 - val_loss: 4985505.7757\n",
      "Epoch 3545/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3516911.1160 - val_loss: 4991940.6955\n",
      "Epoch 3546/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3519400.5664 - val_loss: 5009777.4084\n",
      "Epoch 3547/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517504.4051 - val_loss: 4981895.4244\n",
      "Epoch 3548/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3519216.3373 - val_loss: 4985936.4670\n",
      "Epoch 3549/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3519582.5392 - val_loss: 5010857.9061\n",
      "Epoch 3550/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3519787.2172 - val_loss: 4989176.8163\n",
      "Epoch 3551/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3514699.0011 - val_loss: 5023308.5058\n",
      "Epoch 3552/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3516422.0188 - val_loss: 5010590.5881\n",
      "Epoch 3553/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3520559.9277 - val_loss: 5030042.6275\n",
      "Epoch 3554/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3520429.9884 - val_loss: 4994007.0983\n",
      "Epoch 3555/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517183.5900 - val_loss: 5009235.0095\n",
      "Epoch 3556/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3521537.3186 - val_loss: 4976986.5816\n",
      "Epoch 3557/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3517335.2948 - val_loss: 4994300.0866\n",
      "Epoch 3558/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518262.3050 - val_loss: 4985701.1411\n",
      "Epoch 3559/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3517139.2766 - val_loss: 4999760.5673\n",
      "Epoch 3560/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524037.6310 - val_loss: 5005132.1996\n",
      "Epoch 3561/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518331.9812 - val_loss: 5009508.7805\n",
      "Epoch 3562/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517102.0099 - val_loss: 4981709.8081\n",
      "Epoch 3563/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517275.9731 - val_loss: 5003019.1718\n",
      "Epoch 3564/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3513679.8503 - val_loss: 4990439.1114\n",
      "Epoch 3565/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3522821.7264 - val_loss: 5008014.1881\n",
      "Epoch 3566/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3517763.2038 - val_loss: 4995562.0373\n",
      "Epoch 3567/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3518183.2060 - val_loss: 4999508.4696\n",
      "Epoch 3568/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516666.4511 - val_loss: 5001594.4733\n",
      "Epoch 3569/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3520123.7602 - val_loss: 4995871.5893\n",
      "Epoch 3570/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3517465.4132 - val_loss: 4983283.6745\n",
      "Epoch 3571/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3517493.4005 - val_loss: 4987420.4377\n",
      "Epoch 3572/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518870.6608 - val_loss: 4994832.6940\n",
      "Epoch 3573/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517344.3554 - val_loss: 4985698.6993\n",
      "Epoch 3574/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3517178.2490 - val_loss: 5008805.9856\n",
      "Epoch 3575/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517713.1013 - val_loss: 5007663.8271\n",
      "Epoch 3576/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517632.1099 - val_loss: 4984720.6325\n",
      "Epoch 3577/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3520332.3390 - val_loss: 4992870.3878\n",
      "Epoch 3578/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516091.4841 - val_loss: 4989406.7339\n",
      "Epoch 3579/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3519913.5471 - val_loss: 4980521.5691\n",
      "Epoch 3580/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515067.1361 - val_loss: 5000680.2151\n",
      "Epoch 3581/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512272.1049 - val_loss: 5021263.0840\n",
      "Epoch 3582/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516127.1538 - val_loss: 4989309.6004\n",
      "Epoch 3583/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515127.2512 - val_loss: 5010741.1117\n",
      "Epoch 3584/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516184.8719 - val_loss: 4956644.5796\n",
      "Epoch 3585/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3521045.0509 - val_loss: 5002978.8957\n",
      "Epoch 3586/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3521695.1159 - val_loss: 4995432.5411\n",
      "Epoch 3587/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3521939.9824 - val_loss: 4986268.4849\n",
      "Epoch 3588/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3521258.4193 - val_loss: 5036866.2567\n",
      "Epoch 3589/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3524125.3292 - val_loss: 4997820.0384\n",
      "Epoch 3590/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516729.5895 - val_loss: 4991294.7314\n",
      "Epoch 3591/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513617.0741 - val_loss: 5012374.7509\n",
      "Epoch 3592/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516777.4145 - val_loss: 4989259.7671\n",
      "Epoch 3593/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3520783.7492 - val_loss: 4993748.9853\n",
      "Epoch 3594/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3519925.4508 - val_loss: 4977919.6330\n",
      "Epoch 3595/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3518826.8704 - val_loss: 4985619.1927\n",
      "Epoch 3596/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3515988.2058 - val_loss: 4994439.7553\n",
      "Epoch 3597/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514575.1004 - val_loss: 5000660.0194\n",
      "Epoch 3598/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3516279.5064 - val_loss: 5001851.4524\n",
      "Epoch 3599/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3516778.7263 - val_loss: 5016988.8009\n",
      "Epoch 3600/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3515142.8126 - val_loss: 5017147.5246\n",
      "Epoch 3601/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3519975.9857 - val_loss: 4993493.6726\n",
      "Epoch 3602/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3515697.8662 - val_loss: 4965714.2035\n",
      "Epoch 3603/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3519248.4100 - val_loss: 4975823.3466\n",
      "Epoch 3604/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3516538.6144 - val_loss: 5019167.9456\n",
      "Epoch 3605/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3515867.3410 - val_loss: 5009226.5601\n",
      "Epoch 3606/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514470.7819 - val_loss: 5014951.3780\n",
      "Epoch 3607/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515226.9256 - val_loss: 4988951.4205\n",
      "Epoch 3608/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3516361.8276 - val_loss: 4991143.3037\n",
      "Epoch 3609/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518388.9060 - val_loss: 4985027.9026\n",
      "Epoch 3610/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513298.8694 - val_loss: 4997376.4345\n",
      "Epoch 3611/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3513996.6174 - val_loss: 4990746.5987\n",
      "Epoch 3612/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518611.2051 - val_loss: 5005219.5091\n",
      "Epoch 3613/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3514153.5259 - val_loss: 4977294.6636\n",
      "Epoch 3614/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514159.0588 - val_loss: 4999335.5675\n",
      "Epoch 3615/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515469.5366 - val_loss: 4995525.6929\n",
      "Epoch 3616/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518519.5480 - val_loss: 4987444.9346\n",
      "Epoch 3617/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516303.1978 - val_loss: 5001841.3855\n",
      "Epoch 3618/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518360.3875 - val_loss: 5031379.0890\n",
      "Epoch 3619/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518228.3805 - val_loss: 4994457.1305\n",
      "Epoch 3620/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3517017.0828 - val_loss: 5017366.5387\n",
      "Epoch 3621/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516262.7827 - val_loss: 4985314.4482\n",
      "Epoch 3622/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514777.9627 - val_loss: 5011022.6235\n",
      "Epoch 3623/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515202.0555 - val_loss: 4997213.1446\n",
      "Epoch 3624/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515898.5744 - val_loss: 4978230.9221\n",
      "Epoch 3625/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3515209.2576 - val_loss: 4999670.7630\n",
      "Epoch 3626/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3514112.5430 - val_loss: 5009916.9856\n",
      "Epoch 3627/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513620.5031 - val_loss: 5014334.2326\n",
      "Epoch 3628/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515915.7897 - val_loss: 4995598.3179\n",
      "Epoch 3629/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514249.5061 - val_loss: 4990005.4470\n",
      "Epoch 3630/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515806.6368 - val_loss: 4966366.3040\n",
      "Epoch 3631/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3518282.9130 - val_loss: 4990273.3360\n",
      "Epoch 3632/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515119.1894 - val_loss: 4998734.7918\n",
      "Epoch 3633/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515815.7020 - val_loss: 4981005.8246\n",
      "Epoch 3634/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3519203.6581 - val_loss: 4982947.8181\n",
      "Epoch 3635/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3513960.8061 - val_loss: 5008692.2998\n",
      "Epoch 3636/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513137.9055 - val_loss: 4996701.7585\n",
      "Epoch 3637/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512649.6780 - val_loss: 5046570.5218\n",
      "Epoch 3638/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3514191.1783 - val_loss: 4995409.6593\n",
      "Epoch 3639/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3518179.4131 - val_loss: 5012968.5228\n",
      "Epoch 3640/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3513487.1175 - val_loss: 4984276.0836\n",
      "Epoch 3641/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516375.7896 - val_loss: 4997611.7524\n",
      "Epoch 3642/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3518250.8248 - val_loss: 4990790.4412\n",
      "Epoch 3643/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517139.4286 - val_loss: 4977627.3939\n",
      "Epoch 3644/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3515778.3066 - val_loss: 5012794.1582\n",
      "Epoch 3645/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3513437.7608 - val_loss: 4987281.9616\n",
      "Epoch 3646/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516011.6756 - val_loss: 5002471.3599\n",
      "Epoch 3647/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516432.3367 - val_loss: 4983008.3685\n",
      "Epoch 3648/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3517054.3578 - val_loss: 5001336.1401\n",
      "Epoch 3649/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510441.0684 - val_loss: 5005223.8390\n",
      "Epoch 3650/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513562.7029 - val_loss: 4995312.8526\n",
      "Epoch 3651/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3515975.8293 - val_loss: 4996249.8634\n",
      "Epoch 3652/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513192.6511 - val_loss: 5003367.4719\n",
      "Epoch 3653/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3515339.8765 - val_loss: 5001022.6682\n",
      "Epoch 3654/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515586.3696 - val_loss: 4997839.4953\n",
      "Epoch 3655/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515039.4400 - val_loss: 4983482.0324\n",
      "Epoch 3656/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516963.8389 - val_loss: 4995401.0369\n",
      "Epoch 3657/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515141.8054 - val_loss: 5008777.6725\n",
      "Epoch 3658/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514579.7059 - val_loss: 4998885.4445\n",
      "Epoch 3659/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512789.9628 - val_loss: 4996502.8472\n",
      "Epoch 3660/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511953.8957 - val_loss: 5002048.2262\n",
      "Epoch 3661/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3513562.9767 - val_loss: 5030190.3140\n",
      "Epoch 3662/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512760.3226 - val_loss: 5002491.9315\n",
      "Epoch 3663/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512007.9538 - val_loss: 4990294.0366\n",
      "Epoch 3664/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3510359.5234 - val_loss: 4981915.1693\n",
      "Epoch 3665/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515783.8654 - val_loss: 5038292.0191\n",
      "Epoch 3666/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3515786.0632 - val_loss: 5011430.7095\n",
      "Epoch 3667/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511251.2904 - val_loss: 5000683.7748\n",
      "Epoch 3668/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3513693.2501 - val_loss: 4984497.4772\n",
      "Epoch 3669/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511815.9348 - val_loss: 4984963.9202\n",
      "Epoch 3670/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511041.8576 - val_loss: 5027948.5423\n",
      "Epoch 3671/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3516367.5395 - val_loss: 5015347.9311\n",
      "Epoch 3672/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512890.1830 - val_loss: 4988698.4568\n",
      "Epoch 3673/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511086.3663 - val_loss: 5016434.5566\n",
      "Epoch 3674/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511786.8718 - val_loss: 4987635.1202\n",
      "Epoch 3675/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512176.9529 - val_loss: 4980841.0013\n",
      "Epoch 3676/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512503.8895 - val_loss: 4997256.8827\n",
      "Epoch 3677/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3513400.0951 - val_loss: 5007273.6570\n",
      "Epoch 3678/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517294.4772 - val_loss: 5037512.0667\n",
      "Epoch 3679/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3513531.0349 - val_loss: 5019569.2639\n",
      "Epoch 3680/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517089.7471 - val_loss: 5007518.3472\n",
      "Epoch 3681/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3508688.7915 - val_loss: 5009656.5699\n",
      "Epoch 3682/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512807.9018 - val_loss: 4987607.3403\n",
      "Epoch 3683/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3514212.9518 - val_loss: 4994174.6051\n",
      "Epoch 3684/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3515986.6297 - val_loss: 4985240.8035\n",
      "Epoch 3685/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512529.3851 - val_loss: 5002617.1070\n",
      "Epoch 3686/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512894.0610 - val_loss: 5014651.1422\n",
      "Epoch 3687/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511948.5680 - val_loss: 4991383.9071\n",
      "Epoch 3688/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3515910.5092 - val_loss: 5017522.3413\n",
      "Epoch 3689/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513357.7680 - val_loss: 4995075.8617\n",
      "Epoch 3690/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512807.7852 - val_loss: 5015652.0554\n",
      "Epoch 3691/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3510328.7768 - val_loss: 5021721.9443\n",
      "Epoch 3692/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508759.3640 - val_loss: 4986035.2378\n",
      "Epoch 3693/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509288.6007 - val_loss: 4988200.9236\n",
      "Epoch 3694/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3509871.9566 - val_loss: 5011509.2938\n",
      "Epoch 3695/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513896.3881 - val_loss: 5012933.7885\n",
      "Epoch 3696/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512014.7337 - val_loss: 4986361.5580\n",
      "Epoch 3697/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510870.4651 - val_loss: 4999846.9709\n",
      "Epoch 3698/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512632.8618 - val_loss: 5001724.2237\n",
      "Epoch 3699/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513543.0165 - val_loss: 5000279.2691\n",
      "Epoch 3700/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513115.2590 - val_loss: 5025031.4891\n",
      "Epoch 3701/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515620.7347 - val_loss: 4996266.3451\n",
      "Epoch 3702/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511415.5798 - val_loss: 5024768.0504\n",
      "Epoch 3703/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515305.3549 - val_loss: 5044713.6675\n",
      "Epoch 3704/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514440.0483 - val_loss: 4995535.0913\n",
      "Epoch 3705/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3513226.5415 - val_loss: 5009203.1696\n",
      "Epoch 3706/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512118.3158 - val_loss: 5018247.4773\n",
      "Epoch 3707/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510758.9625 - val_loss: 5009723.4312\n",
      "Epoch 3708/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3518515.0607 - val_loss: 5052543.4014\n",
      "Epoch 3709/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514705.1635 - val_loss: 5004854.3031\n",
      "Epoch 3710/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512782.6017 - val_loss: 5006770.2262\n",
      "Epoch 3711/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512373.2793 - val_loss: 5012131.5691\n",
      "Epoch 3712/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3511290.4589 - val_loss: 5014683.5873\n",
      "Epoch 3713/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511576.3171 - val_loss: 5021393.7948\n",
      "Epoch 3714/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514032.6056 - val_loss: 5011002.6003\n",
      "Epoch 3715/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515782.3223 - val_loss: 4989178.2523\n",
      "Epoch 3716/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515042.3031 - val_loss: 4991442.9183\n",
      "Epoch 3717/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516009.4880 - val_loss: 5009305.8059\n",
      "Epoch 3718/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511326.2388 - val_loss: 5018426.2487\n",
      "Epoch 3719/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3510203.5776 - val_loss: 4999829.6010\n",
      "Epoch 3720/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3514102.8427 - val_loss: 4983363.2226\n",
      "Epoch 3721/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3512113.8257 - val_loss: 5013052.5870\n",
      "Epoch 3722/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3510908.1654 - val_loss: 5034722.2544\n",
      "Epoch 3723/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511997.5684 - val_loss: 5029679.2283\n",
      "Epoch 3724/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512112.3946 - val_loss: 4995894.6715\n",
      "Epoch 3725/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513087.8127 - val_loss: 4996172.3170\n",
      "Epoch 3726/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510860.7956 - val_loss: 4996358.7300\n",
      "Epoch 3727/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3515695.0437 - val_loss: 5005417.5282\n",
      "Epoch 3728/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509677.2769 - val_loss: 5004947.3763\n",
      "Epoch 3729/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511124.4392 - val_loss: 4997448.2568\n",
      "Epoch 3730/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513986.6743 - val_loss: 4985777.0226\n",
      "Epoch 3731/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3509706.4805 - val_loss: 5011021.5993\n",
      "Epoch 3732/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3513343.7759 - val_loss: 4982746.6447\n",
      "Epoch 3733/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511539.6116 - val_loss: 5020862.0508\n",
      "Epoch 3734/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511641.2115 - val_loss: 5024580.6091\n",
      "Epoch 3735/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512395.1390 - val_loss: 4990873.4079\n",
      "Epoch 3736/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513445.9328 - val_loss: 4988473.6510\n",
      "Epoch 3737/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3510915.1025 - val_loss: 5008643.2554\n",
      "Epoch 3738/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512307.4158 - val_loss: 5013914.8208\n",
      "Epoch 3739/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513965.3540 - val_loss: 4980983.1344\n",
      "Epoch 3740/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3509085.5404 - val_loss: 4998741.2419\n",
      "Epoch 3741/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3508207.3501 - val_loss: 5030912.6587\n",
      "Epoch 3742/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3513623.7281 - val_loss: 5006473.9114\n",
      "Epoch 3743/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3516083.5661 - val_loss: 4986263.6700\n",
      "Epoch 3744/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3509661.0599 - val_loss: 5007264.9160\n",
      "Epoch 3745/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510474.0670 - val_loss: 5005287.9520\n",
      "Epoch 3746/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3510142.0801 - val_loss: 5001846.6883\n",
      "Epoch 3747/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512616.1273 - val_loss: 4982892.3837\n",
      "Epoch 3748/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514327.7778 - val_loss: 4978683.9981\n",
      "Epoch 3749/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509020.9179 - val_loss: 4997177.3824\n",
      "Epoch 3750/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510773.6470 - val_loss: 4998726.8973\n",
      "Epoch 3751/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514393.9514 - val_loss: 5008389.7054\n",
      "Epoch 3752/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508449.3329 - val_loss: 5025528.5598\n",
      "Epoch 3753/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510797.3642 - val_loss: 4996649.4555\n",
      "Epoch 3754/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3510606.7464 - val_loss: 5025069.1185\n",
      "Epoch 3755/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514516.1955 - val_loss: 5025083.6270\n",
      "Epoch 3756/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512759.5430 - val_loss: 5033901.0845\n",
      "Epoch 3757/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512794.3330 - val_loss: 5047631.2215\n",
      "Epoch 3758/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511987.1621 - val_loss: 5019016.7007\n",
      "Epoch 3759/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510300.4636 - val_loss: 4992643.8191\n",
      "Epoch 3760/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512063.4110 - val_loss: 4974820.1565\n",
      "Epoch 3761/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510258.7333 - val_loss: 4996602.0467\n",
      "Epoch 3762/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507936.1016 - val_loss: 5061619.5066\n",
      "Epoch 3763/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512331.0076 - val_loss: 5010122.9009\n",
      "Epoch 3764/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510072.2297 - val_loss: 5031738.3369\n",
      "Epoch 3765/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512898.8398 - val_loss: 5043492.6460\n",
      "Epoch 3766/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510710.0697 - val_loss: 5002604.1189\n",
      "Epoch 3767/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509554.1367 - val_loss: 5010049.3529\n",
      "Epoch 3768/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512449.7582 - val_loss: 4985714.0571\n",
      "Epoch 3769/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511710.1925 - val_loss: 5011723.7212\n",
      "Epoch 3770/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512083.7963 - val_loss: 5020378.1992\n",
      "Epoch 3771/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511045.3727 - val_loss: 4990557.4746\n",
      "Epoch 3772/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3511143.9553 - val_loss: 5021150.6844\n",
      "Epoch 3773/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512365.0795 - val_loss: 5023688.5327\n",
      "Epoch 3774/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511429.4216 - val_loss: 5000591.9157\n",
      "Epoch 3775/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512067.8953 - val_loss: 4988465.6149\n",
      "Epoch 3776/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507556.0659 - val_loss: 5033150.8254\n",
      "Epoch 3777/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513662.3577 - val_loss: 5013527.3531\n",
      "Epoch 3778/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3514857.9352 - val_loss: 5003745.5732\n",
      "Epoch 3779/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509417.2343 - val_loss: 5026995.5310\n",
      "Epoch 3780/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511812.6243 - val_loss: 5013729.9126\n",
      "Epoch 3781/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507659.1905 - val_loss: 5010722.2505\n",
      "Epoch 3782/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508443.4977 - val_loss: 5000515.4051\n",
      "Epoch 3783/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3514809.7073 - val_loss: 4991395.6316\n",
      "Epoch 3784/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511628.1165 - val_loss: 5014036.6016\n",
      "Epoch 3785/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3508967.2669 - val_loss: 5052906.0081\n",
      "Epoch 3786/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3509859.3599 - val_loss: 5004396.5259\n",
      "Epoch 3787/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511279.5154 - val_loss: 4994858.3574\n",
      "Epoch 3788/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3510844.8820 - val_loss: 5012713.9100\n",
      "Epoch 3789/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511578.0308 - val_loss: 5003740.5304\n",
      "Epoch 3790/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3517446.9600 - val_loss: 4985900.4142\n",
      "Epoch 3791/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511450.5541 - val_loss: 5021331.7475\n",
      "Epoch 3792/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511023.6056 - val_loss: 5010251.1469\n",
      "Epoch 3793/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509621.2450 - val_loss: 5004355.6410\n",
      "Epoch 3794/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507573.9682 - val_loss: 5017475.1402\n",
      "Epoch 3795/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3510051.4332 - val_loss: 5041702.9415\n",
      "Epoch 3796/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3508622.0389 - val_loss: 4996724.1764\n",
      "Epoch 3797/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507366.6842 - val_loss: 5030293.5159\n",
      "Epoch 3798/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3509588.0413 - val_loss: 4982584.9942\n",
      "Epoch 3799/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507727.6966 - val_loss: 5018040.5511\n",
      "Epoch 3800/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508092.9675 - val_loss: 5017943.8723\n",
      "Epoch 3801/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511578.7184 - val_loss: 4991785.3851\n",
      "Epoch 3802/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511530.4756 - val_loss: 4993029.0544\n",
      "Epoch 3803/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509179.6287 - val_loss: 5009504.5292\n",
      "Epoch 3804/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506492.4676 - val_loss: 5025438.0291\n",
      "Epoch 3805/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3510162.3039 - val_loss: 5011579.7552\n",
      "Epoch 3806/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512149.5795 - val_loss: 5020207.8018\n",
      "Epoch 3807/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509536.1946 - val_loss: 5042643.6910\n",
      "Epoch 3808/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3508759.7489 - val_loss: 4989973.4569\n",
      "Epoch 3809/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513025.8930 - val_loss: 5018879.3862\n",
      "Epoch 3810/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3511057.6683 - val_loss: 4990812.4217\n",
      "Epoch 3811/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3513094.9072 - val_loss: 4988303.1550\n",
      "Epoch 3812/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507284.8407 - val_loss: 5009350.8865\n",
      "Epoch 3813/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510156.0858 - val_loss: 5018443.3201\n",
      "Epoch 3814/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507212.9802 - val_loss: 4974899.7174\n",
      "Epoch 3815/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512750.7616 - val_loss: 5028193.4616\n",
      "Epoch 3816/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508296.5482 - val_loss: 5015749.4101\n",
      "Epoch 3817/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3512817.4625 - val_loss: 5001573.4395\n",
      "Epoch 3818/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509758.4327 - val_loss: 4993206.4592\n",
      "Epoch 3819/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506236.1148 - val_loss: 5011199.2427\n",
      "Epoch 3820/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3511723.4614 - val_loss: 4995834.1498\n",
      "Epoch 3821/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511107.8614 - val_loss: 5004244.9484\n",
      "Epoch 3822/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507757.1298 - val_loss: 4994244.5972\n",
      "Epoch 3823/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3506696.2053 - val_loss: 5015976.1270\n",
      "Epoch 3824/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508241.4164 - val_loss: 5040428.6988\n",
      "Epoch 3825/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3510405.6218 - val_loss: 4997007.4665\n",
      "Epoch 3826/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508605.3138 - val_loss: 4974663.0956\n",
      "Epoch 3827/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3506502.0990 - val_loss: 4992596.7498\n",
      "Epoch 3828/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3508850.0210 - val_loss: 4986265.2734\n",
      "Epoch 3829/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506849.1710 - val_loss: 5003901.3320\n",
      "Epoch 3830/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509584.2432 - val_loss: 5010504.3581\n",
      "Epoch 3831/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3512316.6069 - val_loss: 5007630.9722\n",
      "Epoch 3832/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507462.9542 - val_loss: 4989243.0633\n",
      "Epoch 3833/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510395.8312 - val_loss: 5012797.2257\n",
      "Epoch 3834/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3510274.4387 - val_loss: 5015293.9771\n",
      "Epoch 3835/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3509230.3205 - val_loss: 5013445.4725\n",
      "Epoch 3836/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3508820.6941 - val_loss: 4996726.2147\n",
      "Epoch 3837/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3509809.7338 - val_loss: 5023135.8598\n",
      "Epoch 3838/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3509864.0176 - val_loss: 4999762.3381\n",
      "Epoch 3839/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3511139.7419 - val_loss: 5030105.1142\n",
      "Epoch 3840/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508552.2539 - val_loss: 4989735.2900\n",
      "Epoch 3841/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3509674.0987 - val_loss: 5029632.0624\n",
      "Epoch 3842/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3506332.3420 - val_loss: 5029145.5108\n",
      "Epoch 3843/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3508210.7090 - val_loss: 5026377.0137\n",
      "Epoch 3844/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507885.1257 - val_loss: 5028326.4084\n",
      "Epoch 3845/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3508239.1951 - val_loss: 4990107.0650\n",
      "Epoch 3846/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3505648.8534 - val_loss: 4998274.8302\n",
      "Epoch 3847/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504021.3748 - val_loss: 4981929.9586\n",
      "Epoch 3848/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507259.6997 - val_loss: 5004552.0273\n",
      "Epoch 3849/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3508713.6663 - val_loss: 5026371.5989\n",
      "Epoch 3850/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507851.5071 - val_loss: 5018796.1276\n",
      "Epoch 3851/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507849.4949 - val_loss: 5032300.0112\n",
      "Epoch 3852/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507095.9806 - val_loss: 5014547.1490\n",
      "Epoch 3853/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507819.4871 - val_loss: 5017265.8649\n",
      "Epoch 3854/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509444.7493 - val_loss: 5022090.7808\n",
      "Epoch 3855/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506800.0301 - val_loss: 4982475.3586\n",
      "Epoch 3856/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513109.8371 - val_loss: 5042195.0472\n",
      "Epoch 3857/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3511109.4121 - val_loss: 5014817.7516\n",
      "Epoch 3858/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3509932.1493 - val_loss: 5013732.6552\n",
      "Epoch 3859/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3503352.4984 - val_loss: 5004240.5986\n",
      "Epoch 3860/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509025.1501 - val_loss: 5017019.4731\n",
      "Epoch 3861/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504828.7683 - val_loss: 4993841.5160\n",
      "Epoch 3862/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505726.2405 - val_loss: 5008278.9478\n",
      "Epoch 3863/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508303.4080 - val_loss: 5002468.6361\n",
      "Epoch 3864/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509518.1530 - val_loss: 4996850.0952\n",
      "Epoch 3865/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506434.4727 - val_loss: 5004947.2557\n",
      "Epoch 3866/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3507271.7782 - val_loss: 4982472.0647\n",
      "Epoch 3867/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3510502.5220 - val_loss: 5008780.2113\n",
      "Epoch 3868/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504750.6463 - val_loss: 4999315.7239\n",
      "Epoch 3869/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508017.9308 - val_loss: 4999604.4914\n",
      "Epoch 3870/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507995.4700 - val_loss: 5022217.2057\n",
      "Epoch 3871/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508620.0862 - val_loss: 5027191.4791\n",
      "Epoch 3872/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510029.3060 - val_loss: 5001768.7251\n",
      "Epoch 3873/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509606.3319 - val_loss: 5020407.2682\n",
      "Epoch 3874/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506956.4604 - val_loss: 5027671.1704\n",
      "Epoch 3875/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505306.2187 - val_loss: 5000250.2441\n",
      "Epoch 3876/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3503551.9022 - val_loss: 5049428.4070\n",
      "Epoch 3877/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509757.0452 - val_loss: 5018748.8642\n",
      "Epoch 3878/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3509920.1579 - val_loss: 5008610.3241\n",
      "Epoch 3879/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509912.5424 - val_loss: 4999479.7271\n",
      "Epoch 3880/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3507937.2070 - val_loss: 5016308.5000\n",
      "Epoch 3881/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515390.8690 - val_loss: 5017826.6798\n",
      "Epoch 3882/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507576.7722 - val_loss: 5010910.3965\n",
      "Epoch 3883/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3510605.6196 - val_loss: 5001609.1999\n",
      "Epoch 3884/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509269.2184 - val_loss: 4995778.6209\n",
      "Epoch 3885/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505790.5247 - val_loss: 5013087.5648\n",
      "Epoch 3886/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3510772.0994 - val_loss: 4994877.1199\n",
      "Epoch 3887/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3508748.3431 - val_loss: 5031340.0914\n",
      "Epoch 3888/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509841.7567 - val_loss: 5020472.5525\n",
      "Epoch 3889/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506252.7065 - val_loss: 5019351.5477\n",
      "Epoch 3890/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3510114.0486 - val_loss: 5014997.6321\n",
      "Epoch 3891/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507335.8170 - val_loss: 5022132.8686\n",
      "Epoch 3892/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506548.7562 - val_loss: 5039409.9328\n",
      "Epoch 3893/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506096.9455 - val_loss: 4992845.4392\n",
      "Epoch 3894/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3508208.2513 - val_loss: 5019212.1534\n",
      "Epoch 3895/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507676.8540 - val_loss: 5022076.4061\n",
      "Epoch 3896/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3505373.2015 - val_loss: 5004842.8551\n",
      "Epoch 3897/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507380.3353 - val_loss: 5008527.8464\n",
      "Epoch 3898/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3509019.0388 - val_loss: 4998747.6592\n",
      "Epoch 3899/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3506399.7514 - val_loss: 5027295.2614\n",
      "Epoch 3900/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505257.4396 - val_loss: 5013333.9433\n",
      "Epoch 3901/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507199.8472 - val_loss: 5003793.3450\n",
      "Epoch 3902/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504788.6423 - val_loss: 4989733.4125\n",
      "Epoch 3903/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507843.0137 - val_loss: 5030554.4059\n",
      "Epoch 3904/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3505921.2787 - val_loss: 5014530.2943\n",
      "Epoch 3905/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508393.8991 - val_loss: 5011352.7812\n",
      "Epoch 3906/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508358.5033 - val_loss: 4983979.8908\n",
      "Epoch 3907/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508547.9338 - val_loss: 5032486.2703\n",
      "Epoch 3908/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507029.1965 - val_loss: 5029063.7714\n",
      "Epoch 3909/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504033.7516 - val_loss: 4992389.3226\n",
      "Epoch 3910/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3503820.5673 - val_loss: 5026482.3107\n",
      "Epoch 3911/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3505577.5032 - val_loss: 4999830.9623\n",
      "Epoch 3912/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3506819.8261 - val_loss: 4989521.7474\n",
      "Epoch 3913/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504970.7024 - val_loss: 5015505.5697\n",
      "Epoch 3914/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3513625.9857 - val_loss: 5007985.7643\n",
      "Epoch 3915/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3505505.3527 - val_loss: 4994113.8750\n",
      "Epoch 3916/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505932.5524 - val_loss: 5029530.7903\n",
      "Epoch 3917/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3515177.0766 - val_loss: 5005558.0481\n",
      "Epoch 3918/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505059.9876 - val_loss: 4988834.9258\n",
      "Epoch 3919/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3506263.3197 - val_loss: 5025073.5354\n",
      "Epoch 3920/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3506628.3023 - val_loss: 5036791.9202\n",
      "Epoch 3921/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3506520.0990 - val_loss: 4996116.1089\n",
      "Epoch 3922/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506350.9830 - val_loss: 5041247.3901\n",
      "Epoch 3923/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506758.7252 - val_loss: 5016386.2581\n",
      "Epoch 3924/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505668.6765 - val_loss: 5024660.9865\n",
      "Epoch 3925/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507821.0266 - val_loss: 5011069.2350\n",
      "Epoch 3926/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3513080.4370 - val_loss: 5012132.1438\n",
      "Epoch 3927/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508007.4536 - val_loss: 5016834.8981\n",
      "Epoch 3928/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3503170.3727 - val_loss: 4992969.4779\n",
      "Epoch 3929/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504517.3207 - val_loss: 5018423.1802\n",
      "Epoch 3930/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507352.1060 - val_loss: 5013227.0600\n",
      "Epoch 3931/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3503168.1778 - val_loss: 5005948.1536\n",
      "Epoch 3932/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3505952.3669 - val_loss: 4999607.0579\n",
      "Epoch 3933/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3501755.2113 - val_loss: 5013415.2278\n",
      "Epoch 3934/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3506065.0613 - val_loss: 5032907.4172\n",
      "Epoch 3935/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3503874.1489 - val_loss: 5011614.9781\n",
      "Epoch 3936/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3502938.3232 - val_loss: 5044211.0412\n",
      "Epoch 3937/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3502733.0736 - val_loss: 5002854.0411\n",
      "Epoch 3938/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3505436.3730 - val_loss: 5008722.5198\n",
      "Epoch 3939/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506271.0496 - val_loss: 5017930.2335\n",
      "Epoch 3940/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508603.4721 - val_loss: 5022738.9841\n",
      "Epoch 3941/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3510540.2455 - val_loss: 5033130.5347\n",
      "Epoch 3942/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505461.6520 - val_loss: 5027554.9407\n",
      "Epoch 3943/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3507960.3544 - val_loss: 5018313.1806\n",
      "Epoch 3944/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506484.1245 - val_loss: 4998954.2245\n",
      "Epoch 3945/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505155.0720 - val_loss: 5031959.3619\n",
      "Epoch 3946/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507807.0569 - val_loss: 5000353.0301\n",
      "Epoch 3947/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3506156.4494 - val_loss: 5018940.3395\n",
      "Epoch 3948/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506580.7436 - val_loss: 5008888.1470\n",
      "Epoch 3949/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3505000.0784 - val_loss: 5009530.8146\n",
      "Epoch 3950/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504285.7873 - val_loss: 5015467.1066\n",
      "Epoch 3951/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505524.3465 - val_loss: 5023520.1129\n",
      "Epoch 3952/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504937.7300 - val_loss: 5000137.9244\n",
      "Epoch 3953/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506834.4401 - val_loss: 5023136.3852\n",
      "Epoch 3954/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504223.4747 - val_loss: 5015782.8224\n",
      "Epoch 3955/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504702.9822 - val_loss: 4984212.6495\n",
      "Epoch 3956/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505828.4568 - val_loss: 5022231.8164\n",
      "Epoch 3957/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504210.0142 - val_loss: 5002429.3180\n",
      "Epoch 3958/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505351.8843 - val_loss: 5010903.8872\n",
      "Epoch 3959/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3506954.1372 - val_loss: 5040197.4007\n",
      "Epoch 3960/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3503296.0739 - val_loss: 5030707.3239\n",
      "Epoch 3961/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505886.3905 - val_loss: 5011774.6692\n",
      "Epoch 3962/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3505084.6904 - val_loss: 5028429.8079\n",
      "Epoch 3963/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507919.1070 - val_loss: 4990572.3193\n",
      "Epoch 3964/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504686.5084 - val_loss: 5018251.8644\n",
      "Epoch 3965/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3502500.6363 - val_loss: 4998052.6425\n",
      "Epoch 3966/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3506643.5256 - val_loss: 5035968.3544\n",
      "Epoch 3967/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3506765.9809 - val_loss: 5007592.3430\n",
      "Epoch 3968/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504146.7517 - val_loss: 5024201.8122\n",
      "Epoch 3969/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3502363.5180 - val_loss: 5030682.6398\n",
      "Epoch 3970/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504258.0574 - val_loss: 4998043.4305\n",
      "Epoch 3971/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506193.1679 - val_loss: 5008509.3780\n",
      "Epoch 3972/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3502968.1588 - val_loss: 5010311.4521\n",
      "Epoch 3973/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505778.0344 - val_loss: 5037673.1439\n",
      "Epoch 3974/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3503308.6118 - val_loss: 5036146.6434\n",
      "Epoch 3975/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3503674.3908 - val_loss: 5024285.7995\n",
      "Epoch 3976/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3508477.1208 - val_loss: 5034126.6248\n",
      "Epoch 3977/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507892.2784 - val_loss: 5006282.9636\n",
      "Epoch 3978/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3501429.5607 - val_loss: 5018018.6161\n",
      "Epoch 3979/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504039.6829 - val_loss: 4990494.6975\n",
      "Epoch 3980/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504538.5150 - val_loss: 5010488.8851\n",
      "Epoch 3981/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3501425.6118 - val_loss: 4998763.2657\n",
      "Epoch 3982/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504553.1306 - val_loss: 4995483.4545\n",
      "Epoch 3983/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3505226.5962 - val_loss: 5029222.3787\n",
      "Epoch 3984/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505314.6156 - val_loss: 5009345.1210\n",
      "Epoch 3985/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504791.9624 - val_loss: 4998099.4385\n",
      "Epoch 3986/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3506233.7551 - val_loss: 5022547.4746\n",
      "Epoch 3987/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507237.8615 - val_loss: 5002254.9335\n",
      "Epoch 3988/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504554.4634 - val_loss: 5027056.1654\n",
      "Epoch 3989/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3503332.0708 - val_loss: 5020049.9297\n",
      "Epoch 3990/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3503283.2770 - val_loss: 5039632.0401\n",
      "Epoch 3991/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3503066.4579 - val_loss: 5012258.1345\n",
      "Epoch 3992/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506629.0452 - val_loss: 5001641.2649\n",
      "Epoch 3993/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3502402.5590 - val_loss: 4985042.8643\n",
      "Epoch 3994/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3503601.4562 - val_loss: 4990270.2179\n",
      "Epoch 3995/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504827.3989 - val_loss: 5005865.4098\n",
      "Epoch 3996/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3503765.5213 - val_loss: 4998844.7068\n",
      "Epoch 3997/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3503768.3304 - val_loss: 5000330.2522\n",
      "Epoch 3998/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504840.5454 - val_loss: 5084478.5750\n",
      "Epoch 3999/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3501853.3227 - val_loss: 5043613.5627\n",
      "Epoch 4000/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504542.2774 - val_loss: 5040138.9702\n",
      "Epoch 4001/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3507260.7320 - val_loss: 5000324.3589\n",
      "Epoch 4002/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3503108.0862 - val_loss: 5049020.2217\n",
      "Epoch 4003/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3503470.5264 - val_loss: 5012755.6094\n",
      "Epoch 4004/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3501724.1661 - val_loss: 5030712.5184\n",
      "Epoch 4005/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3505733.8997 - val_loss: 5000547.2867\n",
      "Epoch 4006/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3502294.2753 - val_loss: 5013647.6133\n",
      "Epoch 4007/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3502335.8437 - val_loss: 5015870.5618\n",
      "Epoch 4008/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504935.6687 - val_loss: 4986250.6053\n",
      "Epoch 4009/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504353.1920 - val_loss: 5000400.6565\n",
      "Epoch 4010/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3501974.3172 - val_loss: 5028777.5884\n",
      "Epoch 4011/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3500568.0073 - val_loss: 4999232.6185\n",
      "Epoch 4012/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3502847.2726 - val_loss: 4999680.4917\n",
      "Epoch 4013/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3505943.5913 - val_loss: 5011980.3711\n",
      "Epoch 4014/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3506041.0242 - val_loss: 5000546.2531\n",
      "Epoch 4015/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3501044.4380 - val_loss: 5021225.2694\n",
      "Epoch 4016/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3500741.7304 - val_loss: 4998242.5409\n",
      "Epoch 4017/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3502290.4513 - val_loss: 5012642.1981\n",
      "Epoch 4018/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3505037.4244 - val_loss: 5006494.8989\n",
      "Epoch 4019/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3501118.0351 - val_loss: 5000871.0675\n",
      "Epoch 4020/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3502613.4139 - val_loss: 5000666.6224\n",
      "Epoch 4021/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3504897.2845 - val_loss: 5008008.1207\n",
      "Epoch 4022/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3500627.8137 - val_loss: 5004160.2065\n",
      "Epoch 4023/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3503381.1675 - val_loss: 5009926.8488\n",
      "Epoch 4024/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3503447.8628 - val_loss: 5009893.8824\n",
      "Epoch 4025/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3502139.1308 - val_loss: 5024412.3637\n",
      "Epoch 4026/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3502965.1710 - val_loss: 4995875.9415\n",
      "Epoch 4027/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3508594.5854 - val_loss: 5014504.3847\n",
      "Epoch 4028/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3503088.9707 - val_loss: 5002753.1690\n",
      "Epoch 4029/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3505419.8537 - val_loss: 5034678.4724\n",
      "Epoch 4030/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3506536.3733 - val_loss: 5033598.3810\n",
      "Epoch 4031/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3502830.0009 - val_loss: 5008473.5110\n",
      "Epoch 4032/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3499689.7141 - val_loss: 5005589.2647\n",
      "Epoch 4033/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3498417.7487 - val_loss: 4984541.5478\n",
      "Epoch 4034/5000\n",
      "40850/40850 [==============================] - 1s 20us/sample - loss: 3499171.3689 - val_loss: 5015980.0875\n",
      "Epoch 4035/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3503507.3811 - val_loss: 5004836.4078\n",
      "Epoch 4036/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3503736.2945 - val_loss: 4994435.8171\n",
      "Epoch 4037/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3499872.1701 - val_loss: 4993545.3446\n",
      "Epoch 4038/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3505949.8984 - val_loss: 5005534.2635\n",
      "Epoch 4039/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3504875.5873 - val_loss: 5016294.9708\n",
      "Epoch 4040/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3504528.3942 - val_loss: 4979762.5657\n",
      "Epoch 4041/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3499944.1719 - val_loss: 5017163.6204\n",
      "Epoch 4042/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3505261.2792 - val_loss: 4996658.7361\n",
      "Epoch 4043/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3504230.7628 - val_loss: 4993747.2974\n",
      "Epoch 4044/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3502515.5609 - val_loss: 5004959.1160\n",
      "Epoch 4045/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3502813.8854 - val_loss: 4988012.9080\n",
      "Epoch 4046/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3500229.6294 - val_loss: 5011219.3209\n",
      "Epoch 4047/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3505477.2825 - val_loss: 4997762.8262\n",
      "Epoch 4048/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3500406.0360 - val_loss: 5011082.3793\n",
      "Epoch 4049/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3502998.7878 - val_loss: 5012700.0224\n",
      "Epoch 4050/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3500384.9711 - val_loss: 5010564.2634\n",
      "Epoch 4051/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3500274.2583 - val_loss: 5025188.0213\n",
      "Epoch 4052/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3504884.0939 - val_loss: 4985006.9034\n",
      "Epoch 4053/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3501721.2077 - val_loss: 4998065.4455\n",
      "Epoch 4054/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3499219.2346 - val_loss: 5023845.1727\n",
      "Epoch 4055/5000\n",
      "40850/40850 [==============================] - ETA: 0s - loss: 3497020.547 - 1s 17us/sample - loss: 3501472.4392 - val_loss: 5013874.5996\n",
      "Epoch 4056/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3503446.6423 - val_loss: 5013408.7881\n",
      "Epoch 4057/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3502762.1047 - val_loss: 5001444.2125\n",
      "Epoch 4058/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3501714.0444 - val_loss: 5014453.4414\n",
      "Epoch 4059/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3504939.7363 - val_loss: 4994787.6831\n",
      "Epoch 4060/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504365.7259 - val_loss: 4975830.6419\n",
      "Epoch 4061/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498553.5840 - val_loss: 4998996.8498\n",
      "Epoch 4062/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498904.6938 - val_loss: 4971845.8644\n",
      "Epoch 4063/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3503382.0844 - val_loss: 5018151.9214\n",
      "Epoch 4064/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3503918.2194 - val_loss: 5017507.6538\n",
      "Epoch 4065/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3501110.1372 - val_loss: 5042655.5585\n",
      "Epoch 4066/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3501187.6262 - val_loss: 4998450.1094\n",
      "Epoch 4067/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3500134.6710 - val_loss: 5022994.1117\n",
      "Epoch 4068/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3498101.9349 - val_loss: 5014456.4334\n",
      "Epoch 4069/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3501276.0632 - val_loss: 5007149.2756\n",
      "Epoch 4070/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3498987.8432 - val_loss: 5004588.0389\n",
      "Epoch 4071/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3502318.8801 - val_loss: 4996943.1803\n",
      "Epoch 4072/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498777.2830 - val_loss: 5019291.5096\n",
      "Epoch 4073/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3502505.8033 - val_loss: 5003319.7755\n",
      "Epoch 4074/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3500087.7949 - val_loss: 4991124.4277\n",
      "Epoch 4075/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3503449.8939 - val_loss: 5003574.6163\n",
      "Epoch 4076/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3502170.7813 - val_loss: 5011648.1529\n",
      "Epoch 4077/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3505006.7467 - val_loss: 5004036.4674\n",
      "Epoch 4078/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3499332.0347 - val_loss: 5024548.4892\n",
      "Epoch 4079/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3496055.8917 - val_loss: 5006762.6806\n",
      "Epoch 4080/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3505318.4792 - val_loss: 5012806.7851\n",
      "Epoch 4081/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3500613.9549 - val_loss: 5010535.4143\n",
      "Epoch 4082/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3501352.5058 - val_loss: 5031304.8471\n",
      "Epoch 4083/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3499381.5960 - val_loss: 4987574.1657\n",
      "Epoch 4084/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3501452.1400 - val_loss: 5013824.3966\n",
      "Epoch 4085/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504824.2554 - val_loss: 5020232.6620\n",
      "Epoch 4086/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3503815.8114 - val_loss: 5014611.3516\n",
      "Epoch 4087/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498014.4421 - val_loss: 4984262.7583\n",
      "Epoch 4088/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3501303.1486 - val_loss: 5000737.7938\n",
      "Epoch 4089/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3502152.8013 - val_loss: 5022240.0855\n",
      "Epoch 4090/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3499126.3369 - val_loss: 4978243.9428\n",
      "Epoch 4091/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3501284.0610 - val_loss: 5002650.5757\n",
      "Epoch 4092/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3502860.3251 - val_loss: 5034771.4186\n",
      "Epoch 4093/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3500361.4281 - val_loss: 5039486.5108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4094/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3502438.8175 - val_loss: 5023567.2543\n",
      "Epoch 4095/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495627.0160 - val_loss: 5005343.1916\n",
      "Epoch 4096/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3497686.7346 - val_loss: 5014762.0109\n",
      "Epoch 4097/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3500492.7658 - val_loss: 5029498.2946\n",
      "Epoch 4098/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498958.8965 - val_loss: 5023187.2505\n",
      "Epoch 4099/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496092.4937 - val_loss: 5015971.4635\n",
      "Epoch 4100/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498230.1482 - val_loss: 4999957.3831\n",
      "Epoch 4101/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3499091.0232 - val_loss: 4990429.1841\n",
      "Epoch 4102/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3497251.9237 - val_loss: 4988685.3861\n",
      "Epoch 4103/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3498937.9152 - val_loss: 5034410.6794\n",
      "Epoch 4104/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3502471.9172 - val_loss: 4977001.3071\n",
      "Epoch 4105/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3501734.7169 - val_loss: 5022014.2672\n",
      "Epoch 4106/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495677.1237 - val_loss: 4983160.6281\n",
      "Epoch 4107/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3498596.4281 - val_loss: 5014079.2207\n",
      "Epoch 4108/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3499560.1869 - val_loss: 5014581.7492\n",
      "Epoch 4109/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3497786.2430 - val_loss: 5037548.4072\n",
      "Epoch 4110/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504482.7450 - val_loss: 5012464.7575\n",
      "Epoch 4111/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498131.9225 - val_loss: 4998635.6025\n",
      "Epoch 4112/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3501958.3605 - val_loss: 4994465.4423\n",
      "Epoch 4113/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495914.6213 - val_loss: 5029824.8941\n",
      "Epoch 4114/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3496572.5349 - val_loss: 5007659.6471\n",
      "Epoch 4115/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3505919.0118 - val_loss: 5016763.4825\n",
      "Epoch 4116/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496849.4172 - val_loss: 5019099.0839\n",
      "Epoch 4117/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3503345.2545 - val_loss: 4975380.3005\n",
      "Epoch 4118/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3498716.7379 - val_loss: 5046909.2728\n",
      "Epoch 4119/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3497762.2375 - val_loss: 5017561.3625\n",
      "Epoch 4120/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3496013.4263 - val_loss: 5010951.3302\n",
      "Epoch 4121/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3497781.9303 - val_loss: 5016846.7595\n",
      "Epoch 4122/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498787.5403 - val_loss: 5027990.2046\n",
      "Epoch 4123/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496109.1155 - val_loss: 5026884.8976\n",
      "Epoch 4124/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3495619.6886 - val_loss: 4990155.0695\n",
      "Epoch 4125/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3497384.5858 - val_loss: 5010885.1309\n",
      "Epoch 4126/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3499344.8219 - val_loss: 5036375.4613\n",
      "Epoch 4127/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3497378.8784 - val_loss: 5001984.8186\n",
      "Epoch 4128/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3499479.6290 - val_loss: 4989426.4846\n",
      "Epoch 4129/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3501658.1670 - val_loss: 5006955.5525\n",
      "Epoch 4130/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3501402.9428 - val_loss: 5023151.3518\n",
      "Epoch 4131/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3499686.3950 - val_loss: 4995537.0864\n",
      "Epoch 4132/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495668.1849 - val_loss: 5006694.7399\n",
      "Epoch 4133/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495930.6024 - val_loss: 5046350.1204\n",
      "Epoch 4134/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496681.0784 - val_loss: 5011773.0314\n",
      "Epoch 4135/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495848.0428 - val_loss: 5031350.2665\n",
      "Epoch 4136/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496537.0857 - val_loss: 4970705.1117\n",
      "Epoch 4137/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495683.5996 - val_loss: 5003229.3964\n",
      "Epoch 4138/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3504989.1450 - val_loss: 5025176.2682\n",
      "Epoch 4139/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3497459.8428 - val_loss: 5038556.6291\n",
      "Epoch 4140/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3497894.4648 - val_loss: 5018416.6469\n",
      "Epoch 4141/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3496792.7449 - val_loss: 4991662.9002\n",
      "Epoch 4142/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3498478.2929 - val_loss: 4997161.5407\n",
      "Epoch 4143/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3498824.1899 - val_loss: 4978137.1065\n",
      "Epoch 4144/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3497067.2920 - val_loss: 5012118.7745\n",
      "Epoch 4145/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3499479.7252 - val_loss: 4990623.0299\n",
      "Epoch 4146/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498845.2249 - val_loss: 5018149.9828\n",
      "Epoch 4147/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3497663.5350 - val_loss: 5039354.5867\n",
      "Epoch 4148/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493608.5482 - val_loss: 5015316.5680\n",
      "Epoch 4149/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3497893.2027 - val_loss: 5014060.9031\n",
      "Epoch 4150/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3498604.2506 - val_loss: 5002156.6845\n",
      "Epoch 4151/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495287.1134 - val_loss: 5038685.0307\n",
      "Epoch 4152/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493912.5098 - val_loss: 5016399.1568\n",
      "Epoch 4153/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3496056.6904 - val_loss: 5001748.0412\n",
      "Epoch 4154/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495194.5245 - val_loss: 5001427.3142\n",
      "Epoch 4155/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3496366.3634 - val_loss: 5048416.7651\n",
      "Epoch 4156/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495781.0384 - val_loss: 4999176.6965\n",
      "Epoch 4157/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496416.5695 - val_loss: 5004156.1900\n",
      "Epoch 4158/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3497973.2966 - val_loss: 5004461.1350\n",
      "Epoch 4159/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3494299.8115 - val_loss: 5004463.8975\n",
      "Epoch 4160/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3499251.0782 - val_loss: 5033497.3282\n",
      "Epoch 4161/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3498996.4139 - val_loss: 5024048.3043\n",
      "Epoch 4162/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495458.2071 - val_loss: 4990613.8403\n",
      "Epoch 4163/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3496258.0901 - val_loss: 5035160.2693\n",
      "Epoch 4164/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495960.4973 - val_loss: 4981111.0953\n",
      "Epoch 4165/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495993.2579 - val_loss: 4989841.0171\n",
      "Epoch 4166/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495723.8611 - val_loss: 5003236.0093\n",
      "Epoch 4167/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3498942.4750 - val_loss: 4996393.3964\n",
      "Epoch 4168/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3498090.5758 - val_loss: 5008054.1109\n",
      "Epoch 4169/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498023.6117 - val_loss: 5015733.7462\n",
      "Epoch 4170/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3500466.6427 - val_loss: 5005391.1669\n",
      "Epoch 4171/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495319.2052 - val_loss: 5048571.5500\n",
      "Epoch 4172/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498455.1385 - val_loss: 5018763.5582\n",
      "Epoch 4173/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495822.2598 - val_loss: 5022351.6649\n",
      "Epoch 4174/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495412.5829 - val_loss: 5002717.2197\n",
      "Epoch 4175/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493121.3398 - val_loss: 5017323.3403\n",
      "Epoch 4176/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495003.4500 - val_loss: 5029103.4019\n",
      "Epoch 4177/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3496814.8522 - val_loss: 4972327.7332\n",
      "Epoch 4178/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495866.6331 - val_loss: 5033983.4895\n",
      "Epoch 4179/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3499624.2102 - val_loss: 5013991.4022\n",
      "Epoch 4180/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495910.0075 - val_loss: 4995395.1663\n",
      "Epoch 4181/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3495595.9332 - val_loss: 5035025.6472\n",
      "Epoch 4182/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494344.6408 - val_loss: 5010545.0681\n",
      "Epoch 4183/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3497950.7337 - val_loss: 4987487.2609\n",
      "Epoch 4184/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3503569.1233 - val_loss: 5017617.0076\n",
      "Epoch 4185/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3497491.1545 - val_loss: 4983789.8056\n",
      "Epoch 4186/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498371.9521 - val_loss: 4997744.5202\n",
      "Epoch 4187/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3497665.3784 - val_loss: 4996787.3764\n",
      "Epoch 4188/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494598.1661 - val_loss: 4992711.7758\n",
      "Epoch 4189/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493295.6735 - val_loss: 5004856.9669\n",
      "Epoch 4190/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493834.4585 - val_loss: 5007501.6508\n",
      "Epoch 4191/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493381.9388 - val_loss: 5021965.8004\n",
      "Epoch 4192/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493434.3660 - val_loss: 5015107.8440\n",
      "Epoch 4193/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492753.4128 - val_loss: 4988585.7725\n",
      "Epoch 4194/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498194.1691 - val_loss: 5005353.7507\n",
      "Epoch 4195/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494394.7269 - val_loss: 5003564.4827\n",
      "Epoch 4196/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495831.1205 - val_loss: 5005987.8160\n",
      "Epoch 4197/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495854.1704 - val_loss: 4980310.6702\n",
      "Epoch 4198/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495376.1731 - val_loss: 4998664.7712\n",
      "Epoch 4199/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495875.1726 - val_loss: 5016748.5957\n",
      "Epoch 4200/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493292.6772 - val_loss: 4988567.1843\n",
      "Epoch 4201/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496607.3553 - val_loss: 5023603.5407\n",
      "Epoch 4202/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3493806.4185 - val_loss: 5046915.6675\n",
      "Epoch 4203/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3496085.9426 - val_loss: 5015225.6991\n",
      "Epoch 4204/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3495383.3189 - val_loss: 5023403.0535\n",
      "Epoch 4205/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3499585.5289 - val_loss: 5041949.4977\n",
      "Epoch 4206/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3495655.6799 - val_loss: 4990241.8848\n",
      "Epoch 4207/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496044.0925 - val_loss: 5003461.8665\n",
      "Epoch 4208/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498549.3117 - val_loss: 5038019.9095\n",
      "Epoch 4209/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494269.5042 - val_loss: 5038094.0872\n",
      "Epoch 4210/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3490335.3835 - val_loss: 5009503.4247\n",
      "Epoch 4211/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494768.0590 - val_loss: 4996472.9341\n",
      "Epoch 4212/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493614.8025 - val_loss: 5051645.0986\n",
      "Epoch 4213/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494926.0159 - val_loss: 5043450.0102\n",
      "Epoch 4214/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496752.9889 - val_loss: 5012828.7780\n",
      "Epoch 4215/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495137.4783 - val_loss: 5050226.5012\n",
      "Epoch 4216/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496116.5526 - val_loss: 5020008.5141\n",
      "Epoch 4217/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492427.5716 - val_loss: 5027374.6809\n",
      "Epoch 4218/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494471.4338 - val_loss: 4998497.0824\n",
      "Epoch 4219/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493278.4035 - val_loss: 5022497.0912\n",
      "Epoch 4220/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498497.7535 - val_loss: 4993248.1695\n",
      "Epoch 4221/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496928.2401 - val_loss: 4991588.3204\n",
      "Epoch 4222/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3500532.8142 - val_loss: 5007867.8638\n",
      "Epoch 4223/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495576.2591 - val_loss: 5003566.5165\n",
      "Epoch 4224/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494725.8670 - val_loss: 5013899.3391\n",
      "Epoch 4225/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3491526.4100 - val_loss: 5002626.5948\n",
      "Epoch 4226/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3497285.7186 - val_loss: 4990745.3265\n",
      "Epoch 4227/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3494451.3202 - val_loss: 5077850.9838\n",
      "Epoch 4228/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3496959.4740 - val_loss: 5026276.7751\n",
      "Epoch 4229/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3492854.1090 - val_loss: 5018331.9444\n",
      "Epoch 4230/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3502877.8845 - val_loss: 5007716.4774\n",
      "Epoch 4231/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493695.2442 - val_loss: 5020485.4570\n",
      "Epoch 4232/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3490458.4276 - val_loss: 5003538.2752\n",
      "Epoch 4233/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495949.6334 - val_loss: 5005700.8830\n",
      "Epoch 4234/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3498099.8541 - val_loss: 4991755.5476\n",
      "Epoch 4235/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493869.7374 - val_loss: 5007816.4653\n",
      "Epoch 4236/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3496523.4561 - val_loss: 5005107.6150\n",
      "Epoch 4237/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493725.0382 - val_loss: 5019518.2642\n",
      "Epoch 4238/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492557.1741 - val_loss: 5004163.0241\n",
      "Epoch 4239/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492799.8643 - val_loss: 5031447.0227\n",
      "Epoch 4240/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495895.9630 - val_loss: 5020681.9963\n",
      "Epoch 4241/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493463.4992 - val_loss: 5011626.2429\n",
      "Epoch 4242/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3496418.4758 - val_loss: 5013966.4978\n",
      "Epoch 4243/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492479.6813 - val_loss: 4981003.4648\n",
      "Epoch 4244/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493974.7579 - val_loss: 5018151.5965\n",
      "Epoch 4245/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3493150.5374 - val_loss: 5017038.2896\n",
      "Epoch 4246/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3494897.0630 - val_loss: 5021813.7844\n",
      "Epoch 4247/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492109.9842 - val_loss: 5005909.5358\n",
      "Epoch 4248/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3499499.6419 - val_loss: 5011747.5299\n",
      "Epoch 4249/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493274.1319 - val_loss: 5025761.0459\n",
      "Epoch 4250/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495438.2140 - val_loss: 5048549.3396\n",
      "Epoch 4251/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3499132.2862 - val_loss: 5023208.4729\n",
      "Epoch 4252/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493476.2702 - val_loss: 5015318.5551\n",
      "Epoch 4253/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3491843.7080 - val_loss: 5015328.6760\n",
      "Epoch 4254/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495052.6995 - val_loss: 5028214.0673\n",
      "Epoch 4255/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495059.4973 - val_loss: 5024313.9047\n",
      "Epoch 4256/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3492834.3141 - val_loss: 5017204.6077\n",
      "Epoch 4257/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493775.7978 - val_loss: 5017306.3441\n",
      "Epoch 4258/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3490461.7674 - val_loss: 5009285.7759\n",
      "Epoch 4259/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3494693.5153 - val_loss: 4994812.1364\n",
      "Epoch 4260/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496164.0376 - val_loss: 4998302.8943\n",
      "Epoch 4261/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494798.1215 - val_loss: 5004455.0977\n",
      "Epoch 4262/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3496895.8505 - val_loss: 5040976.0274\n",
      "Epoch 4263/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3491855.7286 - val_loss: 5008517.7703\n",
      "Epoch 4264/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3491154.3642 - val_loss: 5009900.3067\n",
      "Epoch 4265/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3488750.4258 - val_loss: 5052448.2082\n",
      "Epoch 4266/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3493330.2896 - val_loss: 5016870.7925\n",
      "Epoch 4267/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495558.1884 - val_loss: 5001665.3956\n",
      "Epoch 4268/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494533.7788 - val_loss: 5006353.3311\n",
      "Epoch 4269/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3490799.3725 - val_loss: 5008637.9842\n",
      "Epoch 4270/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3500465.2131 - val_loss: 5001504.7067\n",
      "Epoch 4271/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3491799.0897 - val_loss: 5009953.5048\n",
      "Epoch 4272/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3492576.5835 - val_loss: 5000775.6875\n",
      "Epoch 4273/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492598.8148 - val_loss: 5001994.0323\n",
      "Epoch 4274/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3495027.1121 - val_loss: 5034528.7340\n",
      "Epoch 4275/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3490448.9447 - val_loss: 5047633.1906\n",
      "Epoch 4276/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3491611.8860 - val_loss: 4995047.2819\n",
      "Epoch 4277/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493065.8532 - val_loss: 4990222.3118\n",
      "Epoch 4278/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3490953.0690 - val_loss: 4987217.1341\n",
      "Epoch 4279/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3490306.6111 - val_loss: 5005323.4920\n",
      "Epoch 4280/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494736.3402 - val_loss: 5009890.1405\n",
      "Epoch 4281/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493310.6205 - val_loss: 5023511.7495\n",
      "Epoch 4282/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3495720.0763 - val_loss: 5015759.4319\n",
      "Epoch 4283/5000\n",
      "40850/40850 [==============================] - 1s 19us/sample - loss: 3493316.9701 - val_loss: 5019179.5817\n",
      "Epoch 4284/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3488000.7094 - val_loss: 4981521.3309\n",
      "Epoch 4285/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3491524.4021 - val_loss: 5036956.7155\n",
      "Epoch 4286/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493666.8647 - val_loss: 5012383.1203\n",
      "Epoch 4287/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494215.9691 - val_loss: 5002651.5602\n",
      "Epoch 4288/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3490725.5800 - val_loss: 5023486.3889\n",
      "Epoch 4289/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493773.0002 - val_loss: 5005290.7397\n",
      "Epoch 4290/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3491025.2428 - val_loss: 4982935.2736\n",
      "Epoch 4291/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3492862.9172 - val_loss: 4994306.3475\n",
      "Epoch 4292/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3489330.1869 - val_loss: 5004514.3517\n",
      "Epoch 4293/5000\n",
      "40850/40850 [==============================] - ETA: 0s - loss: 3511737.596 - 1s 15us/sample - loss: 3489279.7602 - val_loss: 5051624.1632\n",
      "Epoch 4294/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493771.8939 - val_loss: 4999238.6851\n",
      "Epoch 4295/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3490233.9696 - val_loss: 4984738.0439\n",
      "Epoch 4296/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3491543.4846 - val_loss: 5041441.6589\n",
      "Epoch 4297/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3488415.2360 - val_loss: 4991779.2973\n",
      "Epoch 4298/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494292.5853 - val_loss: 5004450.3754\n",
      "Epoch 4299/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3491032.0024 - val_loss: 5004025.5440\n",
      "Epoch 4300/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494738.7469 - val_loss: 5017591.8979\n",
      "Epoch 4301/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3488909.3136 - val_loss: 4971619.9577\n",
      "Epoch 4302/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3490096.7295 - val_loss: 4992102.0831\n",
      "Epoch 4303/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492561.6161 - val_loss: 5050654.2402\n",
      "Epoch 4304/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3496465.4276 - val_loss: 5024293.8345\n",
      "Epoch 4305/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493015.1506 - val_loss: 5001681.5056\n",
      "Epoch 4306/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3490511.4098 - val_loss: 5034423.9084\n",
      "Epoch 4307/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3489613.2033 - val_loss: 5023867.2736\n",
      "Epoch 4308/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3491549.6967 - val_loss: 4976726.8018\n",
      "Epoch 4309/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3489537.5554 - val_loss: 5037096.9421\n",
      "Epoch 4310/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3499584.0286 - val_loss: 5057019.5746\n",
      "Epoch 4311/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3489876.0151 - val_loss: 5022305.7765\n",
      "Epoch 4312/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3489556.9087 - val_loss: 4997087.5218\n",
      "Epoch 4313/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3493953.7294 - val_loss: 4997895.8709\n",
      "Epoch 4314/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3488364.9913 - val_loss: 4979106.1335\n",
      "Epoch 4315/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3490817.7423 - val_loss: 5004722.9547\n",
      "Epoch 4316/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493728.2248 - val_loss: 5022196.9450\n",
      "Epoch 4317/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3490574.2821 - val_loss: 5031510.1275\n",
      "Epoch 4318/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3491300.5482 - val_loss: 4990004.2983\n",
      "Epoch 4319/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492489.0214 - val_loss: 5015871.2278\n",
      "Epoch 4320/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3490708.4561 - val_loss: 4989016.7119\n",
      "Epoch 4321/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3490045.6226 - val_loss: 4989279.8254\n",
      "Epoch 4322/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492176.5879 - val_loss: 5029204.7407\n",
      "Epoch 4323/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495983.9001 - val_loss: 5027239.5433\n",
      "Epoch 4324/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3487668.4188 - val_loss: 5050496.5186\n",
      "Epoch 4325/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3491693.7704 - val_loss: 5028342.6960\n",
      "Epoch 4326/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3491502.7835 - val_loss: 5005563.6486\n",
      "Epoch 4327/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3490789.8489 - val_loss: 4995756.7974\n",
      "Epoch 4328/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3489365.4905 - val_loss: 5008023.6453\n",
      "Epoch 4329/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3491113.1657 - val_loss: 4997554.8184\n",
      "Epoch 4330/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3489351.6674 - val_loss: 5001321.2962\n",
      "Epoch 4331/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3491996.4719 - val_loss: 4985856.7293\n",
      "Epoch 4332/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3490690.6799 - val_loss: 4995583.4745\n",
      "Epoch 4333/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492701.4697 - val_loss: 4999347.1310\n",
      "Epoch 4334/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3490101.0550 - val_loss: 5011439.4509\n",
      "Epoch 4335/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493367.8497 - val_loss: 5021012.9230\n",
      "Epoch 4336/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3490542.0882 - val_loss: 5007142.3449\n",
      "Epoch 4337/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3491586.1943 - val_loss: 5000162.5267\n",
      "Epoch 4338/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3494002.5987 - val_loss: 5013525.7457\n",
      "Epoch 4339/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3495196.9506 - val_loss: 5016874.3175\n",
      "Epoch 4340/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3487335.9045 - val_loss: 5012106.9618\n",
      "Epoch 4341/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3492664.9131 - val_loss: 4987228.8551\n",
      "Epoch 4342/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3489408.3395 - val_loss: 5021803.5028\n",
      "Epoch 4343/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3487374.2726 - val_loss: 5021563.0178\n",
      "Epoch 4344/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3492658.3146 - val_loss: 5019133.4852\n",
      "Epoch 4345/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3492769.0994 - val_loss: 5024144.7744\n",
      "Epoch 4346/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3489951.2599 - val_loss: 5015997.9570\n",
      "Epoch 4347/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3491722.5078 - val_loss: 5010931.1195\n",
      "Epoch 4348/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3495621.4315 - val_loss: 5015509.2146\n",
      "Epoch 4349/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3491758.0818 - val_loss: 5022831.7936\n",
      "Epoch 4350/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3489206.5416 - val_loss: 5030363.2237\n",
      "Epoch 4351/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3489908.0196 - val_loss: 5004086.1288\n",
      "Epoch 4352/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3491860.6375 - val_loss: 5025326.6191\n",
      "Epoch 4353/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3488720.1956 - val_loss: 5050221.2427\n",
      "Epoch 4354/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3491662.7535 - val_loss: 5002238.1147\n",
      "Epoch 4355/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3487862.1728 - val_loss: 5041505.2642\n",
      "Epoch 4356/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3490353.8219 - val_loss: 5007225.1727\n",
      "Epoch 4357/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3488332.8160 - val_loss: 5011409.1936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4358/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3488182.1951 - val_loss: 5008880.3437\n",
      "Epoch 4359/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3489112.3171 - val_loss: 5011916.6802\n",
      "Epoch 4360/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3491916.7886 - val_loss: 5013092.4123\n",
      "Epoch 4361/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3490499.3462 - val_loss: 5019068.6203\n",
      "Epoch 4362/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3489596.9419 - val_loss: 5013045.5131\n",
      "Epoch 4363/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3493181.2077 - val_loss: 5043769.4227\n",
      "Epoch 4364/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3488977.2110 - val_loss: 5011802.2372\n",
      "Epoch 4365/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3488156.3230 - val_loss: 5018361.5879\n",
      "Epoch 4366/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3488832.2595 - val_loss: 4994932.6361\n",
      "Epoch 4367/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3489158.4160 - val_loss: 5032360.9679\n",
      "Epoch 4368/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3489659.5831 - val_loss: 5017332.8756\n",
      "Epoch 4369/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3489505.2981 - val_loss: 5005265.1732\n",
      "Epoch 4370/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3490164.3662 - val_loss: 5011666.3092\n",
      "Epoch 4371/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3494299.8565 - val_loss: 5020962.4784\n",
      "Epoch 4372/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3487229.6808 - val_loss: 5007549.9464\n",
      "Epoch 4373/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3489934.9020 - val_loss: 5028143.4088\n",
      "Epoch 4374/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3495169.0872 - val_loss: 5027807.4461\n",
      "Epoch 4375/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3490613.8603 - val_loss: 5004255.3801\n",
      "Epoch 4376/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487823.0857 - val_loss: 5014075.5406\n",
      "Epoch 4377/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492127.7247 - val_loss: 5022833.2861\n",
      "Epoch 4378/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3486517.8708 - val_loss: 5063691.2861\n",
      "Epoch 4379/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3490973.1520 - val_loss: 5025128.3206\n",
      "Epoch 4380/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3495825.0887 - val_loss: 5007910.9755\n",
      "Epoch 4381/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3492390.4765 - val_loss: 4996280.8753\n",
      "Epoch 4382/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3491333.1626 - val_loss: 5000966.7110\n",
      "Epoch 4383/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3493107.3442 - val_loss: 5023497.6193\n",
      "Epoch 4384/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3485728.2808 - val_loss: 4986837.4727\n",
      "Epoch 4385/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3491636.3950 - val_loss: 5004844.3829\n",
      "Epoch 4386/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3490652.3166 - val_loss: 5016439.1707\n",
      "Epoch 4387/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3491515.4407 - val_loss: 5010874.3926\n",
      "Epoch 4388/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3490255.5099 - val_loss: 5013128.8944\n",
      "Epoch 4389/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3487477.5956 - val_loss: 5007961.0930\n",
      "Epoch 4390/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3486365.4095 - val_loss: 5001659.5755\n",
      "Epoch 4391/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3488913.3682 - val_loss: 5026005.7018\n",
      "Epoch 4392/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3488511.7893 - val_loss: 5006564.8486\n",
      "Epoch 4393/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3488983.4121 - val_loss: 5063414.4467\n",
      "Epoch 4394/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3493235.9170 - val_loss: 4989454.5034\n",
      "Epoch 4395/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3488520.8131 - val_loss: 5022384.5386\n",
      "Epoch 4396/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3489885.5607 - val_loss: 5022967.9697\n",
      "Epoch 4397/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3494479.8973 - val_loss: 5032968.3679\n",
      "Epoch 4398/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3488590.2203 - val_loss: 4991009.1841\n",
      "Epoch 4399/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3490963.8407 - val_loss: 5065681.6808\n",
      "Epoch 4400/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3490509.8319 - val_loss: 4999198.1816\n",
      "Epoch 4401/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3486023.3029 - val_loss: 5025199.9741\n",
      "Epoch 4402/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3487752.7131 - val_loss: 5009207.5112\n",
      "Epoch 4403/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3489310.4957 - val_loss: 5019019.4323\n",
      "Epoch 4404/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3488928.9290 - val_loss: 5027972.8097\n",
      "Epoch 4405/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3488539.0032 - val_loss: 5048505.1396\n",
      "Epoch 4406/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483324.9083 - val_loss: 5058797.1022\n",
      "Epoch 4407/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3496601.3990 - val_loss: 5040875.8568\n",
      "Epoch 4408/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3488512.7906 - val_loss: 5021760.4216\n",
      "Epoch 4409/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3491359.9382 - val_loss: 5015343.2893\n",
      "Epoch 4410/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486594.2334 - val_loss: 5042061.5619\n",
      "Epoch 4411/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3488105.4556 - val_loss: 5012117.1142\n",
      "Epoch 4412/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487216.0139 - val_loss: 5014886.2798\n",
      "Epoch 4413/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3489492.2703 - val_loss: 4993298.7858\n",
      "Epoch 4414/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3488815.8306 - val_loss: 5007933.9385\n",
      "Epoch 4415/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486869.3182 - val_loss: 4998535.1213\n",
      "Epoch 4416/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486518.8685 - val_loss: 5028709.0543\n",
      "Epoch 4417/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486503.2675 - val_loss: 5029624.9892\n",
      "Epoch 4418/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486053.0176 - val_loss: 5023443.8821\n",
      "Epoch 4419/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3492898.9810 - val_loss: 5048133.0439\n",
      "Epoch 4420/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3487440.2620 - val_loss: 5052917.5148\n",
      "Epoch 4421/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3489157.7645 - val_loss: 5023515.0930\n",
      "Epoch 4422/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3486806.2673 - val_loss: 5021327.1459\n",
      "Epoch 4423/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3490600.3803 - val_loss: 5027085.5099\n",
      "Epoch 4424/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3488832.0465 - val_loss: 5020132.8387\n",
      "Epoch 4425/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3488200.4202 - val_loss: 5039438.0464\n",
      "Epoch 4426/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3486958.9668 - val_loss: 4990958.9063\n",
      "Epoch 4427/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3490263.6222 - val_loss: 4996470.0964\n",
      "Epoch 4428/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3488358.0130 - val_loss: 5043748.4129\n",
      "Epoch 4429/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3489868.0399 - val_loss: 5027820.5806\n",
      "Epoch 4430/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3485424.8151 - val_loss: 5033044.5611\n",
      "Epoch 4431/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3485669.8412 - val_loss: 5034633.2730\n",
      "Epoch 4432/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3484131.8903 - val_loss: 5019562.0478\n",
      "Epoch 4433/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3487019.5919 - val_loss: 5011920.3937\n",
      "Epoch 4434/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3489471.9966 - val_loss: 5023093.9536\n",
      "Epoch 4435/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3488027.6762 - val_loss: 5002792.2817\n",
      "Epoch 4436/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3486526.0993 - val_loss: 5020934.4586\n",
      "Epoch 4437/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3484907.2788 - val_loss: 5032030.3655\n",
      "Epoch 4438/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3486606.8473 - val_loss: 5028011.9544\n",
      "Epoch 4439/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3486196.6476 - val_loss: 5018451.3412\n",
      "Epoch 4440/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3485947.7885 - val_loss: 5015977.1436\n",
      "Epoch 4441/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3485739.0947 - val_loss: 5015080.5254\n",
      "Epoch 4442/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3489052.3938 - val_loss: 5052164.1539\n",
      "Epoch 4443/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3487855.9161 - val_loss: 5027362.9594\n",
      "Epoch 4444/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3485687.8460 - val_loss: 5033041.9003\n",
      "Epoch 4445/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3489270.0250 - val_loss: 5050088.5063\n",
      "Epoch 4446/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3485205.6591 - val_loss: 5024892.7184\n",
      "Epoch 4447/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3489181.4944 - val_loss: 5027324.9963\n",
      "Epoch 4448/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3488790.2808 - val_loss: 5005975.8001\n",
      "Epoch 4449/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482729.1262 - val_loss: 4999797.8092\n",
      "Epoch 4450/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484959.9054 - val_loss: 5039494.5982\n",
      "Epoch 4451/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487886.1771 - val_loss: 5027458.2333\n",
      "Epoch 4452/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485817.0508 - val_loss: 5026721.0274\n",
      "Epoch 4453/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485382.8343 - val_loss: 5032804.5585\n",
      "Epoch 4454/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3489342.3934 - val_loss: 5032240.1534\n",
      "Epoch 4455/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3494980.8478 - val_loss: 5061080.3934\n",
      "Epoch 4456/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486822.7197 - val_loss: 5022039.8564\n",
      "Epoch 4457/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485583.7061 - val_loss: 5009006.2729\n",
      "Epoch 4458/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3491117.3045 - val_loss: 5011077.1544\n",
      "Epoch 4459/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3492260.6325 - val_loss: 5034843.8955\n",
      "Epoch 4460/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3488327.7946 - val_loss: 5019104.4119\n",
      "Epoch 4461/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3491062.2785 - val_loss: 5037270.4700\n",
      "Epoch 4462/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3489474.7608 - val_loss: 5010391.7052\n",
      "Epoch 4463/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3483897.4207 - val_loss: 5018470.6043\n",
      "Epoch 4464/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3490552.9080 - val_loss: 5041522.6686\n",
      "Epoch 4465/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3486372.8986 - val_loss: 5039440.5740\n",
      "Epoch 4466/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3484829.0582 - val_loss: 5011926.3538\n",
      "Epoch 4467/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3487800.7715 - val_loss: 5033004.1303\n",
      "Epoch 4468/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3488574.4442 - val_loss: 5019532.5919\n",
      "Epoch 4469/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3493302.1605 - val_loss: 4983028.0306\n",
      "Epoch 4470/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3489094.1340 - val_loss: 5033225.4323\n",
      "Epoch 4471/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3490855.2871 - val_loss: 5032147.0871\n",
      "Epoch 4472/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3489270.4529 - val_loss: 5024519.6365\n",
      "Epoch 4473/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3489430.0216 - val_loss: 5041668.5470\n",
      "Epoch 4474/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3488544.0616 - val_loss: 5008811.8199\n",
      "Epoch 4475/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3485508.4340 - val_loss: 5054627.8837\n",
      "Epoch 4476/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3485889.0080 - val_loss: 5000534.3341\n",
      "Epoch 4477/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3488754.4211 - val_loss: 5034284.0883\n",
      "Epoch 4478/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3486791.6113 - val_loss: 5043566.3307\n",
      "Epoch 4479/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3487383.2658 - val_loss: 5011616.5384\n",
      "Epoch 4480/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3488522.9288 - val_loss: 5021902.9768\n",
      "Epoch 4481/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3488899.3296 - val_loss: 5009516.8894\n",
      "Epoch 4482/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3493010.8823 - val_loss: 5014762.8249\n",
      "Epoch 4483/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484997.2199 - val_loss: 5030829.0151\n",
      "Epoch 4484/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3484109.7444 - val_loss: 5016865.1711\n",
      "Epoch 4485/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3484604.0997 - val_loss: 5029970.4797\n",
      "Epoch 4486/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3484579.0006 - val_loss: 5055036.2757\n",
      "Epoch 4487/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3486411.5192 - val_loss: 5013217.2524\n",
      "Epoch 4488/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3486259.3482 - val_loss: 5035956.0949\n",
      "Epoch 4489/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486300.5329 - val_loss: 5025005.0644\n",
      "Epoch 4490/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486540.6533 - val_loss: 5032904.3092\n",
      "Epoch 4491/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487298.8958 - val_loss: 5007390.3663\n",
      "Epoch 4492/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3487406.0838 - val_loss: 5066709.9918\n",
      "Epoch 4493/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486493.3119 - val_loss: 5019266.4140\n",
      "Epoch 4494/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3485351.5234 - val_loss: 5048646.6548\n",
      "Epoch 4495/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3491708.6920 - val_loss: 5019149.5496\n",
      "Epoch 4496/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486501.2054 - val_loss: 5030978.3080\n",
      "Epoch 4497/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3489543.5809 - val_loss: 5012408.6019\n",
      "Epoch 4498/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481691.3506 - val_loss: 5055783.4531\n",
      "Epoch 4499/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485771.7220 - val_loss: 5011970.8631\n",
      "Epoch 4500/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487720.4192 - val_loss: 5037541.6865\n",
      "Epoch 4501/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3489851.9662 - val_loss: 5003640.1389\n",
      "Epoch 4502/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487921.4088 - val_loss: 5022833.0849\n",
      "Epoch 4503/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486261.0454 - val_loss: 5030681.7892\n",
      "Epoch 4504/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484353.2627 - val_loss: 5018851.6522\n",
      "Epoch 4505/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483656.1943 - val_loss: 5014783.1582\n",
      "Epoch 4506/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3488844.5492 - val_loss: 5046571.0695\n",
      "Epoch 4507/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486115.2585 - val_loss: 5017681.4121\n",
      "Epoch 4508/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483862.1102 - val_loss: 5028122.4696\n",
      "Epoch 4509/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486541.6519 - val_loss: 5025288.6016\n",
      "Epoch 4510/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486730.7540 - val_loss: 5027273.3889\n",
      "Epoch 4511/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3485247.7727 - val_loss: 5046700.6359\n",
      "Epoch 4512/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484747.3433 - val_loss: 5026206.6865\n",
      "Epoch 4513/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3485389.1988 - val_loss: 5053086.0219\n",
      "Epoch 4514/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483336.5946 - val_loss: 5052669.5919\n",
      "Epoch 4515/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482509.6833 - val_loss: 5048895.0281\n",
      "Epoch 4516/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3484145.0877 - val_loss: 5012885.9157\n",
      "Epoch 4517/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3483822.5350 - val_loss: 5005656.1071\n",
      "Epoch 4518/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3485423.7886 - val_loss: 5001619.3990\n",
      "Epoch 4519/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3487119.9310 - val_loss: 5044205.3219\n",
      "Epoch 4520/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3488054.4581 - val_loss: 5065574.8101\n",
      "Epoch 4521/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3481449.1123 - val_loss: 5030656.4008\n",
      "Epoch 4522/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3488606.8554 - val_loss: 5004594.5175\n",
      "Epoch 4523/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3485132.5176 - val_loss: 5008657.4787\n",
      "Epoch 4524/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3485220.8143 - val_loss: 4998836.9981\n",
      "Epoch 4525/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3484260.6786 - val_loss: 5030993.1342\n",
      "Epoch 4526/5000\n",
      "40850/40850 [==============================] - 1s 12us/sample - loss: 3489624.7036 - val_loss: 5052620.6966\n",
      "Epoch 4527/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3486413.8382 - val_loss: 5034522.3534\n",
      "Epoch 4528/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3487531.3247 - val_loss: 5029331.1522\n",
      "Epoch 4529/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3483431.2991 - val_loss: 5046465.8041\n",
      "Epoch 4530/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3481946.1204 - val_loss: 5034668.3275\n",
      "Epoch 4531/5000\n",
      "40850/40850 [==============================] - 1s 13us/sample - loss: 3483543.2696 - val_loss: 5022447.6236\n",
      "Epoch 4532/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486882.3665 - val_loss: 5029885.4498\n",
      "Epoch 4533/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487275.0655 - val_loss: 5039413.5854\n",
      "Epoch 4534/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485458.1365 - val_loss: 5039784.7813\n",
      "Epoch 4535/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484575.1101 - val_loss: 5016229.4998\n",
      "Epoch 4536/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3489039.2266 - val_loss: 5060241.6886\n",
      "Epoch 4537/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3489054.2502 - val_loss: 5011329.0401\n",
      "Epoch 4538/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3487042.6712 - val_loss: 5039128.3948\n",
      "Epoch 4539/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3485485.7155 - val_loss: 5013046.8602\n",
      "Epoch 4540/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484235.9837 - val_loss: 5006036.5421\n",
      "Epoch 4541/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486694.6498 - val_loss: 5051473.1730\n",
      "Epoch 4542/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483832.1970 - val_loss: 5028993.2397\n",
      "Epoch 4543/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3489067.3481 - val_loss: 5005516.1269\n",
      "Epoch 4544/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485622.4756 - val_loss: 5052480.8609\n",
      "Epoch 4545/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3484616.0986 - val_loss: 5038368.3724\n",
      "Epoch 4546/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484241.1123 - val_loss: 5031559.5220\n",
      "Epoch 4547/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486549.0851 - val_loss: 5044145.2181\n",
      "Epoch 4548/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487504.7273 - val_loss: 5037119.2481\n",
      "Epoch 4549/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483340.5713 - val_loss: 5065793.2303\n",
      "Epoch 4550/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486061.0025 - val_loss: 5014382.3344\n",
      "Epoch 4551/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3492031.6718 - val_loss: 5014290.0473\n",
      "Epoch 4552/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482722.0586 - val_loss: 5037604.2766\n",
      "Epoch 4553/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485120.7253 - val_loss: 5045360.0850\n",
      "Epoch 4554/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3485217.2725 - val_loss: 5008426.4088\n",
      "Epoch 4555/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3485739.2183 - val_loss: 5020444.1433\n",
      "Epoch 4556/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487432.6356 - val_loss: 5010686.8045\n",
      "Epoch 4557/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483994.8037 - val_loss: 5051794.3693\n",
      "Epoch 4558/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485206.6190 - val_loss: 5015084.3100\n",
      "Epoch 4559/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486155.3098 - val_loss: 5031055.2394\n",
      "Epoch 4560/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481061.4551 - val_loss: 5005314.7589\n",
      "Epoch 4561/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482471.8157 - val_loss: 4996479.5513\n",
      "Epoch 4562/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3487367.4875 - val_loss: 5027858.4288\n",
      "Epoch 4563/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481230.3646 - val_loss: 5049177.5112\n",
      "Epoch 4564/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481380.6789 - val_loss: 5024581.8388\n",
      "Epoch 4565/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3485362.4956 - val_loss: 5042532.2516\n",
      "Epoch 4566/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486943.8657 - val_loss: 5027005.7150\n",
      "Epoch 4567/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483842.9228 - val_loss: 5028143.2064\n",
      "Epoch 4568/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3487506.9332 - val_loss: 4997129.9142\n",
      "Epoch 4569/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3488987.5352 - val_loss: 5032318.3954\n",
      "Epoch 4570/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483729.7053 - val_loss: 5027812.3123\n",
      "Epoch 4571/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480872.2272 - val_loss: 5048619.2313\n",
      "Epoch 4572/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3485388.8389 - val_loss: 5025876.1586\n",
      "Epoch 4573/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3490192.1401 - val_loss: 5055927.7220\n",
      "Epoch 4574/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487843.0821 - val_loss: 5034722.4896\n",
      "Epoch 4575/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487229.1516 - val_loss: 5035808.0038\n",
      "Epoch 4576/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486239.3686 - val_loss: 5042371.4230\n",
      "Epoch 4577/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487073.5827 - val_loss: 5048483.1016\n",
      "Epoch 4578/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484252.4595 - val_loss: 5046911.0335\n",
      "Epoch 4579/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486702.1718 - val_loss: 5033818.8263\n",
      "Epoch 4580/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3483129.6738 - val_loss: 5031744.5842\n",
      "Epoch 4581/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3480244.4114 - val_loss: 5035967.4755\n",
      "Epoch 4582/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483855.0914 - val_loss: 5009950.6888\n",
      "Epoch 4583/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484529.6063 - val_loss: 5039393.6893\n",
      "Epoch 4584/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483874.8705 - val_loss: 5048326.1132\n",
      "Epoch 4585/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486611.7933 - val_loss: 5044623.6715\n",
      "Epoch 4586/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485702.1159 - val_loss: 5026285.1981\n",
      "Epoch 4587/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3490695.3064 - val_loss: 5022844.1164\n",
      "Epoch 4588/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484540.4925 - val_loss: 5046518.6734\n",
      "Epoch 4589/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484138.1678 - val_loss: 5029007.7114\n",
      "Epoch 4590/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487887.2982 - val_loss: 5028156.1620\n",
      "Epoch 4591/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483947.3266 - val_loss: 5051303.2558\n",
      "Epoch 4592/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484891.9853 - val_loss: 5024089.8623\n",
      "Epoch 4593/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484442.2381 - val_loss: 5056801.5882\n",
      "Epoch 4594/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3483753.4364 - val_loss: 5027898.1049\n",
      "Epoch 4595/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3485180.5270 - val_loss: 5016549.2599\n",
      "Epoch 4596/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3484656.4116 - val_loss: 5036606.8586\n",
      "Epoch 4597/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3483731.8633 - val_loss: 5026070.0178\n",
      "Epoch 4598/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3484777.3243 - val_loss: 5045833.9895\n",
      "Epoch 4599/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3488266.7938 - val_loss: 5012653.8714\n",
      "Epoch 4600/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3483926.2510 - val_loss: 5011531.4285\n",
      "Epoch 4601/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484035.0182 - val_loss: 5026635.3557\n",
      "Epoch 4602/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486144.9781 - val_loss: 5031197.9425\n",
      "Epoch 4603/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3485144.8049 - val_loss: 5067510.0799\n",
      "Epoch 4604/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484976.1344 - val_loss: 5020116.9316\n",
      "Epoch 4605/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485161.3773 - val_loss: 5006221.9354\n",
      "Epoch 4606/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486394.1888 - val_loss: 5013488.9271\n",
      "Epoch 4607/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3485370.1736 - val_loss: 5039030.0692\n",
      "Epoch 4608/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484988.0057 - val_loss: 5042750.9244\n",
      "Epoch 4609/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486532.2482 - val_loss: 5066924.5106\n",
      "Epoch 4610/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481754.7817 - val_loss: 5027389.0628\n",
      "Epoch 4611/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487247.7658 - val_loss: 5037596.0044\n",
      "Epoch 4612/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3482131.2865 - val_loss: 5048189.7307\n",
      "Epoch 4613/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485362.5017 - val_loss: 4995527.7379\n",
      "Epoch 4614/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487160.9888 - val_loss: 5024422.7486\n",
      "Epoch 4615/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484861.1905 - val_loss: 5082653.0516\n",
      "Epoch 4616/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486570.4570 - val_loss: 5040299.5238\n",
      "Epoch 4617/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481161.9320 - val_loss: 5021133.1644\n",
      "Epoch 4618/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487565.8692 - val_loss: 5020425.7578\n",
      "Epoch 4619/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482804.3007 - val_loss: 5027697.0655\n",
      "Epoch 4620/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482963.7653 - val_loss: 5029545.1137\n",
      "Epoch 4621/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3481571.1215 - val_loss: 5030420.3134\n",
      "Epoch 4622/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481903.1612 - val_loss: 5024709.5480\n",
      "Epoch 4623/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3485860.6912 - val_loss: 5019731.7190\n",
      "Epoch 4624/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482790.9975 - val_loss: 5029948.1951\n",
      "Epoch 4625/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3485016.1782 - val_loss: 5047076.0979\n",
      "Epoch 4626/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481920.2820 - val_loss: 5049309.3095\n",
      "Epoch 4627/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3485948.3016 - val_loss: 5044179.9961\n",
      "Epoch 4628/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484476.9448 - val_loss: 5040227.8287\n",
      "Epoch 4629/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482432.7768 - val_loss: 5029643.2059\n",
      "Epoch 4630/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482712.0883 - val_loss: 5014639.0628\n",
      "Epoch 4631/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3482688.6066 - val_loss: 5055292.8199\n",
      "Epoch 4632/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483979.5971 - val_loss: 4994985.7676\n",
      "Epoch 4633/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486422.5794 - val_loss: 5024508.8427\n",
      "Epoch 4634/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482821.8045 - val_loss: 4998935.9143\n",
      "Epoch 4635/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3478389.4105 - val_loss: 5048260.0893\n",
      "Epoch 4636/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479795.0683 - val_loss: 5024056.8961\n",
      "Epoch 4637/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3490086.9159 - val_loss: 5021687.7158\n",
      "Epoch 4638/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482067.8143 - val_loss: 5055894.3198\n",
      "Epoch 4639/5000\n",
      "40850/40850 [==============================] - 1s 14us/sample - loss: 3485972.9743 - val_loss: 5019099.0913\n",
      "Epoch 4640/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483412.1704 - val_loss: 5033223.6601\n",
      "Epoch 4641/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483820.6648 - val_loss: 5003378.4378\n",
      "Epoch 4642/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480844.8906 - val_loss: 5017976.5734\n",
      "Epoch 4643/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3483121.5911 - val_loss: 5027230.0294\n",
      "Epoch 4644/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483532.0594 - val_loss: 5024614.5005\n",
      "Epoch 4645/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487211.1088 - val_loss: 5012939.1605\n",
      "Epoch 4646/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484470.6258 - val_loss: 5026279.5034\n",
      "Epoch 4647/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481761.2715 - val_loss: 5047502.2686\n",
      "Epoch 4648/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483714.4344 - val_loss: 5045679.9557\n",
      "Epoch 4649/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486588.2869 - val_loss: 5053616.6866\n",
      "Epoch 4650/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482182.4547 - val_loss: 5032958.9520\n",
      "Epoch 4651/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482085.9867 - val_loss: 5064675.2024\n",
      "Epoch 4652/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480995.1375 - val_loss: 5035451.9373\n",
      "Epoch 4653/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481831.5326 - val_loss: 5010950.8748\n",
      "Epoch 4654/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3488005.8682 - val_loss: 5038761.0306\n",
      "Epoch 4655/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482779.2398 - val_loss: 5046937.6649\n",
      "Epoch 4656/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480405.3232 - val_loss: 5033206.7683\n",
      "Epoch 4657/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481776.9068 - val_loss: 5031710.6656\n",
      "Epoch 4658/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481780.1390 - val_loss: 5036646.1216\n",
      "Epoch 4659/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486161.8378 - val_loss: 5030076.5141\n",
      "Epoch 4660/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3488818.1626 - val_loss: 5036699.4237\n",
      "Epoch 4661/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481233.5071 - val_loss: 5046541.4730\n",
      "Epoch 4662/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484213.8888 - val_loss: 5052375.5959\n",
      "Epoch 4663/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481837.9562 - val_loss: 5024845.7309\n",
      "Epoch 4664/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486752.3368 - val_loss: 5018101.1211\n",
      "Epoch 4665/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483309.8399 - val_loss: 5029036.1621\n",
      "Epoch 4666/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483016.2891 - val_loss: 5019202.1129\n",
      "Epoch 4667/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3479904.4356 - val_loss: 5039027.3569\n",
      "Epoch 4668/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3481963.4927 - val_loss: 5033211.6506\n",
      "Epoch 4669/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3484603.4015 - val_loss: 5058081.6164\n",
      "Epoch 4670/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482079.0477 - val_loss: 5012820.2604\n",
      "Epoch 4671/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485286.2131 - val_loss: 5012618.5240\n",
      "Epoch 4672/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3484943.1645 - val_loss: 5017199.1481\n",
      "Epoch 4673/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3481841.9355 - val_loss: 5046146.5986\n",
      "Epoch 4674/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3480430.0349 - val_loss: 5048169.8812\n",
      "Epoch 4675/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483023.2441 - val_loss: 5008534.5408\n",
      "Epoch 4676/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3485626.9871 - val_loss: 5023599.9028\n",
      "Epoch 4677/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3482223.2418 - val_loss: 5037878.0910\n",
      "Epoch 4678/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485988.9203 - val_loss: 5029360.2529\n",
      "Epoch 4679/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484082.2169 - val_loss: 5031788.3004\n",
      "Epoch 4680/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482899.2115 - val_loss: 5032180.0532\n",
      "Epoch 4681/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484983.5849 - val_loss: 5021283.6607\n",
      "Epoch 4682/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482406.8982 - val_loss: 5018724.0051\n",
      "Epoch 4683/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482807.3361 - val_loss: 5056378.5907\n",
      "Epoch 4684/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3482847.6278 - val_loss: 5053782.3116\n",
      "Epoch 4685/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482146.9438 - val_loss: 5028872.9691\n",
      "Epoch 4686/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480740.5209 - val_loss: 5023876.3139\n",
      "Epoch 4687/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484504.6957 - val_loss: 5043282.0476\n",
      "Epoch 4688/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483026.5206 - val_loss: 5033657.9574\n",
      "Epoch 4689/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482545.6096 - val_loss: 5027647.9055\n",
      "Epoch 4690/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482154.9607 - val_loss: 5034374.2418\n",
      "Epoch 4691/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481696.5309 - val_loss: 5004838.7751\n",
      "Epoch 4692/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481021.8384 - val_loss: 5021090.4907\n",
      "Epoch 4693/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3484189.0823 - val_loss: 5032623.0083\n",
      "Epoch 4694/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3483086.1138 - val_loss: 5021729.3776\n",
      "Epoch 4695/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3480339.5948 - val_loss: 5016683.1812\n",
      "Epoch 4696/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3479818.0744 - val_loss: 5029652.9480\n",
      "Epoch 4697/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3482980.9014 - val_loss: 5064946.0214\n",
      "Epoch 4698/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484565.7384 - val_loss: 5047465.1082\n",
      "Epoch 4699/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481069.0453 - val_loss: 5045371.7539\n",
      "Epoch 4700/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480281.0538 - val_loss: 5028122.5430\n",
      "Epoch 4701/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482981.7665 - val_loss: 5049730.5925\n",
      "Epoch 4702/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482279.3994 - val_loss: 5028350.1933\n",
      "Epoch 4703/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481844.9504 - val_loss: 5038914.6321\n",
      "Epoch 4704/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3482333.0838 - val_loss: 5046664.3596\n",
      "Epoch 4705/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480790.7974 - val_loss: 5053079.0744\n",
      "Epoch 4706/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482582.0754 - val_loss: 5033137.0098\n",
      "Epoch 4707/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3486632.7251 - val_loss: 5039895.3672\n",
      "Epoch 4708/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483474.9413 - val_loss: 5047217.7683\n",
      "Epoch 4709/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484907.3920 - val_loss: 5028417.3061\n",
      "Epoch 4710/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481044.9771 - val_loss: 5078801.8440\n",
      "Epoch 4711/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480297.2184 - val_loss: 5051120.4932\n",
      "Epoch 4712/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479863.2222 - val_loss: 5048515.8499\n",
      "Epoch 4713/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482544.2826 - val_loss: 5026953.3296\n",
      "Epoch 4714/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482622.4812 - val_loss: 5029635.8856\n",
      "Epoch 4715/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484980.9683 - val_loss: 5016916.5314\n",
      "Epoch 4716/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482514.5988 - val_loss: 5031360.5647\n",
      "Epoch 4717/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3487573.8948 - val_loss: 5025427.1698\n",
      "Epoch 4718/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481249.8714 - val_loss: 5032472.9082\n",
      "Epoch 4719/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484287.6140 - val_loss: 5021375.3261\n",
      "Epoch 4720/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481678.8784 - val_loss: 5038492.4766\n",
      "Epoch 4721/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480862.1834 - val_loss: 5028737.1473\n",
      "Epoch 4722/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479919.3819 - val_loss: 5011766.9168\n",
      "Epoch 4723/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478780.9108 - val_loss: 5044476.3170\n",
      "Epoch 4724/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483275.1359 - val_loss: 5030432.7494\n",
      "Epoch 4725/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483317.4870 - val_loss: 5028637.0011\n",
      "Epoch 4726/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3488773.1442 - val_loss: 5034047.1781\n",
      "Epoch 4727/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3485452.5552 - val_loss: 5039468.2211\n",
      "Epoch 4728/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478764.8599 - val_loss: 5028538.1743\n",
      "Epoch 4729/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484744.0902 - val_loss: 5041312.7997\n",
      "Epoch 4730/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483011.8381 - val_loss: 5027989.1203\n",
      "Epoch 4731/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484468.3746 - val_loss: 5057540.9779\n",
      "Epoch 4732/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479890.7202 - val_loss: 5029542.1449\n",
      "Epoch 4733/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481284.3075 - val_loss: 5069491.4810\n",
      "Epoch 4734/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480125.2837 - val_loss: 5013952.3285\n",
      "Epoch 4735/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481754.0476 - val_loss: 5032697.7120\n",
      "Epoch 4736/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481805.1008 - val_loss: 5021186.7199\n",
      "Epoch 4737/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482622.3626 - val_loss: 5033705.6366\n",
      "Epoch 4738/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3484021.0299 - val_loss: 5035246.6306\n",
      "Epoch 4739/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483705.0584 - val_loss: 5059584.2344\n",
      "Epoch 4740/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482226.2115 - val_loss: 5038184.4506\n",
      "Epoch 4741/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482794.6382 - val_loss: 5019353.1710\n",
      "Epoch 4742/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479506.3903 - val_loss: 5029475.7783\n",
      "Epoch 4743/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3478652.9593 - val_loss: 5026034.2516\n",
      "Epoch 4744/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480075.0867 - val_loss: 5050974.2228\n",
      "Epoch 4745/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479060.6615 - val_loss: 5032756.3766\n",
      "Epoch 4746/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480851.4887 - val_loss: 5018446.4934\n",
      "Epoch 4747/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481973.3567 - val_loss: 5012535.6921\n",
      "Epoch 4748/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480101.1306 - val_loss: 5027813.3529\n",
      "Epoch 4749/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484065.4474 - val_loss: 5022310.6985\n",
      "Epoch 4750/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483899.0046 - val_loss: 5023964.1939\n",
      "Epoch 4751/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480552.4257 - val_loss: 5023779.5665\n",
      "Epoch 4752/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482778.3240 - val_loss: 5038533.9469\n",
      "Epoch 4753/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483136.0655 - val_loss: 5024160.0623\n",
      "Epoch 4754/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484631.1132 - val_loss: 5034553.9327\n",
      "Epoch 4755/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480003.7709 - val_loss: 5032785.9653\n",
      "Epoch 4756/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480235.1036 - val_loss: 5030369.4094\n",
      "Epoch 4757/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483131.3564 - val_loss: 5009497.6278\n",
      "Epoch 4758/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483533.4549 - val_loss: 5021770.3726\n",
      "Epoch 4759/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481315.9136 - val_loss: 5047649.7831\n",
      "Epoch 4760/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3481791.6826 - val_loss: 5050421.2945\n",
      "Epoch 4761/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3481873.7063 - val_loss: 5031862.6218\n",
      "Epoch 4762/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483271.3780 - val_loss: 5034561.8664\n",
      "Epoch 4763/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483501.6260 - val_loss: 5041328.2884\n",
      "Epoch 4764/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482030.2269 - val_loss: 5044062.8730\n",
      "Epoch 4765/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486330.3203 - val_loss: 5020109.3323\n",
      "Epoch 4766/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3481678.1051 - val_loss: 5036472.6512\n",
      "Epoch 4767/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483484.3316 - val_loss: 5039655.2835\n",
      "Epoch 4768/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482153.0268 - val_loss: 5040174.7542\n",
      "Epoch 4769/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3476156.6657 - val_loss: 5036218.0228\n",
      "Epoch 4770/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3486369.6923 - val_loss: 5031114.7410\n",
      "Epoch 4771/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3485786.5363 - val_loss: 5038129.6103\n",
      "Epoch 4772/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482015.9482 - val_loss: 5051937.1661\n",
      "Epoch 4773/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3484845.0619 - val_loss: 5040581.4075\n",
      "Epoch 4774/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481842.5468 - val_loss: 5024220.5090\n",
      "Epoch 4775/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478879.4218 - val_loss: 5017468.3151\n",
      "Epoch 4776/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479217.8600 - val_loss: 5049715.3619\n",
      "Epoch 4777/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479924.2915 - val_loss: 5045667.2231\n",
      "Epoch 4778/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3487790.5981 - val_loss: 5005514.2720\n",
      "Epoch 4779/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3484529.3320 - val_loss: 5031028.3349\n",
      "Epoch 4780/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3481613.3687 - val_loss: 5018382.6331\n",
      "Epoch 4781/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481071.4149 - val_loss: 5009437.3623\n",
      "Epoch 4782/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479672.6908 - val_loss: 5023718.5011\n",
      "Epoch 4783/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479152.9974 - val_loss: 5034796.9788\n",
      "Epoch 4784/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3476726.1576 - val_loss: 5010407.7380\n",
      "Epoch 4785/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482985.4477 - val_loss: 5016556.0417\n",
      "Epoch 4786/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480549.5817 - val_loss: 5049184.4151\n",
      "Epoch 4787/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481371.3371 - val_loss: 5023440.4121\n",
      "Epoch 4788/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481465.7312 - val_loss: 5013678.6119\n",
      "Epoch 4789/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478426.3603 - val_loss: 5053368.6109\n",
      "Epoch 4790/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479378.0318 - val_loss: 5027117.1114\n",
      "Epoch 4791/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480664.8048 - val_loss: 5023379.9682\n",
      "Epoch 4792/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3478509.1809 - val_loss: 5023187.5981\n",
      "Epoch 4793/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480091.6931 - val_loss: 5026192.5734\n",
      "Epoch 4794/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480304.6087 - val_loss: 5008327.0882\n",
      "Epoch 4795/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479168.5026 - val_loss: 5033902.3614\n",
      "Epoch 4796/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481000.7454 - val_loss: 5017553.4814\n",
      "Epoch 4797/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479952.4713 - val_loss: 5024024.5222\n",
      "Epoch 4798/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479247.9553 - val_loss: 5030348.4237\n",
      "Epoch 4799/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481621.9437 - val_loss: 5042082.8737\n",
      "Epoch 4800/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481471.6751 - val_loss: 5042377.5755\n",
      "Epoch 4801/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480146.1868 - val_loss: 5044061.8444\n",
      "Epoch 4802/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479130.4921 - val_loss: 5069175.3620\n",
      "Epoch 4803/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479732.5501 - val_loss: 5009953.1727\n",
      "Epoch 4804/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483412.5334 - val_loss: 5029646.9538\n",
      "Epoch 4805/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480311.6003 - val_loss: 5040177.3319\n",
      "Epoch 4806/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481122.1442 - val_loss: 5030232.0128\n",
      "Epoch 4807/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483335.4097 - val_loss: 5025141.6613\n",
      "Epoch 4808/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482534.0091 - val_loss: 5040519.7018\n",
      "Epoch 4809/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481425.9057 - val_loss: 5014322.0271\n",
      "Epoch 4810/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482291.0842 - val_loss: 5027816.5580\n",
      "Epoch 4811/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479022.7461 - val_loss: 5034398.4628\n",
      "Epoch 4812/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3478969.4896 - val_loss: 5039393.3616\n",
      "Epoch 4813/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483897.4529 - val_loss: 5013442.1208\n",
      "Epoch 4814/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480687.5222 - val_loss: 5010304.7460\n",
      "Epoch 4815/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481250.4449 - val_loss: 5023128.9508\n",
      "Epoch 4816/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479143.1818 - val_loss: 5061594.5557\n",
      "Epoch 4817/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479381.9312 - val_loss: 5015951.4294\n",
      "Epoch 4818/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3477957.4446 - val_loss: 5050153.3950\n",
      "Epoch 4819/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480118.4327 - val_loss: 5019123.8509\n",
      "Epoch 4820/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479056.9798 - val_loss: 5027202.5929\n",
      "Epoch 4821/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3476364.4997 - val_loss: 5026477.0398\n",
      "Epoch 4822/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480339.8567 - val_loss: 5026376.1234\n",
      "Epoch 4823/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483495.1057 - val_loss: 5025783.9136\n",
      "Epoch 4824/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480574.4124 - val_loss: 5053604.8169\n",
      "Epoch 4825/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482572.4808 - val_loss: 5034603.4219\n",
      "Epoch 4826/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480639.8055 - val_loss: 5072909.6449\n",
      "Epoch 4827/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483219.6229 - val_loss: 5030709.9130\n",
      "Epoch 4828/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479919.9089 - val_loss: 5024946.7700\n",
      "Epoch 4829/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479522.4194 - val_loss: 5030864.6844\n",
      "Epoch 4830/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483749.4292 - val_loss: 5030025.8408\n",
      "Epoch 4831/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481170.4268 - val_loss: 5030636.5997\n",
      "Epoch 4832/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479694.2471 - val_loss: 5018700.0550\n",
      "Epoch 4833/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3476730.8850 - val_loss: 5038600.6807\n",
      "Epoch 4834/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479249.1737 - val_loss: 5014049.7737\n",
      "Epoch 4835/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479989.2771 - val_loss: 5058561.2002\n",
      "Epoch 4836/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480135.4062 - val_loss: 5034516.5032\n",
      "Epoch 4837/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3476355.4661 - val_loss: 5011205.3372\n",
      "Epoch 4838/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3475007.5430 - val_loss: 5033544.2147\n",
      "Epoch 4839/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3483833.1282 - val_loss: 5032817.9785\n",
      "Epoch 4840/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481255.0504 - val_loss: 5030832.3047\n",
      "Epoch 4841/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3477360.0467 - val_loss: 5018376.2998\n",
      "Epoch 4842/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481430.1064 - val_loss: 5039974.1181\n",
      "Epoch 4843/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481506.4758 - val_loss: 5011351.2051\n",
      "Epoch 4844/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481418.6508 - val_loss: 5027322.8476\n",
      "Epoch 4845/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479102.7510 - val_loss: 5021824.2375\n",
      "Epoch 4846/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3481127.6987 - val_loss: 5005221.0917\n",
      "Epoch 4847/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3479939.1320 - val_loss: 5019888.1793\n",
      "Epoch 4848/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478567.3256 - val_loss: 5023520.4453\n",
      "Epoch 4849/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480626.0414 - val_loss: 5027019.2322\n",
      "Epoch 4850/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479639.0936 - val_loss: 5016467.0585\n",
      "Epoch 4851/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478655.7724 - val_loss: 5066892.2286\n",
      "Epoch 4852/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478163.1304 - val_loss: 5012732.1842\n",
      "Epoch 4853/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480763.4105 - val_loss: 5023362.8120\n",
      "Epoch 4854/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3482322.2914 - val_loss: 5033607.8517\n",
      "Epoch 4855/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3480159.2423 - val_loss: 5031688.4138\n",
      "Epoch 4856/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480366.6265 - val_loss: 5012235.1067\n",
      "Epoch 4857/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3476893.5476 - val_loss: 5003399.8931\n",
      "Epoch 4858/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3477810.5475 - val_loss: 5036658.0973\n",
      "Epoch 4859/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3479844.4608 - val_loss: 5062614.1237\n",
      "Epoch 4860/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3478943.6162 - val_loss: 5001307.7817\n",
      "Epoch 4861/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3483844.2202 - val_loss: 5033805.6188\n",
      "Epoch 4862/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3477620.5219 - val_loss: 5042483.0175\n",
      "Epoch 4863/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3483271.6745 - val_loss: 5057435.6164\n",
      "Epoch 4864/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3480903.3052 - val_loss: 5021580.7647\n",
      "Epoch 4865/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3480224.8422 - val_loss: 5024738.5055\n",
      "Epoch 4866/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3476598.4666 - val_loss: 5032768.2825\n",
      "Epoch 4867/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3477891.9243 - val_loss: 5024343.6480\n",
      "Epoch 4868/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3482402.2938 - val_loss: 5014132.7263\n",
      "Epoch 4869/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482188.8365 - val_loss: 5019893.6666\n",
      "Epoch 4870/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3477680.4098 - val_loss: 5045013.0788\n",
      "Epoch 4871/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481809.6918 - val_loss: 5024250.4610\n",
      "Epoch 4872/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482601.1915 - val_loss: 5060560.7572\n",
      "Epoch 4873/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3484659.0234 - val_loss: 5040467.0427\n",
      "Epoch 4874/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3477617.1231 - val_loss: 5019074.2989\n",
      "Epoch 4875/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3480158.7645 - val_loss: 5017982.6517\n",
      "Epoch 4876/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481061.2669 - val_loss: 5031753.7684\n",
      "Epoch 4877/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481439.6639 - val_loss: 5026074.9166\n",
      "Epoch 4878/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479716.1874 - val_loss: 5038737.3731\n",
      "Epoch 4879/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478830.4316 - val_loss: 5027595.3172\n",
      "Epoch 4880/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478912.3905 - val_loss: 5020545.1829\n",
      "Epoch 4881/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3479317.5567 - val_loss: 5023480.1832\n",
      "Epoch 4882/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480759.1420 - val_loss: 5065621.4442\n",
      "Epoch 4883/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481355.9740 - val_loss: 5034856.8197\n",
      "Epoch 4884/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482211.4307 - val_loss: 5037327.7837\n",
      "Epoch 4885/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478682.0501 - val_loss: 5013742.3470\n",
      "Epoch 4886/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3475706.2478 - val_loss: 5036118.3631\n",
      "Epoch 4887/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479879.0924 - val_loss: 5014404.1100\n",
      "Epoch 4888/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481907.5246 - val_loss: 5010863.8397\n",
      "Epoch 4889/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479477.0105 - val_loss: 5016254.3906\n",
      "Epoch 4890/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478819.5542 - val_loss: 5018664.4240\n",
      "Epoch 4891/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481358.4155 - val_loss: 5021392.2259\n",
      "Epoch 4892/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3477964.4682 - val_loss: 5022009.2208\n",
      "Epoch 4893/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480546.3606 - val_loss: 5028144.5007\n",
      "Epoch 4894/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479415.5831 - val_loss: 5035258.3418\n",
      "Epoch 4895/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3476388.3272 - val_loss: 5033124.7458\n",
      "Epoch 4896/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480272.3054 - val_loss: 5014646.5674\n",
      "Epoch 4897/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3478514.8840 - val_loss: 5001670.6534\n",
      "Epoch 4898/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3478821.3723 - val_loss: 5036399.6671\n",
      "Epoch 4899/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479935.2130 - val_loss: 5017465.0076\n",
      "Epoch 4900/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3482136.8267 - val_loss: 5041762.1217\n",
      "Epoch 4901/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3477846.9894 - val_loss: 5040017.5265\n",
      "Epoch 4902/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3476830.4344 - val_loss: 5038385.8943\n",
      "Epoch 4903/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3477904.2369 - val_loss: 5028246.3021\n",
      "Epoch 4904/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3478069.1230 - val_loss: 5027091.0317\n",
      "Epoch 4905/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3477776.0500 - val_loss: 5019600.5484\n",
      "Epoch 4906/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3477705.4178 - val_loss: 5015379.8542\n",
      "Epoch 4907/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3477056.9362 - val_loss: 5013774.3053\n",
      "Epoch 4908/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482234.5797 - val_loss: 5016208.7438\n",
      "Epoch 4909/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480025.3862 - val_loss: 5021388.0744\n",
      "Epoch 4910/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3477399.1662 - val_loss: 5028720.2018\n",
      "Epoch 4911/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3477886.0307 - val_loss: 5037244.2572\n",
      "Epoch 4912/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478580.8117 - val_loss: 5030491.3900\n",
      "Epoch 4913/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478930.1759 - val_loss: 5029019.3887\n",
      "Epoch 4914/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3477995.6048 - val_loss: 5021995.4200\n",
      "Epoch 4915/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3475785.3959 - val_loss: 5021003.4416\n",
      "Epoch 4916/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481929.0504 - val_loss: 5014679.5702\n",
      "Epoch 4917/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3477073.5450 - val_loss: 5043995.8680\n",
      "Epoch 4918/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3477563.9962 - val_loss: 5038813.2348\n",
      "Epoch 4919/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479048.9838 - val_loss: 5017569.4739\n",
      "Epoch 4920/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3477515.1659 - val_loss: 5011028.7723\n",
      "Epoch 4921/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3477513.7821 - val_loss: 5024437.5904\n",
      "Epoch 4922/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482555.8038 - val_loss: 5025165.6212\n",
      "Epoch 4923/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479215.8908 - val_loss: 5017978.8577\n",
      "Epoch 4924/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3477523.2879 - val_loss: 5029849.0443\n",
      "Epoch 4925/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3482317.7179 - val_loss: 5014873.8523\n",
      "Epoch 4926/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3482186.2412 - val_loss: 5040178.5740\n",
      "Epoch 4927/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3477490.7469 - val_loss: 5034592.9699\n",
      "Epoch 4928/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3479429.0412 - val_loss: 5037244.5426\n",
      "Epoch 4929/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3479373.4170 - val_loss: 5037964.9903\n",
      "Epoch 4930/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3477332.1160 - val_loss: 5024895.7376\n",
      "Epoch 4931/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3476757.8745 - val_loss: 5037149.0989\n",
      "Epoch 4932/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479748.6807 - val_loss: 5026364.3936\n",
      "Epoch 4933/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478736.0006 - val_loss: 5052594.2975\n",
      "Epoch 4934/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3477935.5394 - val_loss: 5034450.7285\n",
      "Epoch 4935/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481637.7909 - val_loss: 5030934.7920\n",
      "Epoch 4936/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3478745.2388 - val_loss: 5037528.6070\n",
      "Epoch 4937/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3475221.5997 - val_loss: 5028371.7244\n",
      "Epoch 4938/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478808.0417 - val_loss: 5033713.9327\n",
      "Epoch 4939/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3480844.6087 - val_loss: 5033288.9446\n",
      "Epoch 4940/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3475759.7458 - val_loss: 5049532.3409\n",
      "Epoch 4941/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3475943.3888 - val_loss: 5041463.7487\n",
      "Epoch 4942/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3476903.1987 - val_loss: 5038143.2358\n",
      "Epoch 4943/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3476724.9410 - val_loss: 5044188.7352\n",
      "Epoch 4944/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3481696.1887 - val_loss: 5022810.1961\n",
      "Epoch 4945/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3477790.2600 - val_loss: 5049093.9477\n",
      "Epoch 4946/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479575.5087 - val_loss: 5013035.7852\n",
      "Epoch 4947/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3476014.8667 - val_loss: 5030787.5839\n",
      "Epoch 4948/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478287.7349 - val_loss: 5017594.1362\n",
      "Epoch 4949/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479120.0015 - val_loss: 5046259.1570\n",
      "Epoch 4950/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3480379.1612 - val_loss: 5057320.4767\n",
      "Epoch 4951/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3475039.2111 - val_loss: 5016241.2778\n",
      "Epoch 4952/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3475303.6214 - val_loss: 5039616.4809\n",
      "Epoch 4953/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478295.5647 - val_loss: 5023615.3643\n",
      "Epoch 4954/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479239.9788 - val_loss: 5012876.4428\n",
      "Epoch 4955/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3476455.7031 - val_loss: 5017588.8641\n",
      "Epoch 4956/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479302.0801 - val_loss: 5029812.4547\n",
      "Epoch 4957/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478971.8114 - val_loss: 5056903.9580\n",
      "Epoch 4958/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3476331.0522 - val_loss: 5031468.4907\n",
      "Epoch 4959/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3479065.4269 - val_loss: 5039274.3983\n",
      "Epoch 4960/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481018.1888 - val_loss: 5050520.3691\n",
      "Epoch 4961/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3474612.2421 - val_loss: 5030711.6114\n",
      "Epoch 4962/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3476878.4537 - val_loss: 5036402.2495\n",
      "Epoch 4963/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3481948.6723 - val_loss: 5048753.2903\n",
      "Epoch 4964/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3478542.2404 - val_loss: 5041052.8165\n",
      "Epoch 4965/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3475148.4249 - val_loss: 5040165.3441\n",
      "Epoch 4966/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478447.1904 - val_loss: 5038802.0602\n",
      "Epoch 4967/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3477445.7267 - val_loss: 5051424.5420\n",
      "Epoch 4968/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3480708.3948 - val_loss: 5010381.4363\n",
      "Epoch 4969/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3477416.5667 - val_loss: 5019568.2533\n",
      "Epoch 4970/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3478338.6869 - val_loss: 5042460.4288\n",
      "Epoch 4971/5000\n",
      "40850/40850 [==============================] - 1s 15us/sample - loss: 3478906.0046 - val_loss: 5027080.8427\n",
      "Epoch 4972/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3477554.8519 - val_loss: 5041061.6575\n",
      "Epoch 4973/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3478272.5338 - val_loss: 5059581.9255\n",
      "Epoch 4974/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3476758.8970 - val_loss: 5047377.9337\n",
      "Epoch 4975/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3476993.1658 - val_loss: 5042625.8673\n",
      "Epoch 4976/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3476798.2951 - val_loss: 5042564.2212\n",
      "Epoch 4977/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3479984.5852 - val_loss: 5041734.9996\n",
      "Epoch 4978/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3475980.5889 - val_loss: 5062684.4672\n",
      "Epoch 4979/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3477046.6921 - val_loss: 5019423.7751\n",
      "Epoch 4980/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3478703.7614 - val_loss: 5040479.2558\n",
      "Epoch 4981/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3475563.3112 - val_loss: 5043106.4743\n",
      "Epoch 4982/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3478397.7637 - val_loss: 5043817.0580\n",
      "Epoch 4983/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3474734.1466 - val_loss: 5023515.2158\n",
      "Epoch 4984/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3479175.2010 - val_loss: 5009347.6680\n",
      "Epoch 4985/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3473627.4113 - val_loss: 5031739.7961\n",
      "Epoch 4986/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3477764.2007 - val_loss: 5045334.8801\n",
      "Epoch 4987/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3474315.2539 - val_loss: 4998949.6493\n",
      "Epoch 4988/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479170.5635 - val_loss: 5021118.1784\n",
      "Epoch 4989/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3476057.2809 - val_loss: 5036119.5100\n",
      "Epoch 4990/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3474669.4533 - val_loss: 5059716.7616\n",
      "Epoch 4991/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3479940.0042 - val_loss: 5032341.3255\n",
      "Epoch 4992/5000\n",
      "40850/40850 [==============================] - 1s 16us/sample - loss: 3479033.7035 - val_loss: 5045437.6646\n",
      "Epoch 4993/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3475915.6933 - val_loss: 5038285.7433\n",
      "Epoch 4994/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3476645.6605 - val_loss: 5040331.6869\n",
      "Epoch 4995/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3476764.1878 - val_loss: 5037162.9999\n",
      "Epoch 4996/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3474410.3757 - val_loss: 5056775.1686\n",
      "Epoch 4997/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3479664.9302 - val_loss: 5067463.5339\n",
      "Epoch 4998/5000\n",
      "40850/40850 [==============================] - 1s 18us/sample - loss: 3477263.8254 - val_loss: 5053437.4825\n",
      "Epoch 4999/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3478071.7233 - val_loss: 5054599.4827\n",
      "Epoch 5000/5000\n",
      "40850/40850 [==============================] - 1s 17us/sample - loss: 3476494.2753 - val_loss: 5032512.9222\n",
      "\n",
      " 54.0 min.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model.fit(x=X_train,y=y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          batch_size=256,epochs=5000,\n",
    "#           callbacks=[early_stop],\n",
    "         )\n",
    "\n",
    "stop = time.time()\n",
    "print('\\n',(stop-start)//60,'min.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 10000000.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj8ElEQVR4nO3deZxU1Z338c+vlt7obugGmq2RRRFEWhAaNTHiEseFJDIajbhGx9HHSXSi88RRxycZE5OZTOIkM/MEQ3hmiDoxUeMyIXGbGEVw4gIoi6yyarH1AjRNQ29V5/njVkNT3XQXTTXd9/J9v14tVfeeW/U7LXzr1Klzb5lzDhER8b9QTxcgIiKZoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGA6NFAN7O5ZlZhZh+l0fYnZrY0+bPOzPYchxJFRHzDenIduplNA/YBTzrnJhzFcXcDZzrn/qLbihMR8ZkeHaE75xYAu1pvM7OTzexVM1tiZgvNbFw7h14H/Pq4FCki4hORni6gHXOAO51zH5vZ2cBjwEUtO81sBDAKeKOH6hMR6ZV6VaCbWT7wWeA3ZtayOTul2UzgOedc/HjWJiLS2/WqQMebAtrjnJvUQZuZwNePTzkiIv7Rq5YtOuf2ApvM7BoA80xs2W9mY4Ei4J0eKlFEpNfqNNA7W1qYDN1/M7P1ZrbczCan++Rm9mu8cB5rZjEzuw24AbjNzJYBK4EZrQ65Dnja6RKRIiJtdLpssbOlhWY2HbgbmA6cDfyrc+7sbqhVREQ60OkIvb2lhSlm4IW9c869C/QzsyGZKlBERNKTiQ9FhwGftrofS27bntrQzO4A7gDo06fPlHHj2lti3rmmbStoiuSTVzKqS8eLiPjVkiVLqpxzA9vbl4lAt3a2tTuP45ybg7fOnPLycrd48eIuPeGOh0cTKzqb8m/o3CIRObGY2ZYj7cvEKpcYMLzV/VJgWwYetwPtvYaIiJzYMhHo84Cbk6tdzgFqnHNtplsyyQFGojufQkTEdzqdckkuLbwAGGBmMeDvgSiAc2428DLeCpf1wH7g1u4qtoXDjjCpIyJy4uo00J1z13Wy33Hcz9w0lOgi/tTU1EQsFqO+vr6nS+nVcnJyKC0tJRqNpn1Mbzv1Py3eCF2BLuJHsViMgoICRo4cSatrNkkrzjmqq6uJxWKMGpX+ar5edep/urw5dAW6iB/V19fTv39/hXkHzIz+/fsf9bsYXwa6plxE/E1h3rmu/I58GejO9KGoiEgqfwY6gJYtikgX5efn93QJ3cKXgQ6mU4tERFL4MtC1ykVEMsE5x3333ceECRMoKyvjmWeeAWD79u1MmzaNSZMmMWHCBBYuXEg8HueWW2452PYnP/lJD1fflk+XLWqVi0gQfOd3K1m1bW9GH3P80EL+/kunp9X2hRdeYOnSpSxbtoyqqiqmTp3KtGnT+NWvfsWll17KQw89RDweZ//+/SxdupStW7fy0UfeV0Ps2bMno3Vngi9H6FrlIiKZ8Pbbb3PdddcRDocZNGgQ559/PosWLWLq1Kn84he/4OGHH2bFihUUFBQwevRoNm7cyN13382rr75KYWFhT5ffhk9H6Ap0kSBIdyTdXY70BT/Tpk1jwYIFvPTSS9x0003cd9993HzzzSxbtozXXnuNWbNm8eyzzzJ37tzjXHHH/DtCV56LyDGaNm0azzzzDPF4nMrKShYsWMBZZ53Fli1bKCkp4fbbb+e2227jgw8+oKqqikQiwZe//GUeeeQRPvjgg54uvw1/jtDNNIcuIsfsyiuv5J133mHixImYGT/84Q8ZPHgwTzzxBD/60Y+IRqPk5+fz5JNPsnXrVm699VYSCW/J9D/+4z/2cPVtdfqdot3lWL7gYsN3z2Bf7nAm3vdShqsSke62evVqTjvttJ4uwxfa+12Z2RLnXHl77f075aIRuojIYXwZ6A5NuYiIpPJloHsU6CIirfky0HWmqIhIW74MdF3LRUSkLV8GujN9KCoiksqfgd7qvyIi4vFloINhmkMXkeOgo2unb968mQkTJhzHajrmy0B3mkEXEWnDl6f+68QikYB45QHYsSKzjzm4DC7/wRF333///YwYMYKvfe1rADz88MOYGQsWLGD37t00NTXxve99jxkzZhzV09bX1/NXf/VXLF68mEgkwo9//GMuvPBCVq5cya233kpjYyOJRILnn3+eoUOH8pWvfIVYLEY8Hudb3/oW11577TF1G3wa6A405SIiXTJz5kzuueeeg4H+7LPP8uqrr3LvvfdSWFhIVVUV55xzDldcccVRfVHzrFmzAFixYgVr1qzhkksuYd26dcyePZtvfOMb3HDDDTQ2NhKPx3n55ZcZOnQoL73kXb6kpqYmI33zZaCjVS4iwdDBSLq7nHnmmVRUVLBt2zYqKyspKipiyJAh3HvvvSxYsIBQKMTWrVvZuXMngwcPTvtx3377be6++24Axo0bx4gRI1i3bh2f+cxn+P73v08sFuOqq65izJgxlJWV8c1vfpP777+fL37xi5x33nkZ6Zsv59AThHTqv4h02dVXX81zzz3HM888w8yZM3nqqaeorKxkyZIlLF26lEGDBlFfX39Uj3mkCx1ef/31zJs3j9zcXC699FLeeOMNTj31VJYsWUJZWRkPPvgg3/3udzPRLZ+O0LXKRUSOwcyZM7n99tupqqrirbfe4tlnn6WkpIRoNMqbb77Jli1bjvoxp02bxlNPPcVFF13EunXr+OSTTxg7diwbN25k9OjR/PVf/zUbN25k+fLljBs3juLiYm688Uby8/N5/PHHM9IvnwY6aMpFRLrq9NNPp7a2lmHDhjFkyBBuuOEGvvSlL1FeXs6kSZMYN27cUT/m1772Ne68807KysqIRCI8/vjjZGdn88wzz/DLX/6SaDTK4MGD+fa3v82iRYu47777CIVCRKNRfvazn2WkX768HvpH3zuXcDjEaQ8uzHBVItLddD309J0Q10PXNxaJiLTl0ykXrXIRkeNnxYoV3HTTTYdty87O5r333uuhitrny0DXOnQRf3POHdUa755WVlbG0qVLj+tzdmU63JdTLhqhi/hXTk4O1dXVXQqsE4VzjurqanJyco7qOJ+O0DWHLuJXpaWlxGIxKisre7qUXi0nJ4fS0tKjOsaXga4zRUX8KxqNMmrUqJ4uI5DSmnIxs8vMbK2ZrTezB9rZ39fMfmdmy8xspZndmvlSU55TeS4icphOA93MwsAs4HJgPHCdmY1PafZ1YJVzbiJwAfDPZpaV4VoPcppDFxFpI50R+lnAeufcRudcI/A0kHpdSQcUmPexdT6wC2jOaKWH0Ry6iEiqdAJ9GPBpq/ux5LbWfgqcBmwDVgDfcM4lUh/IzO4ws8VmtvhYPhDRd4qKiLSVTqC3t1g0NU0vBZYCQ4FJwE/NrLDNQc7Ncc6VO+fKBw4ceJSlppakQBcRaS2dQI8Bw1vdL8Ubibd2K/CC86wHNgFHf3WbNHknFnXXo4uI+FM6gb4IGGNmo5IfdM4E5qW0+QT4PICZDQLGAhszWejhNIcuIpKq03XozrlmM7sLeA0IA3OdcyvN7M7k/tnAI8DjZrYCbz7kfudcVXcVrVUuIiJtpXVikXPuZeDllG2zW93eBlyS2dI6oKstioi04dNruYiISCpfBrqu5SIi0pYvAx0z0JXaREQO48tA1whdRKQtXwZ6++c6iYic2Hwb6Bqhi4gczp+BbqB16CIih/NloGsOXUSkLV8GOpgG6CIiKXwb6Bqhi4gczpeB7nTqv4hIG74MdI8CXUSkNV8GuiOklegiIin8GehmGG2+4U5E5ITmy0DXh6IiIm35NNDRFLqISAp/BrqFNEIXEUnhy0B3oEAXEUnhy0DHtMZFRCSVPwNdH4qKiLShQBcRCQh/BroZWuYiInI4nwZ6mJDTiUUiIq35MtATFiakM0VFRA7jy0B3FiZMvKfLEBHpVXwa6BHCGqGLiBzGl4GeCGmELiKSypeBrikXEZG2fBnohMJESIDT0kURkRa+DHRnkeQNzaOLiLTwaaCHvRuJ5p4tRESkF/FnoIcU6CIiqXwZ6ISSUy4JfTAqItLCl4F+cA5dI3QRkYPSCnQzu8zM1prZejN74AhtLjCzpWa20szeymyZKULJsjVCFxE5KNJZAzMLA7OAPwNiwCIzm+ecW9WqTT/gMeAy59wnZlbSTfUCGqGLiLQnnRH6WcB659xG51wj8DQwI6XN9cALzrlPAJxzFZktM0VyDt0lmrr1aURE/CSdQB8GfNrqfiy5rbVTgSIzm29mS8zs5vYeyMzuMLPFZra4srKyaxVzaNliIq4pFxGRFukEentf4Jl6imYEmAJ8AbgU+JaZndrmIOfmOOfKnXPlAwcOPOpiDz5OOAuARFN9lx9DRCRoOp1DxxuRD291vxTY1k6bKudcHVBnZguAicC6jFSZojmSB0CiYV93PLyIiC+lM0JfBIwxs1FmlgXMBOaltPktcJ6ZRcwsDzgbWJ3ZUg+JR/p4NxToIiIHdTpCd841m9ldwGtAGJjrnFtpZncm9892zq02s1eB5UAC+Hfn3EfdVXRztGWEXttdTyEi4jvpTLngnHsZeDll2+yU+z8CfpS50o6sZYTuGjVCFxFp4cszRQ9OudQr0EVEWvgy0Juj+d6NA7t7thARkV7El4Eezs6nyhXCnk96uhQRkV7Dl4GeHQkRcwOxPZt7uhQRkV7Dl4GeEw2zNjGcrIoVkNC3FomIgE8DPTsS4v3EOMKNNRB7v6fLERHpFXwZ6DnRMPMTE707cy+F5saeLUhEpBfwZaBnR0NU0/fQhu8NhO3LYV8luNTLzIiInBh8Geg5Ee9qi69fverQxp+fB4+eAt/pB7U7eqYwEZEe5MtAz8v2Ar22ycHDNTA55Wq9/zwWHu4Lm9/ugepERHqGLwO9fx/v8rnV+5Jz51f8Xy/Yr5xzeMPHv+AF+/O3H+cKRUSOP18GemFOlEjI2FWX8mHoxGu9YH9w6+HbVzzrBbuuny4iAebLQA+FjOI+WVTWNrTfIDvfC/aHa+CMmYe2f38QPP+Xx6dIEZHjzJeBDjBqQB8+rkjj4lxX/Rz+bvuh+yt+443WP3kX9u/qvgJFpHNrX4Ga2NEft+3D9L4Pwbn2V77Fm72TEhMJb3+81RfO18Rg1W/bHrN3G+xc1TY3Duzxatm7zVtC7VzHJzw21nVedxeldfnc3qhsWF/+890tNDYnyIp08rqUleeN1uv3wg+SX74099JD+//iNTjpnO4rVqQ71e8Fl4DFc+HMmyCSBTtWQDgLcvrBgDHQtN/7cvU5F8IZX4HP3XPo+EQC1r8Ow6dCbpF37IBTYeN8KBkPtdth0wIYNgUW/jOUXQMLHoX6Pd7nV2/9E1S0WnF2yp9BaTms/yMUDoFV86D/ybBro1dni5Lxh4674qcwahose9q7v/IFqFzTtq/nfB3endXx7+P8B+CtHxz97/F4+vPZMOm6jD+suR5at11eXu4WL17c5ePfXFvBrb9YxKzrJ/OFM4Yc3cGb/wcen374tpHnwS2/73I9IhnV3ACYF8J7NntBOuJcb2T6/pzOjpbe7pSL4cbnu3SomS1xzpW3u8+vgR5POM7/0ZvkZYWZd9fnyImGj+4BnIP//j/wzk8P337NE3DaFRDy7WyUHC+1O6Fg0KH7LZdzzi2CumpwcXh0DJx8EZx+JezbCVkF8N5sGHqmNwptz6Ay2Lmi++uXoxPOgvgxnJUezfPeKRWPhq+/D+Folx4mkIEO8IdVO7n9ycV8flwJP752En1zu/YL4rWH2gZ7i3tXQt/Srhcp/hNbDP1GQNVaqFgNiWZY/iwMOcOb/9y7Hbb04nMcon2gqZ152qJR3otMKAq7Nhz5+GHlMPU279/FkIkwuMx7Z1B+KxQMhewCKBrp/V4q18C+Cu9FbPjZsG+HN8+c0xf6DIBQGPompzmb671j403eO5DsfKivSQZlE+zZ4k25nHsPbF8GB3ZB4TDYsRwmfBk2L4Tik73pm+wCb647f5AXshvnw6fvQflt0GcgRHO950w0e8HZknNm3hnl+QMz+As/vgIb6ACP/88mHv7dKgqyI9xwzgjuvugU+mR34aOBeBO8+iAs+n/t77/1FRjx2WMrVg7Xcg2eSNahbQ37vH/4fQZ0fGz1Bu/DqeFTvfs1MS9YikZ65x801sFX58GWd+Cj57xgiObBez/rlq50q9wimPEYDJ0EmxbCaV+ErD49XZX0kEAHOsB/fbiVb/32I2rrm+mXF+Wh6adxTfnwY3vQhn3w4v+CNe3Mq0/+Kky5BSLZMPC0Q9Mzez6FgsHeiKB2pzf/aeaNLPqd5I2Mcou8kQnmLaEcea739ju7AAqGQF5/L6g2vOG9VV/3ihdKFzwADXu9udQzZkLlavjjdw+vK68/7K8+cp+6+la+aCTs3nzo/phLYOdK2Jtc7198sjfiG3EuDBzr/R7W/+Hon8fvwtle6F7wIGTle6PXj/8bSk6DUy+FktO9Eatz0HwALJz8uyCSvsAHOoBzjt8siTHrzfVsqd7P1VNK+fsvjacgp4vTMK29/jC8/ZNjfxzp/YZM8l6QS8/yXrQHngqV67wRcVYfyO3XwwXKie6ECPQWjc0Jvv/SKp54ZwsDC7L5Snkpt583mn55WZ0f3JGq9fCffw41n2akzl7BQocvIwPvXUROYccj/WPVMqJvLacvTLoRVr4IpVNg9e86f5yx073504LBMGhCcmWI84J4yRMw+nzv3Y9IgJxQgd7i/U27eOT3q1ixtYbiPln8x1fLOfOkom57voMSifRXyDjnTck0N3jTNwcfI463ZE0rbUTkcB0FemAT46xRxfzu7s/x2A2TaWiKc+2cd5n91ga6/QXsaELYzPuzdZiDN8+qMBeRoxT41JheNoSF91/EhWMH8oNX1nDvM0tpbNb3kIpI8AQ+0AGK+2Qx+8Yp/O8/O5X/WrqNa2b/iXU7a3u6LBGRjDohAh3AzLj782N47IbJbKqq46rH/sSCdZU9XZaISMacMIHeYnrZEF65ZxqlRbncPPd9vvmbZT1dkohIRpxwgQ4wrF8uv7nzM4wa0IfnlsT4+lMfUN8U7+myRESOyQkZ6AAFOVH+cO807pg2mpdWbOfaOe9SW9/U02WJiHTZCRvoAJFwiL+bfhr3XDyGZZ/u4bJ/Wcjmqu67+LyISHc6oQO9xT0Xn8rsG6ewc289Fzw6n98v39b969VFRDJMgZ502YTB/PoO71uL7vrVh4z91qu8vmpnD1clIpI+BXorU0cWs+EfpvPoNRNpbE7wl08u5gevrKEprhORRKT3U6CnCIeMq6eU8s6DFzG9bDCz39rAhY/OZ/X2vT1dmohIh9IKdDO7zMzWmtl6M3ugg3ZTzSxuZldnrsSeMaRvLrOun8y/zpxEbPcBLv/Xhfzw1TVa3igivVangW5mYWAWcDkwHrjOzMYfod0/Aa9lusieYmbMmDSMhX97IcP65fLY/A2M+9ar/MPLq7UaRkR6nXRG6GcB651zG51zjcDTwIx22t0NPA9UZLC+XmF4cR4L//ZC7rl4DABzFmzkgkfnM+Onb/PztzYwb9k2zbOLSI9L58s3hwGtv9UhBpzduoGZDQOuBC4Cph7pgczsDuAOgJNOOuloa+1RoZBxz8Wncs/Fp7Kjpp5HXlrFS8u3syxWc7DNeWMGML1sCMOL8jhrVDFZEX1EISLHTzqBbu1sS12k/S/A/c65uFl7zZMHOTcHmAPeF1ykWWOvM7hvDrOun8ys62F7zQG+M28VizbvYuHHVSz8uKpN+5xoiIml/fjy5FJys8KUFuVSNqwvkbACX0QyJ51AjwGtv3G5FNiW0qYceDoZ5gOA6WbW7Jz7r0wU2ZsN6ZvL7JumAJBIONZV1HL7k4vZubeB0qJcNlbWUd+U4L1Nu3hv0642x0dC3jz9ix/GeOyGKZwzupi+uVE6emEUEWlPp19BZ2YRYB3weWArsAi43jm38gjtHwd+75x7rqPH7e6voOtNmuIJdtTU88mu/by3sZq31lVSXddIbPeBIx4TCRnNCUd+doQzT+rHPRePIRIKMXZwATnR8HGsXkR6k46+gq7TEbpzrtnM7sJbvRIG5jrnVprZncn9szNabQBFwyGGF+cxvDiPc08ZwN9cMvaw/U3xBH9cXcHu/Y3UHGji+SUxPq7YB8C+huY2UzkD8rMozI2y90AzZ48uZn9DM5uq6hg/tJCXV+ygKC/KV6YOZ9zgAspHFFNalKsRv8gJILBfEh0Ezjmq9jXypw1VhMz49fufMGl4P3bvb2TbnnoqahtoaIqzMc0llKMH9GFjVR0FORFq65v5/LgS9tY3UZgT5Y9rKrhw7EDKhvXlnJP7M7woj5LCbLIjejcg0pt0NEJXoAdAIuEwg+019fxxTQWVe+vJyQqzaNMuBuRnU1vfzObqOkb0z+O1lYeuT9MyrZOuiaV9aWhOkB0JMaJ/H7IiIV78cCuXnT6Y9zbtYsqIfmRHwlw5eRh9siL0y4tSUpCNmdE3N9odXRc54SjQ5YjiCceOvfW8t7GaSDjE2h3eJQ6cg8fmb2BQYTZnDi9ieWwPw4pyqahtYEv1foryouzen/7148MhIxo2oqEQtQ3NHbadNLwfu+oauSr5wvD8BzHGDy3klJJ8hhflsauukY8rapk59SQamhM458iKhOifn03/PlkAZIVDuOTzigSJAl26hXOOeMJR1xinal8DdQ3NVO1roLE5wYef7uHnb2082HbGpKHkZYWpb0rw4odbe7BqyMsKs78xzoRhhXy01XsBO6O0L0P65rA8VsN5YwawobKOJVt2A5AVCXHLZ0eyqaqOk4rzWLezlsraBtbsqOWicSW8saaC4cW5nFpSwFWTS9lV10BpUR61Dc1s23OAM4f3Y8uu/URCxtSRxVTXNRJPJDhlYAF1jc2YQcJBflaEUAjysiI45wiZEdILkqRQoIsvOOcwMxqbEzgcdQ1xdtU1ENt9gMLcKAca4xTkRFizvZb3Nu3ic2P6s7lqP6+v3smW6v2Ujyyib26U3y49tKr2mimlvPDhVuLtTC2N6J/Hlur9AORnR2iKJ2hoThz1u4/joV9elD2tahpYkE1lbQMA4wYXsGZHbZtjLj6thPlrK2lOOCaW9qWkMIdFm3dRnJfF7v2N5GVF2LrHW2lVkB2htqGZy04fTGlRLou37KakIJtoJMTA/GzGDymkOeFoTiRYEathwrC+NMUTrN1RS3PC8blTBvA/G6o4Z1R/du6tpynhOH1oIY3NCVZsreHsUcW8vnonJw/MZ0B+NqeU5LNnfxORsFGQEyE7Ek7+/4d9DfGD77T65UVJJKBvXpTmeIKE86YKmxIJIqEQLa93Znbw70/QKdBFjlLLuw+AuHO0/DNpaE7QHE9Q1xDnQJP3ziSecGyqqiMnGmLc4EL21jex90DzwfArH1nM/LUVLP10Dzd9ZgTLP61hZ209k4b3Y0Wshu019fTPz2LF1hr27G86+OF1i+xIiHNPGcAbaw5dVeP0oYWs3Oa9u2j9TqO11KAfXJjDjr313fHr6rWyIyEamr3LcpQN68uKrTVt2owbXEBlbQPVdY2At3jgpP55zF9bebDN58eV0BhPsPDjKk4pyWdk/zxeX11BXlaYKSOK+NOGauIJR9/cKDUHmsgKh7i6vJT5ayqYdFI/Xl9VwRmlfVnyyW6cg1/cMpULx5V0qU8KdBE5opYMaAm+/Y1xEs5xoDFOKGTsb2gmLztCJGSEzNhQuY+caJide+uJho2q2kZGD+zDki27KSvty6JNuynMjTCsXy6bq+vIjoQZVJjNG2sqGFiQTcJ5H7BX1Dbwu2XbGD0gn6xIiKK8KNtr6vnNkhifPbk/K7ftpaE5jmFMHtGPk4rzeHZxjLAZjSnXTmrvXUpLuLY4e1TxwZP7BuRnUbXPC/CR/fNIOPhk1/6DbccPKWRVq0tmjx7Qh9juAwefd2T/PDZXH2rfnv59sg6+SKS68/yTeeDycR0efyQKdBGRXqAlbxOu6x/YH9OJRSIikhktc/zhbprq19WhREQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQaQW6mV1mZmvNbL2ZPdDO/hvMbHny509mNjHzpYqISEc6DXQzCwOzgMuB8cB1ZjY+pdkm4Hzn3BnAI8CcTBcqIiIdS2eEfhaw3jm30TnXCDwNzGjdwDn3J+fc7uTdd4HSzJYpIiKdSSfQhwGftrofS247ktuAV9rbYWZ3mNliM1tcWVmZfpUiItKpdALd2tnm2m1odiFeoN/f3n7n3BznXLlzrnzgwIHpVykiIp2KpNEmBgxvdb8U2JbayMzOAP4duNw5V52Z8kREJF3pjNAXAWPMbJSZZQEzgXmtG5jZScALwE3OuXWZL1NERDrT6QjdOddsZncBrwFhYK5zbqWZ3ZncPxv4NtAfeMzMAJqdc+XdV7aIiKQy59qdDu925eXlbvHixT3y3CIifmVmS440YNaZoiIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQKQV6GZ2mZmtNbP1ZvZAO/vNzP4tuX+5mU3OfKkiItKRTgPdzMLALOByYDxwnZmNT2l2OTAm+XMH8LMM1ykiIp1IZ4R+FrDeObfROdcIPA3MSGkzA3jSed4F+pnZkAzXKiIiHYik0WYY8Gmr+zHg7DTaDAO2t25kZnfgjeAB9pnZ2qOq9pABQFUXj/Ur9fnEoD6fGI6lzyOOtCOdQLd2trkutME5NweYk8ZzdlyQ2WLnXPmxPo6fqM8nBvX5xNBdfU5nyiUGDG91vxTY1oU2IiLSjdIJ9EXAGDMbZWZZwExgXkqbecDNydUu5wA1zrntqQ8kIiLdp9MpF+dcs5ndBbwGhIG5zrmVZnZncv9s4GVgOrAe2A/c2n0lAxmYtvEh9fnEoD6fGLqlz+Zcm6luERHxIZ0pKiISEAp0EZGA8F2gd3YZAj8xs7lmVmFmH7XaVmxmfzCzj5N/FrXa92Cy32vN7NJW26eY2Yrkvn8zs/aWkfY4MxtuZm+a2WozW2lm30huD3Kfc8zsfTNbluzzd5LbA9vnFmYWNrMPzez3yfuB7rOZbU7WutTMFie3Hd8+O+d884P3oewGYDSQBSwDxvd0XcfQn2nAZOCjVtt+CDyQvP0A8E/J2+OT/c0GRiV/D+HkvveBz+CdD/AKcHlP9+0I/R0CTE7eLgDWJfsV5D4bkJ+8HQXeA84Jcp9b9f1vgF8Bvw/63+1krZuBASnbjmuf/TZCT+cyBL7hnFsA7ErZPAN4Inn7CeDPW21/2jnX4JzbhLei6KzkJRYKnXPvOO9vw5OtjulVnHPbnXMfJG/XAqvxzigOcp+dc25f8m40+eMIcJ8BzKwU+ALw7602B7rPR3Bc++y3QD/SJQaCZJBLruFP/lmS3H6kvg9L3k7d3quZ2UjgTLwRa6D7nJx6WApUAH9wzgW+z8C/AH8LJFptC3qfHfDfZrYkeZkTOM59TufU/94krUsMBNSR+u6734mZ5QPPA/c45/Z2MEUYiD475+LAJDPrB7xoZhM6aO77PpvZF4EK59wSM7sgnUPa2earPied65zbZmYlwB/MbE0Hbbulz34boZ8IlxjYmXzbRfLPiuT2I/U9lrydur1XMrMoXpg/5Zx7Ibk50H1u4ZzbA8wHLiPYfT4XuMLMNuNNi15kZr8k2H3GObct+WcF8CLeFPFx7bPfAj2dyxD43Tzgq8nbXwV+22r7TDPLNrNReNeefz/5Nq7WzM5Jfhp+c6tjepVkff8BrHbO/bjVriD3eWByZI6Z5QIXA2sIcJ+dcw8650qdcyPx/o2+4Zy7kQD32cz6mFlBy23gEuAjjnefe/qT4S58kjwdb3XEBuChnq7nGPvya7xLDDfhvTLfBvQH/gh8nPyzuFX7h5L9XkurT76B8uRfng3AT0meAdzbfoDP4b19XA4sTf5MD3ifzwA+TPb5I+Dbye2B7XNK/y/g0CqXwPYZb+XdsuTPypZsOt591qn/IiIB4bcpFxEROQIFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIP4/jrN7C778bkIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()\n",
    "plt.ylim(0,10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model ewaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1350.14250928041"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2243.3263362259077"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.710698328898677"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dda333d2b0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "# plt.xlim(0,500)\n",
    "# plt.ylim(0,500)\n",
    "\n",
    "# Our predictions\n",
    "plt.scatter(y_test,predictions,edgecolor=None,alpha=0.2)\n",
    "\n",
    "# Perfect predictions\n",
    "plt.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = y_test.reshape(y_test.shape[0], 1) - predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.xlim(-200000,200000)\n",
    "\n",
    "sns.histplot(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11711.797 ,  6363.9263, 11991.918 , 12743.926 , 11252.657 ,\n",
       "       11720.649 ,  7921.41  ,  5710.392 ,  6998.1997, 15860.561 ,\n",
       "        9198.814 ,  4099.0854, 11390.213 ,  7736.8657,  6290.003 ,\n",
       "        4113.644 ,  6910.2603,  9825.897 ,  5291.9614, 10009.516 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.reshape(y_test.shape[0])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9592.59259259,  6268.99028306,  8734.93975904,  9320.        ,\n",
       "       10414.74654378, 10487.80487805,  7500.        ,  5295.0075643 ,\n",
       "        5649.99365724, 14166.66666667,  8843.44528711,  4173.88565128,\n",
       "       12253.39763262,  7989.49737434,  5478.80690738,  4128.35428786,\n",
       "        6209.67741935,  8247.9338843 ,  4310.81081081, 11800.        ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.22092091, 1.01514374, 1.37286785, 1.36737401, 1.08045426,\n",
       "       1.11755029, 1.05618802, 1.07844833, 1.23862081, 1.11956898,\n",
       "       1.04018447, 0.982079  , 0.92955548, 0.96837953, 1.14806071,\n",
       "       0.99643678, 1.11282113, 1.19131623, 1.22760234, 0.84826404])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.reshape(y_test.shape[0])[:20]/y_test[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\piotr\\anaconda3\\envs\\machine_learning_2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models_ann\\800_2021-01-12--00-22\\assets\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow.keras.models import load_model\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "model.save('models_ann\\\\' + '800_' + timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_800']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, 'scaler_800')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
